<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>186606598926</title>
    <url>/2017/07/09/3699/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>16个有用的带宽监控工具，用于分析Linux中的网络使用情况</title>
    <url>/2018/06/09/40382/</url>
    <content><![CDATA[<p>在本文中，我们将回顾16个有用的系统和网络带宽监控工具，以分析Linux系统上的网络流量使用情况。<br>您是否在监控Linux网络带宽使用方面遇到问题？ 你需要帮助吗？ 重要的是，您能够可视化网络中发生的事情，以便了解和解决导致网络运行缓慢的任何问题，或者只是密切关注您的网络。</p>
<h1 id="另请参阅-：-20个用于监控Linux性能的Commad-Line工具"><a href="#另请参阅-：-20个用于监控Linux性能的Commad-Line工具" class="headerlink" title="另请参阅 ： 20个用于监控Linux性能的Commad Line工具"></a>另请参阅 ： <a href="https://www.howtoing.com/command-line-tools-to-monitor-linux-performance/">20个用于监控Linux性能的Commad Line工具</a></h1><p>在本文中，我们将回顾16个有用的带宽监控工具，以分析Linux系统上的网络使用情况。</p>
<p>如果您希望管理，排除故障或调试网络，请阅读我们的文章 - <a href="https://www.howtoing.com/linux-networking-commands/">Linux系统管理员网络管理指南，故障排除和调试</a></p>
<p>下面列出的工具都是开源的，可以帮助您回答诸如“ 为什么网络今天如此缓慢？ ”。 本文包括用于监控单个Linux计算机带宽的小工具和完整的监控解决方案，这些解决方案能够将LAN （ 局域网 ）上的少数主机处理到多个主机，即使在WAN （ 广域网 ）上也是如此。</p>
<h2 id="1-vnStat-网络流量监视器"><a href="#1-vnStat-网络流量监视器" class="headerlink" title="1. vnStat - 网络流量监视器"></a>1. <a href="https://www.howtoing.com/install-vnstat-and-vnstati-to-monitor-linux-network-traffic/">vnStat - 网络流量监视器</a></h2><p>VnStat是一个功能齐全的基于命令行的程序，用于在Linux和BSD系统上实时监控Linux网络流量和带宽利用率。</p>
<p>Vnstat网络流量监控工具</p>
<p>Vnstat网络流量监控工具</p>
<p>它与类似工具相比的一个优点是它记录网络流量和带宽使用统计数据以供以后分析 - 这是它的默认行为。 即使在系统重新启动后，您也可以实际查看这些日志。</p>
<p>在Linux中安装VnStat</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install vnstat

# apt install vnstat   [On Debian/Ubuntu]</code></pre>
<h2 id="2-iftop-显示带宽使用情况"><a href="#2-iftop-显示带宽使用情况" class="headerlink" title="2. iftop - 显示带宽使用情况"></a>2. <a href="https://www.howtoing.com/iftop-linux-network-bandwidth-monitoring-tool/">iftop - 显示带宽使用情况</a></h2><p>iftop是一个简单，易于使用，实时顶级的基于命令行的网络带宽监控工具，用于快速浏览界面上的网络活动。 它平均每2,10和40秒显示一次网络使用带宽更新。</p>
<p>Iftop显示带宽使用情况</p>
<p>Iftop显示带宽使用情况</p>
<p>在Linux中安装iftop</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install iftop

# apt install iftop   [On Debian/Ubuntu]</code></pre>
<h2 id="3-nload-显示网络使用情况"><a href="#3-nload-显示网络使用情况" class="headerlink" title="3. nload - 显示网络使用情况"></a>3. nload - 显示网络使用情况</h2><p>nload是另一种简单易用的命令行工具，用于实时监控网络流量和带宽使用情况。 它使用图表来帮助您监控入站和出站流量。 此外，它还显示诸如传输数据总量和最小/最大网络使用量等信息。</p>
<p>nload  - 监控网络使用情况</p>
<p>nload - 监控网络使用情况</p>
<p>在Linux中安装nload</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install nload

# apt install nload   [On Debian/Ubuntu]</code></pre>
<h2 id="4-NetHogs-监控网络流量带宽"><a href="#4-NetHogs-监控网络流量带宽" class="headerlink" title="4. NetHogs - 监控网络流量带宽"></a>4. NetHogs - 监控网络流量带宽</h2><p>NetHogs是一种类似于顶级的基于文本的工具，用于监控Linux系统上运行的每个进程或应用程序的实时网络流量带宽使用情况。 它仅提供基于每个进程的网络带宽使用情况的实时统计信息。</p>
<p>NetHogs  - 监控每个用户的网络使用情况</p>
<p>NetHogs - 监控每个用户的网络使用情况</p>
<p>在Linux中安装NetHogs</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install nethogs

# apt install nethogs       [On Debian/Ubuntu]</code></pre>
<h2 id="5-bmon-带宽监视器和速率估算器"><a href="#5-bmon-带宽监视器和速率估算器" class="headerlink" title="5. bmon - 带宽监视器和速率估算器"></a>5. bmon - 带宽监视器和速率估算器</h2><p>bmon也是一个简单的命令行工具，用于监控网络带宽利用率和Linux中的速率估算器。 它捕获网络统计数据并以人性化的格式显示它们，以便您可以密切关注系统。</p>
<p>Bmon  - 带宽监视器和速率估计器</p>
<p>Bmon - 带宽监视器和速率估计器</p>
<p>在Linux中安装Bmon</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install bmon

# apt install bmon          [On Debian/Ubuntu]</code></pre>
<h2 id="6-Darkstat-捕获网络流量"><a href="#6-Darkstat-捕获网络流量" class="headerlink" title="6. Darkstat - 捕获网络流量"></a>6. Darkstat - 捕获网络流量</h2><p>Darkstat是一个小型，简单，跨平台，实时，高效的基于Web的网络流量分析器。 它是一种网络统计监控工具，可以捕获网络流量，计算使用情况统计信息，并以图形格式通过HTTP提供报告。 您也可以通过命令行使用它来获得相同的结果。</p>
<p>Darkstat  - 捕获网络流量</p>
<p>Darkstat - 捕获网络流量</p>
<p>在Linux中安装Darkstat</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install darkstat

# apt install darkstat      [On Debian/Ubuntu]</code></pre>
<h2 id="7-IPTraf-IP网络监视器"><a href="#7-IPTraf-IP网络监视器" class="headerlink" title="7. IPTraf - IP网络监视器"></a>7. IPTraf - IP网络监视器</h2><p>IPTraf是一种易于使用，基于ncurses和可配置的工具，用于监控通过接口传入的传入和传出网络流量。 它对于IP流量监控，查看常规接口统计信息，详细的接口统计信息等非常有用。</p>
<p>IPTraf  - 网络统计工具</p>
<p>IPTraf - 网络统计工具</p>
<p>在Linux中安装IPTraf</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install iptraf

# apt install iptraf        [On Debian/Ubuntu]</code></pre>
<h2 id="8-CBM-（彩色带宽计）"><a href="#8-CBM-（彩色带宽计）" class="headerlink" title="8. CBM - （彩色带宽计）"></a>8. CBM - （彩色带宽计）</h2><p>CBM是一个微型命令行实用程序，用于在Ubuntu Linux及其衍生产品（如Linux Mint，Lubuntu等）的彩色输出中显示所有连接设备上的当前网络流量。 它显示每个连接的网络接口，接收的字节数，传输的字节数和总字节数，允许您监控网络带宽。</p>
<p>CBM  - 监控网络LAN使用情况</p>
<p>CBM - 监控网络LAN使用情况</p>
<p>在Linux中安装彩色带宽计</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install cbm

# apt install cbm           [On Debian/Ubuntu]</code></pre>
<h2 id="9-Iperf-Iperf3-网络带宽测量工具"><a href="#9-Iperf-Iperf3-网络带宽测量工具" class="headerlink" title="9. Iperf / Iperf3 - 网络带宽测量工具"></a>9. Iperf / Iperf3 - 网络带宽测量工具</h2><p>Iperf / Iperf3是一种功能强大的工具，用于测量TCP，UDP和SCTP等协议的网络吞吐量。 它主要用于帮助调整特定路径上的TCP连接，因此可用于测试和监视IP网络上可实现的最大带宽（支持IPv4和IPv6）。 它需要服务器和客户端来执行测试（报告带宽，丢失和其他有用的网络性能参数）。</p>
<p>Iperf3  - 网络性能和调优</p>
<p>Iperf3 - 网络性能和调优</p>
<p>在Linux中安装Iperf3</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install iperf3

# apt install iperf3        [On Debian/Ubuntu]</code></pre>
<h2 id="10-Netperf-网络带宽测试"><a href="#10-Netperf-网络带宽测试" class="headerlink" title="10. Netperf - 网络带宽测试"></a>10. Netperf - 网络带宽测试</h2><p>Netperf类似于iperf，用于测试网络性能。 它可以通过使用TCP，UDP测量数据传输来帮助监控Linux中的网络带宽。 它还支持通过Berkeley套接字接口，DLPI，Unix域套接字和许多其他接口进行测量。 您需要服务器和客户端来运行测试。</p>
<p>Netperf  - 网络带宽测试</p>
<p>Netperf - 网络带宽测试</p>
<p>有关安装说明，请查看项目github页面。</p>
<h2 id="11-SARG-Squid分析报告生成器"><a href="#11-SARG-Squid分析报告生成器" class="headerlink" title="11. SARG - Squid分析报告生成器"></a>11. SARG - Squid分析报告生成器</h2><p>SARG是一个Squid日志文件分析器和互联网带宽监控工具。 它生成有用的HTML报告，其中包含但不限于IP地址和总带宽使用情况。 它是一种便捷的工具，用于监控单个网络上各台计算机的互联网带宽利用率。</p>
<p>Sarg  -  Squid网络分析报告生成器</p>
<p>Sarg - Squid网络分析报告生成器</p>
<p>有关安装说明和用法，请查看我们的文章 - 如何安装SARG以监控Squid Internet带宽使用情况 。</p>
<h2 id="12-Monitorix-系统和网络监控工具"><a href="#12-Monitorix-系统和网络监控工具" class="headerlink" title="12. Monitorix - 系统和网络监控工具"></a>12. Monitorix - 系统和网络监控工具</h2><p>Monitorix是一个轻量级的系统资源和网络监控应用程序，专为小型Linux / Unix服务器而设计，并且还为嵌入式设备提供了出色的支持。</p>
<p>它可以帮助您监控无限数量的网络设备的网络流量和使用情况统计信息。 它支持IPv4和IPv6连接，包括数据包流量和流量错误图，并且每个网络接口最多支持9个qdisc。</p>
<p>Monitorix  - 系统和网络监控工具</p>
<p>Monitorix - 系统和网络监控工具</p>
<p>在Linux中安装Monitorix</p>
<pre><code class="bash"># yum install epel-release  [On RHEL/CentOS]
# yum install monitorix

# apt install monitorix     [On Debian/Ubuntu]</code></pre>
<h2 id="13-仙人掌-网络监控和绘图工具"><a href="#13-仙人掌-网络监控和绘图工具" class="headerlink" title="13.仙人掌 - 网络监控和绘图工具"></a>13.仙人掌 - 网络监控和绘图工具</h2><p>Cacti是一个功能齐全，基于Web的网络图形PHP应用程序，具有直观，易用的界面。 它使用MySQL数据库存储数据收集的网络性能数据，用于生成自定义图形。 它是RRDTool的前端，可用于监控具有数千个设备的小型到复杂网络。</p>
<p>Cacti  - 网络监控和绘图工具</p>
<p>Cacti - 网络监控和绘图工具</p>
<p>有关安装说明和用法，请查看我们的文章 - 如何安装Cacti - 网络监控和图形工具 。</p>
<h2 id="14-观察-网络监测平台"><a href="#14-观察-网络监测平台" class="headerlink" title="14.观察 - 网络监测平台"></a>14.观察 - 网络监测平台</h2><p>Observium是一个功能齐全的网络监控平台，具有优雅，功能强大，功能强大且简单直观的界面。 它支持许多平台，包括Linux，Windows，FreeBSD，Cisco，HP，Dell和许多其他平台，并包括设备的自动检测。 它可以帮助用户收集网络指标，并从收集的性能数据中提供直观的设备指标图表。</p>
<p>观测 - 网络监控平台</p>
<p>观测 - 网络监控平台</p>
<p>有关安装说明和使用方法，请查看我们的文章 - 如何安装Observium - 完整的网络管理和监控系统 。</p>
<h2 id="15-Zabbix-应用程序和网络监视工具"><a href="#15-Zabbix-应用程序和网络监视工具" class="headerlink" title="15. Zabbix - 应用程序和网络监视工具"></a>15. Zabbix - 应用程序和网络监视工具</h2><p>Zabbix是一个功能丰富，常用的网络监控平台，采用服务器 - 客户端模型设计，可实时监控网络，服务器和应用程序。 它收集用于可视化表示网络性能或受监控设备的负载指标的不同类型的数据。</p>
<p>它能够使用众所周知的网络协议，如HTTP，FTP，SMTP，IMAP等，而无需在受监控设备上安装其他软件。</p>
<p>Zabbix  -  Linux的监控解决方案</p>
<p>Zabbix - Linux的监控解决方案</p>
<p>有关安装说明和用法，请查看我们的文章 - 如何安装Zabbix - 适用于Linux的完整网络监控解决方案 。</p>
<h2 id="16-Nagios-监视系统，网络和基础设施"><a href="#16-Nagios-监视系统，网络和基础设施" class="headerlink" title="16. Nagios - 监视系统，网络和基础设施"></a>16. Nagios - 监视系统，网络和基础设施</h2><p>Nagios是一款功能强大，功能强大且功能广泛的监控软件。 它允许您从单个窗口监视本地和远程网络设备及其服务。</p>
<p>它通过SNMP在交换机和路由器等网络设备中提供带宽监控，从而使您能够轻松找到过度使用的端口，并确定可能的网络滥用者。</p>
<p>另请参阅 ： 13 Linux网络配置和故障排除命令</p>
<p>此外，Nagios还可帮助您密切关注每端口带宽利用率和错误，并支持快速检测网络中断和协议故障。</p>
<p>Nagios  -  IT基础架构监控工具</p>
<p>Nagios - IT基础架构监控工具</p>
<p>有关安装说明和使用方法，请查看我们的文章 - 如何安装Nagios - 适用于Linux的完整IT基础架构监控解决方案 。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>1956409564654</title>
    <url>/2017/11/02/53224/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>195640956464</title>
    <url>/2017/09/18/59872/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>5款超级简单的IP流量监控工具</title>
    <url>/2020/07/27/5298/</url>
    <content><![CDATA[<p>对于系统管理员来说，最重要的任务之一就是密切关注网络。当有糟糕的事情发生时，起因可能就是某个卑鄙的人。有可能是黑客，被攻破的系统，或者是出故障的硬件，关键是要找出问题所在。</p>
<p>为此，你需要合适的工具。首先你可能需要用到的工具是IP流量监控工具。所幸的是，如今有很多工具可以为你服务。糟糕的是……其中一些工具还是相当复杂的。这就是为什么我要找出最简单的IP流量监控工具，并且其中5款罗列出来，为你监控网络提供帮助。</p>
<h2 id="1、Microsoft-Network-Monitor"><a href="#1、Microsoft-Network-Monitor" class="headerlink" title="1、Microsoft Network Monitor"></a>1、Microsoft Network Monitor</h2><p>Microsoft Network Monitor（如图A）可能有些过时，但它就像是一位冠军。有了MSNM，你可以轻松地为超过300种开放协议和专有协议捕获和分析网络流量包；同时运行获取对话；运行无线监控模式，混合模式或者监听模式；等等。有了Capture选项，你可以过滤获取项，这改变适配器的选项，甚至是更改全局选项。<br>这款工具让你只需要点击几下就可以快速监控网络。当你检查故障的时候，你不会看到太多花哨的功能。这款应用是免费的，支持Windows XP/Vista/7/8/2003/2008。</p>
<h2 id="2、Umit"><a href="#2、Umit" class="headerlink" title="2、Umit"></a>2、Umit</h2><p><a href="https://sourceforge.net/projects/umit/">Umit</a>（如图B）是另外一款用于广受欢迎的nmap扫描工具的Linux前端应用。它可以很好地让任何用户使用强大的nmap工具。但是不要让简单的界面欺骗了你。Umit提供了nmap扫描器所有的强大功能和灵活性。<br>Umit可能看起来有些熟悉，因为它集成了更为流行的nmap前端，Zenmap。两者之间的主要区别是，Umit将所有必要工具放在了一个可以轻易访问到的工具栏——而Zenmao将同样的工具放到了菜单中。Umit是免费的，但是与跨平台Zenmap不同的是，它只支持Linux。</p>
<h2 id="3、Advanced-IP-Scanner"><a href="#3、Advanced-IP-Scanner" class="headerlink" title="3、Advanced IP Scanner"></a>3、Advanced IP Scanner</h2><p><a href="https://www.advanced-ip-scanner.com/">Advanced IP Scanner</a>（如图C）是这个类别下可以作为便携式版本运行的少数工具之一。这对于大多数网络管理员来说是一个福音，因为你并不总是希望花时间来安装必要的工具来发现问题。Advanced IP Scanner让你可以访问共享文件夹以及HTTP/FTP服务器，扫描所有网络设备，提供对计算机的远程控制（通过RDP），甚至可以远程关闭计算机。<br>最重要的是，你只需要打开应用，点击开始按钮，就可以关闭或者启动扫描。Advanced IP Scanner可运行在Windows 7和8上，并且是免费的。</p>
<h2 id="4、Capsa-Free"><a href="#4、Capsa-Free" class="headerlink" title="4、Capsa Free"></a>4、Capsa Free</h2><p>Capsa Free（如图D）是由Colasoft提供的，在分析流量和IP包以及解决网络问题方面表现出色。与其他选择不同的是，Capsa Free要求你必须有许可才能激活软件。（它是免费的，但是你需要提交电子邮件地址以接收许可密钥。）<br>这款工具的免费的确存在一些Capsa Professional或者Capsa Enterprise中不会有的局限性。关于这三个版本的对比，可以查看这里。Capsa中包括更繁琐的用户界面，但是这凸显出一些出色的功能（尤其是实时绘图工具）。我强烈推荐尝试一下免费版，如果符合你的需求，可以购买专业版或者企业版得到更多强大的功能。</p>
<h2 id="5、The-Dude"><a href="#5、The-Dude" class="headerlink" title="5、The Dude"></a>5、The Dude</h2><p>由MikroTik提供的The Dude（如图E）是一款有趣的网络监控工具。它监控你的网络，如果出现问题的时候会提醒你。它还可以快速扫描你的网络并定位被发现的设备。<br>有一个很方便的功能，就是手动添加设备甚至是为每台设备设定各种类型的监控。这意味着你可以设置特定的监控以细致地观察每台连接到你的网络中的设备。The Dude是免费的，只支持Windows。</p>
<p>其他选择？</p>
<p>现在有很多可用的网络监控工具可以满足你的需求。如果你正在寻找易于使用（但是足够强大以具有生产力的话），其中一款工具肯定会符合你的预算条件。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>解决 gitee page 无法自动更新</title>
    <url>/2020/12/04/32250/</url>
    <content><![CDATA[<p>众所周知，国内 GitHub 的加载速度不太理想，而大多数开发者会使用 Github 的 Github Page 功能搭建博客，因此博客的访问速度也会受到影响。为了解决访问速度的问题，我们将博客转移到了 gitee 中（ OSChina 旗下 git 平台）</p>
<h2 id="1-问题：使用-hexo-部署到-gitee-后，博客页面并没有更新"><a href="#1-问题：使用-hexo-部署到-gitee-后，博客页面并没有更新" class="headerlink" title="1. 问题：使用 hexo 部署到 gitee 后，博客页面并没有更新"></a>1. 问题：使用 hexo 部署到 gitee 后，博客页面并没有更新</h2><p>原因： gitee page 只有付费版才能自动更新，免费版只能手动点击 “设置” 中的更新按钮</p>
<h2 id="2-自动化解决方案"><a href="#2-自动化解决方案" class="headerlink" title="2. 自动化解决方案"></a>2. 自动化解决方案</h2><p>使用 puppeteer 操作浏览器进行更新按钮点击。</p>
<h2 id="3-源码如下"><a href="#3-源码如下" class="headerlink" title="3. 源码如下:"></a>3. 源码如下:</h2><a id="more"></a>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">// 此处安装版本为 1.8.0</span><br><span class="line">const puppeteer = require(<span class="string">&#x27;puppeteer&#x27;</span>); </span><br><span class="line"></span><br><span class="line">async <span class="keyword">function</span> <span class="function"><span class="title">giteeUpdate</span></span>() &#123;</span><br><span class="line">    const browser = await puppeteer.launch(&#123;</span><br><span class="line">        // 此处可以使用 <span class="literal">false</span> 有头模式进行调试, 调试完注释即可</span><br><span class="line">          headless: <span class="literal">false</span>,</span><br><span class="line">    &#125;);</span><br><span class="line">    const page = await browser.newPage();</span><br><span class="line">    await page.goto(<span class="string">&#x27;https://gitee.com/login&#x27;</span>);</span><br><span class="line">    // 1. 选中账号控件</span><br><span class="line">    <span class="built_in">let</span> accountElements = await page.<span class="variable">$x</span>(<span class="string">&#x27;//*[@id=&quot;user_login&quot;]&#x27;</span>) // 此处使用 xpath 寻找控件，下同</span><br><span class="line">    // 2. 填入账号</span><br><span class="line">    await accountElements[0].<span class="built_in">type</span>(<span class="string">&#x27;你的 gitee 账户&#x27;</span>)</span><br><span class="line">    // 3. 选中密码控件</span><br><span class="line">    <span class="built_in">let</span> pwdElements = await page.<span class="variable">$x</span>(<span class="string">&#x27;//*[@id=&quot;user_password&quot;]&#x27;</span>)</span><br><span class="line">    // 4. 填入密码</span><br><span class="line">    await pwdElements[0].<span class="built_in">type</span>(<span class="string">&#x27;你的 gitee 密码&#x27;</span>)</span><br><span class="line">    // 5. 点击登录</span><br><span class="line">    <span class="built_in">let</span> loginButtons = await page.<span class="variable">$x</span>(<span class="string">&#x27;//*[@id=&quot;new_user&quot;]/div[2]/div/div/div[4]/input&#x27;</span>)</span><br><span class="line">    await loginButtons[0].click()</span><br><span class="line">    // 6. 等待登录成功</span><br><span class="line">    await page.waitFor(1000)</span><br><span class="line">    await page.goto(<span class="string">&#x27;你的 gitee page 更新按钮页面&#x27;</span>); // 比如： https://gitee.com/yang0033/hexo-blog/pages</span><br><span class="line">    // 7.1. 监听步骤 7 中触发的确认弹框，并点击确认</span><br><span class="line">    await page.on(<span class="string">&#x27;dialog&#x27;</span>, async dialog =&gt; &#123;</span><br><span class="line">        console.log(<span class="string">&#x27;确认更新&#x27;</span>)</span><br><span class="line">        dialog.accept();</span><br><span class="line">    &#125;)</span><br><span class="line">    // 7. 点击更新按钮，并弹出确认弹窗</span><br><span class="line">    <span class="built_in">let</span> updateButtons = await page.<span class="variable">$x</span>(<span class="string">&#x27;//*[@id=&quot;pages-branch&quot;]/div[7]&#x27;</span>)</span><br><span class="line">    await updateButtons[0].click()</span><br><span class="line">    // 8. 轮询并确认是否更新完毕</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        await page.waitFor(2000)</span><br><span class="line">        try &#123;</span><br><span class="line">            // 8.1 获取更新状态标签</span><br><span class="line">            deploying = await page.<span class="variable">$x</span>(<span class="string">&#x27;//*[@id=&quot;pages_deploying&quot;]&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> (deploying.length &gt; 0) &#123;</span><br><span class="line">                console.log(<span class="string">&#x27;更新中...&#x27;</span>)</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                console.log(<span class="string">&#x27;更新完毕&#x27;</span>)</span><br><span class="line">                <span class="built_in">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (error) &#123;</span><br><span class="line">            <span class="built_in">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    await page.waitFor(500);</span><br><span class="line">    // 10.更新完毕，关闭浏览器</span><br><span class="line">    browser.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">giteeUpdate();</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>Docker 本地导入镜像/保存镜像/载入镜像/删除镜像</title>
    <url>/2020/07/24/62766/</url>
    <content><![CDATA[<h1 id="1、Docker导入本地镜像"><a href="#1、Docker导入本地镜像" class="headerlink" title="1、Docker导入本地镜像"></a>1、Docker导入本地镜像</h1><p>有时候我们自己在本地或者其它小伙伴电脑上拷贝了一份镜像，有了这个镜像之后，我们可以把本地的镜像导入，使用docker import 命令。</p>
<p>例如这里下载了一个 alibaba-rocketmq-3.2.6.tar.gz 镜像文件，使用下列命令导入：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@rocketmq-nameserver4 dev]<span class="comment"># cat alibaba-rocketmq-3.2.6.tar.gz | docker import - rocketmq:3.2.6(镜像名自己定义)</span></span><br><span class="line">[root@rocketmq-nameserver4 dev]<span class="comment"># docker images</span></span><br><span class="line">REPOSITORY                   TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">rocketmq                     <span class="number">3.2</span><span class="number">.6</span>               53925d1cf9f0        <span class="number">23</span> seconds ago      14MB</span><br><span class="line">my/python                    v1                  36b6e288656c        <span class="number">2</span> days ago          281MB</span><br><span class="line">my/centos_width_python       v1<span class="number">.0</span><span class="number">.1</span>              36b6e288656c        <span class="number">2</span> days ago          281MB</span><br><span class="line">my/sinatra                   v2                  8ba1d6a3ce4e        <span class="number">2</span> days ago          453MB</span><br><span class="line">hello-world                  latest              725dcfab7d63        <span class="number">4</span> months ago        <span class="number">1.84</span>kB</span><br></pre></td></tr></table></figure>
<p>​<br>可以看到导入完成后，docker为我们生成了一个镜像ID，使用docker images也可以看到我们刚刚从本地导入的镜像。</p>
<p>注意镜像文件必须是tar.gz类型的文件。</p>
<h1 id="2、保存镜像"><a href="#2、保存镜像" class="headerlink" title="2、保存镜像"></a>2、保存镜像</h1><p>先根据已有的这个容器来提交一个新的镜像，提交时需要用到容器ID。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker commit –m “rocketmq” –a “zmc” d8990fec2141 rocketmq</span><br></pre></td></tr></table></figure>
<p>我们的镜像做好之后，我们要保存起来，以供备份使用，该怎么做？使用docker save命令，保存镜像到本地。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@rocketmq-nameserver4 dev]<span class="comment"># docker save -o rocketmq.tar rocketmq ##-o：指定保存的镜像的名字；rocketmq.tar：保存到本地的镜像名称；rocketmq：镜像名字，通过&quot;docker images&quot;查看</span></span><br><span class="line">[root@rocketmq-nameserver4 dev]<span class="comment"># ll </span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>rocketmq.tar为刚保存的镜像</p>
<h1 id="3、载入镜像"><a href="#3、载入镜像" class="headerlink" title="3、载入镜像"></a>3、载入镜像</h1><p>我们有了本地的镜像文件，在需要的时候可以使用docker load将本地保存的镜像再次导入docker中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker load --<span class="built_in">input</span> rocketmq.tar 或 docker load &lt; rocketmq.tar</span><br></pre></td></tr></table></figure>


<h1 id="4、删除镜像"><a href="#4、删除镜像" class="headerlink" title="4、删除镜像"></a>4、删除镜像</h1><p>有些镜像过时了，我们需要删除。使用如下的命令：docker rmi -f image_id ##-f：表示强制删除镜像；image_id：镜像id</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker容器命令整理</title>
    <url>/2020/07/31/50481/</url>
    <content><![CDATA[<p>Docker重启所有命令以及构建是如何设置开机重启</p>
<h2 id="设置开机重启"><a href="#设置开机重启" class="headerlink" title="设置开机重启"></a>设置开机重启</h2><p>–restart=always</p>
<h2 id="启动所有容器"><a href="#启动所有容器" class="headerlink" title="启动所有容器"></a>启动所有容器</h2><p>docker start $(docker ps -a | awk ‘{ print $1}’ | tail -n +2)</p>
<a id="more"></a>
<h2 id="关闭所有容器"><a href="#关闭所有容器" class="headerlink" title="关闭所有容器"></a>关闭所有容器</h2><p>docker stop $(docker ps -a | awk ‘{ print $1}’ | tail -n +2)</p>
<h2 id="删除所有容器"><a href="#删除所有容器" class="headerlink" title="删除所有容器"></a>删除所有容器</h2><p>docker rm $(docker ps -a | awk ‘{ print $1}’ | tail -n +2)</p>
<h2 id="删除所有镜像"><a href="#删除所有镜像" class="headerlink" title="删除所有镜像"></a>删除所有镜像</h2><p>docker rmi $(docker p_w_picpaths | awk ‘{print $3}’ |tail -n +2)</p>
<h2 id="重启所有容器"><a href="#重启所有容器" class="headerlink" title="重启所有容器"></a>重启所有容器</h2><p>docker restart $(docker ps -a | awk ‘{ print $1}’ | tail -n +2)</p>
<h2 id="清理没有运行的容器"><a href="#清理没有运行的容器" class="headerlink" title="清理没有运行的容器"></a>清理没有运行的容器</h2><p>docker container prune<br><a href="https://yuehuaxw.com/2019/03/07/Gitlab%E5%AE%9E%E7%8E%B0CI-CD/">link</a></p>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo使用攻略-添加分类及标签</title>
    <url>/2020/07/23/31198/</url>
    <content><![CDATA[<h2 id="1、创建“分类”选项"><a href="#1、创建“分类”选项" class="headerlink" title="1、创建“分类”选项"></a>1、创建“分类”选项</h2><h3 id="1-1-生成“分类”页并添加tpye属性"><a href="#1-1-生成“分类”页并添加tpye属性" class="headerlink" title="1.1 生成“分类”页并添加tpye属性"></a>1.1 生成“分类”页并添加tpye属性</h3><p>打开命令行，进入博客所在文件夹。执行命令</p>
<pre><code class="python">$ hexo new page categories</code></pre>
<p>成功后会提示：</p>
<pre><code class="python">INFO  Created: ~/Documents/blog/source/categories/index.md</code></pre>
<p>根据上面的路径，找到index.md这个文件，打开后默认内容是这样的：</p>
<pre><code class="python">---
title: 文章分类
date: 2017-05-27 13:47:40
---</code></pre>
<p>添加type: “categories”到内容中，添加后是这样的：</p>
<pre><code class="python">---
title: 文章分类
date: 2017-05-27 13:47:40
type: &quot;categories&quot;
---</code></pre>
<p>保存并关闭文件。</p>
<h3 id="1-2-给文章添加“categories”属性"><a href="#1-2-给文章添加“categories”属性" class="headerlink" title="1.2 给文章添加“categories”属性"></a>1.2 给文章添加“categories”属性</h3><p>打开需要添加分类的文章，为其添加categories属性。下方的categories: web前端表示添加这篇文章到“web前端”这个分类。注意：hexo一篇文章只能属于一个分类，也就是说如果在“- web前端”下方添加“-xxx”，hexo不会产生两个分类，而是把分类嵌套（即该文章属于 “- web前端”下的 “-xxx ”分类）。</p>
<pre><code class="python">---
title: jQuery对表单的操作及更多应用
date: 2017-05-26 12:12:57
categories: 
- web前端
---</code></pre>
<p>至此，成功给文章添加分类，点击首页的“分类”可以看到该分类下的所有文章。当然，只有添加了categories: xxx的文章才会被收录到首页的“分类”中。</p>
<h2 id="2、创建“标签”选项"><a href="#2、创建“标签”选项" class="headerlink" title="2、创建“标签”选项"></a>2、创建“标签”选项</h2><h3 id="2-1-生成“标签”页并添加tpye属性"><a href="#2-1-生成“标签”页并添加tpye属性" class="headerlink" title="2.1 生成“标签”页并添加tpye属性"></a>2.1 生成“标签”页并添加tpye属性</h3><p>打开命令行，进入博客所在文件夹。执行命令</p>
<pre><code class="python">$ hexo new page tags</code></pre>
<p>成功后会提示：</p>
<pre><code class="python">INFO  Created: ~/Documents/blog/source/tags/index.md</code></pre>
<p>根据上面的路径，找到index.md这个文件，打开后默认内容是这样的：</p>
<pre><code class="python">---
title: 标签
date: 2017-05-27 14:22:08
---</code></pre>
<p>添加type: “tags”到内容中，添加后是这样的：</p>
<pre><code class="python">---
title: 文章分类
date: 2017-05-27 13:47:40
type: &quot;tags&quot;
---</code></pre>
<p>保存并关闭文件。</p>
<h3 id="2-2-给文章添加“tags”属性"><a href="#2-2-给文章添加“tags”属性" class="headerlink" title="2.2 给文章添加“tags”属性"></a>2.2 给文章添加“tags”属性</h3><p>打开需要添加标签的文章，为其添加tags属性。下方的tags:下方的- jQuery - 表格</p>
<ul>
<li>表单验证就是这篇文章的标签了<pre><code class="python"></code></pre>
</li>
</ul>
<hr>
<p>title: jQuery对表单的操作及更多应用<br>date: 2017-05-26 12:12:57<br>categories: </p>
<ul>
<li>web前端<br>tags:</li>
<li>jQuery</li>
<li>表格</li>
<li>表单验证</li>
</ul>
<hr>
<p>```<br>至此，成功给文章添加分类，点击首页的“标签”可以看到该标签下的所有文章。当然，只有添加了tags: xxx的文章才会被收录到首页的“标签”中。</p>
<p>细心的朋友可能已经发现，这两个的设置几乎一模一样！是的，没错，思路都是一样的。所以我们可以</p>
<h3 id="打开scaffolds-post-md文件，在tages-上面加入categories-保存后，之后执行hexo-new-文章名命令生成的文件，页面里就有categories-项了。"><a href="#打开scaffolds-post-md文件，在tages-上面加入categories-保存后，之后执行hexo-new-文章名命令生成的文件，页面里就有categories-项了。" class="headerlink" title="打开scaffolds/post.md文件，在tages:上面加入categories:,保存后，之后执行hexo new 文章名命令生成的文件，页面里就有categories:项了。"></a>打开scaffolds/post.md文件，在tages:上面加入categories:,保存后，之后执行hexo new 文章名命令生成的文件，页面里就有categories:项了。</h3><p>scaffolds目录下，是新建页面的模板，执行新建命令时，是根据这里的模板页来完成的，所以可以在这里根据你自己的需求添加一些默认值。</p>
<p>教程结束，赶紧去设置吧！</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>在Hexo博客中插入图片的各种方式</title>
    <url>/2020/12/07/23963/</url>
    <content><![CDATA[<p>在文章中插入图片<br><a href="https://yanyinhong.github.io/2017/05/02/How-to-insert-image-in-hexo-post/">Hexo博客搭建之在文章中插入图片</a></p>
<h2 id="绝对路径本地引用"><a href="#绝对路径本地引用" class="headerlink" title="绝对路径本地引用"></a>绝对路径本地引用</h2><p>当Hexo项目中只用到少量图片时，可以将图片统一放在source/images文件夹中，通过markdown语法访问它们。</p>
<p><a href="/images/image.jpg"></a></p>
<a id="more"></a>
<p>图片既可以在首页内容中访问到，也可以在文章正文中访问到。</p>
<h2 id="相对路径本地引用"><a href="#相对路径本地引用" class="headerlink" title="相对路径本地引用"></a>相对路径本地引用</h2><p>图片除了可以放在统一的images文件夹中，还可以放在文章自己的目录中。文章的目录可以通过站点配置文件_config.yml来生成。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">post_asset_folder: <span class="literal">true</span></span><br><span class="line">``` </span><br><span class="line">将_config.yml文件中的配置项post_asset_folder设为<span class="literal">true</span>后，执行命令$ hexo new post_name，在<span class="built_in">source</span>/_posts中会生成文章post_name.md和同名文件夹post_name。将图片资源放在post_name中，文章就可以使用相对路径引用图片资源了。</span><br><span class="line">``` bash</span><br><span class="line">![](image.jpg)</span><br><span class="line">``` </span><br><span class="line">[vi-vim-cheat-sheet.gif](vi-vim-cheat-sheet.gif)</span><br><span class="line"><span class="comment">## 标签插件语法引用</span></span><br><span class="line">这种相对路径的图片显示方法在博文详情页面显示没有问题，但是在首页预览页面图片将显示不出来。如果希望图片在文章和首页中同时显示，可以使用标签插件语法。</span><br><span class="line">``` bash</span><br><span class="line"><span class="comment"># 本地图片资源，不限制图片尺寸</span></span><br><span class="line">&#123;% asset_img image.jpg This is an image %&#125;</span><br><span class="line"><span class="comment"># 网络图片资源，限制图片显示尺寸</span></span><br><span class="line">&#123;% img http://www.viemu.com/vi-vim-cheat-sheet.gif 200 400 vi-vim-cheat-sheet %&#125;</span><br><span class="line">HTML语法引用</span><br><span class="line">&lt;img src=<span class="string">&quot;SpellCheck.png&quot;</span> width=<span class="string">&quot;50%&quot;</span> height=<span class="string">&quot;50%&quot;</span> title=<span class="string">&quot;拼写检查工具Grammarly.&quot;</span> alt=<span class="string">&quot;拼写检查工具Grammarly.&quot;</span>/&gt;</span><br></pre></td></tr></table></figure>
<p>直接将<img src="/.com//image.jpg">替换上面的语法即可。</p>
<p>启用fancybox：点击查看图片大图<br>我这里使用的是Hexo的NexT主题，NexT主题中提供了fancybox的方便接口。</p>
<p>Usage：<a href="https://github.com/theme-next/theme-next-fancybox3">https://github.com/theme-next/theme-next-fancybox3</a><br>markdown用法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% img http://www.viemu.com/vi-vim-cheat-sheet.gif 600 600 <span class="string">&quot;点击查看大图:vi/vim-cheat-sheet&quot;</span> %&#125;</span><br></pre></td></tr></table></figure>
<p>Hexo部分图片禁用fancybox</p>
<p>hexo在使用fancybox插件时，图片的效果还是很可观的，但是我们往往是不需要所有的图片都用fancybox；<br>例如：hexo next主题下，添加某些图片的时候，有些事不需要可点击的<br>修改theme\next\source\js\src\utils.js 红色字体部分；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">diff --git a/<span class="built_in">source</span>/js/src/utils.js b/<span class="built_in">source</span>/js/src/utils.js</span><br><span class="line">index 0f3704e..8516665 100644</span><br><span class="line">--- a/<span class="built_in">source</span>/js/src/utils.js</span><br><span class="line">+++ b/<span class="built_in">source</span>/js/src/utils.js</span><br><span class="line">@@ -11,6 +11,7 @@ NexT.utils = NexT.<span class="variable">$u</span> = &#123;</span><br><span class="line">       .not(<span class="string">&#x27;.group-picture img, .post-gallery img&#x27;</span>)</span><br><span class="line">       .each(<span class="function"><span class="title">function</span></span>() &#123;</span><br><span class="line">         var <span class="variable">$image</span> = $(this);</span><br><span class="line">+        <span class="keyword">if</span> ($(this).hasClass(<span class="string">&#x27;nofancybox&#x27;</span>)) <span class="built_in">return</span>;</span><br><span class="line">         var imageTitle = <span class="variable">$image</span>.attr(<span class="string">&#x27;title&#x27;</span>);</span><br><span class="line">         var <span class="variable">$imageWrapLink</span> = <span class="variable">$image</span>.parent(<span class="string">&#x27;a&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>在img标签使用的时候加上class=”nofancybox”即可。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;img src=<span class="string">&quot;http://www.viemu.com/vi-vim-cheat-sheet.gif&quot;</span> class=<span class="string">&quot;nofancybox&quot;</span> /&gt;</span><br></pre></td></tr></table></figure>
<img src="http://www.viemu.com/vi-vim-cheat-sheet.gif" class width="600" height="600" title="点击查看大图:vi&#x2F;vim-cheat-sheet">]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客使用系列（一）——新建文章并发布</title>
    <url>/2020/07/22/54320/</url>
    <content><![CDATA[<h2 id="新建文章的方法"><a href="#新建文章的方法" class="headerlink" title="新建文章的方法"></a>新建文章的方法</h2><p>1、进入你的博客目录，在 /source/_posts 文件夹下直接建立一个.md文件。<br>2、进入你的博客目录，右键选择 Git Bash Here 进入命令窗口，输入下面代码:<br>hexo new “新建文章名称”    #新建文章<br>此时，在方法1所述的文件夹里便有了 新建文章名称.md 文件。</p>
<h2 id="发布新建文章"><a href="#发布新建文章" class="headerlink" title="发布新建文章"></a>发布新建文章</h2><p>在该博客项目文件夹下运行 Git Bash Here 命令窗口，依次输入如下代码：</p>
<p>hexo generate    #生成更改<br>hexo deploy    #将生成的更改部署到码云或者GitHub上</p>
<h3 id="注意"><a href="#注意" class="headerlink" title="==注意=="></a>==注意==</h3><p>1、部署到GitHub时，可能因为网速、被墙等原因，需要多次运行 hexo deploy ；有时候可以运行 hexo clean 后在运行上述代码。<br>2、.md文件不要用记事本打开，建议使用具有markdown语法的程序打开，比如：subline text、notepad++等。也可以使用在线markdown编辑器，比如：</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>HyperLedger Fabric 2.0-release测试网络部署</title>
    <url>/2020/07/29/51980/</url>
    <content><![CDATA[<h2 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1.环境准备"></a>1.环境准备</h2><p>CentOS 7<br>Docker 18.09.4<br>Docker-compose 1.32.2<br>GO 1.13.4</p>
<h2 id="2-下载源码"><a href="#2-下载源码" class="headerlink" title="2.下载源码"></a>2.下载源码</h2><h3 id="1-创建go工作目录"><a href="#1-创建go工作目录" class="headerlink" title="1.创建go工作目录"></a>1.创建go工作目录</h3><p>mkdir go<br>mkdir go/src<br>mkdir go/pkg<br>mkdir go/bin<br>export GOPATH=xx/go<br>复制代码2.创建hyperledger目录<br>mkdir go/src/github.com/hyperledger<br>复制代码3.下载fabric release-2.0源码<br>cd go/src/github.com/hyperledger<br>git clone <a href="https://github.com/hyperledger/fabric.git">https://github.com/hyperledger/fabric.git</a><br>cd fabric &amp;&amp; git checkout release-2.0<br>复制代码假如觉得git clone慢可参考 如何快速clone github代码库</p>
<h2 id="3-编译二进制文件以及docker镜像"><a href="#3-编译二进制文件以及docker镜像" class="headerlink" title="3. 编译二进制文件以及docker镜像"></a>3. 编译二进制文件以及docker镜像</h2><p>当前在fabric目录<br>打开控制台进入fabric目录，执行以下命令<br>make all<br>复制代码中间可能提示没有安装gcc，此时只需要安装即可<br>yum install gcc<br>复制代码执行完成后，查看编译二进制文件如下：<br>ll build/bin<br>复制代码控制台输出如下：</p>
<p>执行完成后，查看编译Docker镜像如下：<br>docker images |grep 2.0|grep fabric<br>复制代码控制台输出如下：</p>
<h2 id="4-运行测试网络"><a href="#4-运行测试网络" class="headerlink" title="4.运行测试网络"></a>4.运行测试网络</h2><p>1.将编译完成的二进制文件复制到 fabric-samples 目录<br>cp -r build/bin fabric-samples<br>复制代码2.网络准备<br>cd  fabric-samples/first-network<br>./byfn.sh generate<br>复制代码生成证书文件以及通道文件如下</p>
<p>3.运行测试网络<br>./byfn.sh up<br>复制代码控制台输出如下提示即运行成功</p>
<p>查看docker状态如下：<br>docker ps |grep fabric<br>复制代码执行结果如下：</p>
<h2 id="5-END"><a href="#5-END" class="headerlink" title="5.END"></a>5.END</h2><p>官方测试网络运行结束，接下来将对2.0的部署配置、合约以及raft共识进行继续学习，请持续关注。<br>推荐阅读： <a href="https://blog.csdn.net/qq_28540443/article/details/104282768">Fabric2.0 first-network</a> 生成配置说明</p>
<p>链接：<a href="https://juejin.im/post/5e440073518825490d124c92">https://juejin.im/post/5e440073518825490d124c92</a></p>
]]></content>
      <categories>
        <category>block chain</category>
      </categories>
      <tags>
        <tag>block chain</tag>
        <tag>HyperLedger Fabric</tag>
      </tags>
  </entry>
  <entry>
    <title> Hyperledger Fabric 1.4 快速环境搭建</title>
    <url>/2020/07/29/62761/</url>
    <content><![CDATA[<p>自己的硕士研究方向和区块链有关，工程上一直以IBM的Hyperledger Fabric为基础进行开发，对该项目关注也有两年了。目前迎来了Hyperledger Fabric v1.4，这也是Fabric的第一个长期支持版本，因此也比较有代表性，故在此和大家分享一下自己的环境搭建过程。</p>
<p>附上v1.4的官方文档：<a href="https://hyperledger-fabric.readthedocs.io/en/release-1.4/%E3%80%82">https://hyperledger-fabric.readthedocs.io/en/release-1.4/。</a></p>
<p>环境说明:</p>
<p>　　本人测试环境为腾讯云学生机（1Core/RAM 2G/ROM 50G），CentOS 7.5 64位。</p>
<h2 id="Golang-安装配置（非必须）"><a href="#Golang-安装配置（非必须）" class="headerlink" title="Golang 安装配置（非必须）"></a>Golang 安装配置（非必须）</h2><p>下载安装包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mkdir download</span><br><span class="line">cd download</span><br><span class="line"><span class="comment"># 从国内站点下载合适的安装包</span></span><br><span class="line">wget https://studygolang.com/dl/golang/go1<span class="number">.12</span><span class="number">.4</span>.linux-amd64.tar.gz </span><br><span class="line">解压</span><br><span class="line"></span><br><span class="line">tar -C /usr/local/ -xzvf go1<span class="number">.12</span><span class="number">.4</span>.linux-amd64.tar.gz  <span class="comment">#解压到/usr/local/go目录下</span></span><br><span class="line">配置</span><br><span class="line"></span><br><span class="line">vim /etc/profile  <span class="comment"># 配置系统环境变量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在最下方插入</span></span><br><span class="line"><span class="comment"># Golang 环境变量</span></span><br><span class="line">export GOROOT=/usr/local/go</span><br><span class="line">export GOPATH=/root/go</span><br><span class="line">export GOBIN=$GOPATH/<span class="built_in">bin</span></span><br><span class="line">export PATH=$PATH:$GOROOT/<span class="built_in">bin</span></span><br><span class="line">export PATH=$PATH:$GOPATH/<span class="built_in">bin</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使配置的环境变量生效</span></span><br><span class="line">source /etc/profile </span><br><span class="line"><span class="comment">#检查是否配置正确</span></span><br><span class="line">go version</span><br></pre></td></tr></table></figure>
<p>说明：Go的环境并非运行的必须条件，但后期调试智能合约可能会用到，而且官网安装说明也提到了需要安装Go。</p>
<h2 id="Node-js-安装配置（非必须）"><a href="#Node-js-安装配置（非必须）" class="headerlink" title="Node.js 安装配置（非必须）"></a>Node.js 安装配置（非必须）</h2><p>通过nvm安装Node.js和npm，该步骤也不是运行的必须条件，但后期如果需要node-sdk来开发应用程序的话就需要node环境。（npm源切换可参考npm 淘宝源切换教程）</p>
<p>安装nvm（官方文档：<a href="https://github.com/nvm-sh/nvm%EF%BC%89">https://github.com/nvm-sh/nvm）</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装后重启该会话或重新开一个会话即可生效</span></span><br><span class="line">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0<span class="number">.34</span><span class="number">.0</span>/install.sh | bash</span><br><span class="line">通过nvm安装Node.js和npm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前支持的版本，fabricv1.4要求只支持8.x</span></span><br><span class="line">nvm ls-remote</span><br><span class="line"><span class="comment"># 安装当前8.x LTS的最新版本（会同时安装npm）</span></span><br><span class="line">nvm install <span class="number">8.16</span><span class="number">.0</span></span><br><span class="line"><span class="comment"># 检查node.js安装版本</span></span><br><span class="line">node -v</span><br><span class="line"><span class="comment"># 检查npm的安装版本</span></span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure>
<h2 id="Docker-安装"><a href="#Docker-安装" class="headerlink" title="Docker 安装"></a>Docker 安装</h2><p>Docker安装社区版的就可以，参考官方文档：<a href="https://docs.docker.com/install/linux/docker-ce/centos/">https://docs.docker.com/install/linux/docker-ce/centos/</a></p>
<p>参考官方文档的第一种通过仓库安装的方式（傻瓜操作的话第三种直接脚本安装更简单）。</p>
<p>p.s. 由于docker-hub镜像仓库在国外，可能会被墙或者很慢，建议大家参考daocloud加速器配置一下仓库，或者用云服务器的可以参考各家的docker仓库源（阿里Docker镜像库、腾讯Docker镜像库等）。</p>
<p>卸载旧版本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br><span class="line"></span><br><span class="line">安装docker-ce的必需条件</span><br><span class="line"></span><br><span class="line">sudo yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2</span><br><span class="line">设置稳定版的仓库</span><br><span class="line"></span><br><span class="line">sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">安装docker-ce</span><br><span class="line"></span><br><span class="line">yum install docker-ce docker-ce-cli containerd.io</span><br><span class="line">启动docker</span><br><span class="line"></span><br><span class="line">sudo systemctl start docker</span><br><span class="line">测试docker是否安装成功</span><br><span class="line"></span><br><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure>
<h2 id="Docker-Compose-安装"><a href="#Docker-Compose-安装" class="headerlink" title="Docker Compose 安装"></a>Docker Compose 安装</h2><p>Fabric中节点容器编排使用的使docker-compose，故需要安装docker-compose。官方文档：<a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a></p>
<p>下载docker-compose</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo curl -L <span class="string">&quot;https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m)&quot;</span> -o /usr/local/<span class="built_in">bin</span>/docker-compose</span><br><span class="line">为docker-compose配置执行权限</span><br><span class="line"></span><br><span class="line">sudo chmod +x /usr/local/<span class="built_in">bin</span>/docker-compose</span><br><span class="line">检查是否安装成功</span><br><span class="line"></span><br><span class="line">docker-compose -v</span><br></pre></td></tr></table></figure>
<h2 id="源码获取"><a href="#源码获取" class="headerlink" title="源码获取"></a>源码获取</h2><p>通过go get 的方式获取源码，配合git切换分支</p>
<p>获取fabric源码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取fabric源码</span></span><br><span class="line">go get -u github.com/hyperledger/fabric</span><br><span class="line"><span class="comment"># 进入目录 切换分支</span></span><br><span class="line">cd go/src/github.com/hyperledger/fabric</span><br><span class="line">git checkout v1<span class="number">.4</span><span class="number">.1</span></span><br><span class="line">获取fabric-sample源码</span><br><span class="line"></span><br><span class="line">go get github.com/hyperledger/fabric-samples</span><br><span class="line"><span class="comment"># 进入目录，切换分支</span></span><br><span class="line">cd go/src/github.com/hyperledger/fabric-samples/</span><br><span class="line">git checkout v1<span class="number">.4</span><span class="number">.1</span></span><br></pre></td></tr></table></figure>
<h2 id="获取镜像和二进制文件"><a href="#获取镜像和二进制文件" class="headerlink" title="获取镜像和二进制文件"></a>获取镜像和二进制文件</h2><p>我们通过fabric-sample测试</p>
<p>通过脚本获取docker镜像和可执行文件（建议事先配置好docker仓库）</p>
<p>cd go/src/github.com/hyperledger/fabric-samples/scripts/<br>#此处可能因为网络问题执行时间比较久<br>bash bootstrap.sh</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## 运行测试</span><br><span class="line">通过fabric-sample中first-network示例测试，执行了一个A和B转账，中间多次查询余额的一个过程。</span><br><span class="line"></span><br><span class="line">docker运行需要权限，最好用root身份运行。</span><br><span class="line"></span><br><span class="line">找到first-network示例</span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">cd go&#x2F;src&#x2F;github.com&#x2F;hyperledger&#x2F;fabric-samples&#x2F;first-network</span><br><span class="line">生成密钥文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@VM_0_39_centos first-network]# bash byfn.sh generate</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="启动示例"><a href="#启动示例" class="headerlink" title="启动示例"></a>启动示例</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@VM_0_39_centos first-network]<span class="comment"># bash byfn.sh up</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">90</span></span><br><span class="line">===================== Query successful on peer1.org2 on channel <span class="string">&#x27;mychannel&#x27;</span> ===================== </span><br><span class="line"></span><br><span class="line">========= All GOOD, BYFN execution completed =========== </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> _____   _   _   ____   </span><br><span class="line">| ____| | \ | | |  _ \  </span><br><span class="line">|  _|   |  \| | | | | | </span><br><span class="line">| |___  | |\  | | |_| | </span><br><span class="line">|_____| |_| \_| |____/  </span><br></pre></td></tr></table></figure>
<h2 id="清除示例"><a href="#清除示例" class="headerlink" title="清除示例"></a>清除示例</h2><p>执行删除密钥文件，停止并删除容器等操作</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@VM_0_39_centos first-network]<span class="comment"># bash byfn.sh down</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://www.cnblogs.com/xiaoxt/p/10806720.html">link</a><br><a href="https://juejin.im/post/5da738f851882505ca647153">link</a><br><a href="https://developer.ibm.com/zh/tutorials/cl-lo-hyperledger-fabric-study-notes1/">IMB hyperledger-fabric</a></p>
]]></content>
      <categories>
        <category>block chain</category>
      </categories>
      <tags>
        <tag>block chain</tag>
        <tag>Hyperledger Fabric</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes(一) 跟着官方文档从零搭建K8S</title>
    <url>/2020/08/03/39247/</url>
    <content><![CDATA[<h1 id="强烈建议kubernetes-离线二进制安装更kubeOperator"><a href="#强烈建议kubernetes-离线二进制安装更kubeOperator" class="headerlink" title="强烈建议kubernetes 离线二进制安装更kubeOperator"></a>强烈建议kubernetes 离线二进制安装更<a href="https://github.com/KubeOperator/k8s-package">kubeOperator</a></h1><p>文章地址: <a href="https://blog.piaoruiqing.com/2019/09/17/kubernetes-1-installation/">https://blog.piaoruiqing.com/2019/09/17/kubernetes-1-installation/</a></p>
<p>前言<br>本文将带领读者一起, 参照着Kubernetes官方文档, 对其安装部署进行讲解. Kubernetes更新迭代很快, 书上、网上等教程可能并不能适用于新版本, 但官方文档能.</p>
<p>阅读这篇文章你能收获到:</p>
<a id="more"></a>
<p>如何阅读Kubernetes官方安装指南并搭建一个Kubernetes环境.<br>Kubernetes安装过程中的注意事项.<br>避过常见的坑.<br>阅读本文你需要:</p>
<p>熟悉Linux命令.<br>知道Kubernetes是用来干什么的 (不然装它干啥(ಥ_ಥ)).<br>知道Docker<br>器材准备<br>文档链接: Before you begin</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">序号	名称	数量	备注</span><br><span class="line"><span class="number">1</span>	服务器	<span class="number">2</span>	操作系统: Linux(centos7, 其它操作系统也可, 安装过程类似, 可参考官方文档)</span><br><span class="line">机器配置: CPU &gt;= <span class="number">2</span>, 内存 &gt;= 2G</span><br><span class="line">从官网找到kubeadm安装文档入口, 文档很详细. 英文阅读没有障碍的读者推荐直接查看英文文档, 中文文档不全且更新不及时安装时可能存在问题.</span><br></pre></td></tr></table></figure>
<!--more-->

<h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><p>笔者已经预先安装好了两台虚拟机, centos7(CPUx2, 内存2.5G). 并在路由器上固定了这两个虚拟机的IP地址.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#修改hostname</span></span><br><span class="line">[root@k8s-master ~]$ vim /etc/hostname <span class="comment"># 修改hostname</span></span><br><span class="line">[root@k8s-master ~]$ vim /etc/hosts <span class="comment"># 将本机IP指向hostname</span></span><br><span class="line">[root@k8s-master ~]$ reboot -h      <span class="comment"># 重启(可以做完全部前期准备后再重启)</span></span><br><span class="line">修改后, 两台虚拟机的配置如下:</span><br><span class="line"></span><br><span class="line"><span class="comment"># in k8s-master</span></span><br><span class="line">[root@k8s-master ~]$ cat /etc/hostname </span><br><span class="line">k8s-master</span><br><span class="line">[root@k8s-master ~]$ cat /etc/hosts | grep k8s</span><br><span class="line"><span class="number">10.33</span><span class="number">.30</span><span class="number">.92</span> k8s-master</span><br><span class="line"><span class="number">10.33</span><span class="number">.30</span><span class="number">.91</span> k8s-worker</span><br><span class="line"></span><br><span class="line"><span class="comment"># in k8s-worker</span></span><br><span class="line">[root@k8s-worker ~]$ cat /etc/hostname </span><br><span class="line">k8s-worker</span><br><span class="line">[root@k8s-worker ~]$ cat /etc/hosts | grep k8s</span><br><span class="line"><span class="number">10.33</span><span class="number">.30</span><span class="number">.92</span> k8s-master</span><br><span class="line"><span class="number">10.33</span><span class="number">.30</span><span class="number">.91</span> k8s-worker</span><br></pre></td></tr></table></figure>
<h2 id="确认MAC和product-uuid的唯一性"><a href="#确认MAC和product-uuid的唯一性" class="headerlink" title="确认MAC和product_uuid的唯一性"></a>确认MAC和product_uuid的唯一性</h2><p>文档链接: Verify the MAC address and product_uuid are unique for every node</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ ifconfig -a    <span class="comment"># 查看MAC</span></span><br><span class="line">[root@k8s-master ~]$ cat /sys/<span class="class"><span class="keyword">class</span>/<span class="title">dmi</span>/<span class="title">id</span>/<span class="title">product_uuid</span> # 查看<span class="title">product_uuid</span></span></span><br></pre></td></tr></table></figure>
<p>注: 如果你的centos7没有ifconfig命令, 可以执行yum install net-tools进行安装.</p>
<h2 id="配置防火墙"><a href="#配置防火墙" class="headerlink" title="配置防火墙"></a>配置防火墙</h2><p>文档链接: Check required ports</p>
<p>由于是本地内网测试环境, 笔者图方便, 直接关闭了防火墙. 若安全要求较高, 可以参考官方文档放行必要端口.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ systemctl stop firewalld   <span class="comment"># 关闭服务</span></span><br><span class="line">[root@k8s-master ~]$ systemctl disable firewalld    <span class="comment"># 禁用服务</span></span><br></pre></td></tr></table></figure>
<h2 id="禁用SELinux"><a href="#禁用SELinux" class="headerlink" title="禁用SELinux"></a>禁用SELinux</h2><p>文档链接: coredns pods have CrashLoopBackOff or Error state</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">修改/etc/selinux/config, 设置SELINUX=disabled. 重启机器.</span><br><span class="line"></span><br><span class="line">[root@k8s-master ~]$ sestatus   <span class="comment"># 查看SELinux状态</span></span><br><span class="line">SELinux status: disabled</span><br></pre></td></tr></table></figure>
<h2 id="禁用交换分区"><a href="#禁用交换分区" class="headerlink" title="禁用交换分区"></a>禁用交换分区</h2><p>文档链接: Before you begin</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Swap disabled. You MUST disable swap <span class="keyword">in</span> order <span class="keyword">for</span> the kubelet to work properly.</span><br><span class="line"></span><br><span class="line">编辑/etc/fstab, 将swap注释掉. 重启机器.</span><br><span class="line"></span><br><span class="line">[root@k8s-master ~]$ vim /etc/fstab </span><br><span class="line"><span class="comment">#/dev/mapper/cl-swap     swap                    swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>
<h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><p>文档链接: Get Docker Engine – Community for CentOS</p>
<p>Docker官方文档对安装步骤描述已经足够详细, 过程并不复杂, 本文便不再赘述.</p>
<p>Docker请使用18.09, k8s暂不支持Docker最新版19.x, 安装时请按照文档描述的方式明确指定版本号yum install docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9-3.el7 containerd.io.</p>
<p>若网络不好, 可换用国内源, 阿里云、中科大等都可. 此处附上阿里云源docker安装文档地址: 容器镜像服务.</p>
<p>安装完毕后, 建议将docker源替换为国内. 推荐阿里云镜像加速, 有阿里云账号即可免费使用.阿里云 -&gt; 容器镜像服务 -&gt; 镜像中心 -&gt; 镜像加速</p>
<h2 id="配置Docker"><a href="#配置Docker" class="headerlink" title="配置Docker"></a>配置Docker</h2><p>文档地址: Container runtimes</p>
<p>修改/etc/docker/daemon.json为如下内容:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [<span class="string">&quot;https://xxxxxxxx.mirror.aliyuncs.com&quot;</span>],</span><br><span class="line">  <span class="string">&quot;exec-opts&quot;</span>: [<span class="string">&quot;native.cgroupdriver=systemd&quot;</span>],</span><br><span class="line">  <span class="string">&quot;log-driver&quot;</span>: <span class="string">&quot;json-file&quot;</span>,</span><br><span class="line">  <span class="string">&quot;log-opts&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;max-size&quot;</span>: <span class="string">&quot;100m&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;storage-driver&quot;</span>: <span class="string">&quot;overlay2&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中<a href="https://xxxxxxxx.mirror.aliyuncs.com为阿里云镜像加速地址/">https://xxxxxxxx.mirror.aliyuncs.com为阿里云镜像加速地址</a>, xxxxxxxx需要替换为自己账户中的地址. 如图:</p>
<p>安装配置完毕后执行:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ systemctl enable docker</span><br><span class="line">[root@k8s-master ~]$ systemctl start docker</span><br></pre></td></tr></table></figure>
<h1 id="安装Kubernetes"><a href="#安装Kubernetes" class="headerlink" title="安装Kubernetes"></a>安装Kubernetes</h1><p>文档地址: Installing kubeadm, kubelet and kubectl</p>
<h2 id="添加源"><a href="#添加源" class="headerlink" title="添加源"></a>添加源</h2><p>由于国内网络原因, 官方文档中的地址不可用, 本文替换为阿里云镜像地址, 执行以下代码即可:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=<span class="number">1</span></span><br><span class="line">gpgcheck=<span class="number">1</span></span><br><span class="line">repo_gpgcheck=<span class="number">1</span></span><br><span class="line">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">exclude=kube*</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br><span class="line">[root@k8s-master ~]$ systemctl enable kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure>
<h2 id="修改网络配置"><a href="#修改网络配置" class="headerlink" title="修改网络配置"></a>修改网络配置</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = <span class="number">1</span></span><br><span class="line">net.bridge.bridge-nf-call-iptables = <span class="number">1</span></span><br><span class="line">EOF</span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>
<p>注意: 至此, 以上的全部操作, 在Worker机器上也需要执行. 注意hostname等不要相同.</p>
<h2 id="初始化Master"><a href="#初始化Master" class="headerlink" title="初始化Master"></a>初始化Master</h2><p>生成初始化文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ kubeadm config <span class="built_in">print</span> init-defaults &gt; kubeadm-init.yaml</span><br></pre></td></tr></table></figure>
<p>该文件有两处需要修改:</p>
<p>将advertiseAddress: 1.2.3.4修改为本机地址<br>将imageRepository: k8s.gcr.io修改为imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers<br>修改完毕后文件如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef<span class="number">.0123456789</span>abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: <span class="number">10.33</span><span class="number">.30</span><span class="number">.92</span></span><br><span class="line">  bindPort: <span class="number">6443</span></span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: /var/run/dockershim.sock</span><br><span class="line">  name: k8s-master</span><br><span class="line">  taints:</span><br><span class="line">  - effect: NoSchedule</span><br><span class="line">    key: node-role.kubernetes.io/master</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns:</span><br><span class="line">  <span class="built_in">type</span>: CoreDNS</span><br><span class="line">etcd:</span><br><span class="line">  local:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1<span class="number">.15</span><span class="number">.0</span></span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">12</span></span><br><span class="line">scheduler: &#123;&#125;</span><br></pre></td></tr></table></figure>
<h2 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ kubeadm config images pull --config kubeadm-init.yaml</span><br></pre></td></tr></table></figure>

<h2 id="执行初始化"><a href="#执行初始化" class="headerlink" title="执行初始化"></a>执行初始化</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ kubeadm init --config kubeadm-init.yaml</span><br></pre></td></tr></table></figure>
<p>等待执行完毕后, 会输出如下内容:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line">...</span><br><span class="line">Then you can join <span class="built_in">any</span> number of worker nodes by running the following on each <span class="keyword">as</span> root:</span><br><span class="line"></span><br><span class="line">kubeadm join <span class="number">10.33</span><span class="number">.30</span><span class="number">.92</span>:<span class="number">6443</span> --token abcdef<span class="number">.0123456789</span>abcdef \</span><br><span class="line">    --discovery-token-ca-cert-<span class="built_in">hash</span> sha256:2883b1961db36593fb67ab5cd024f451b934fc0e72e2fa3858dda3ad3b225837 </span><br></pre></td></tr></table></figure>
<p>最后两行需要保存下来, kubeadm join …是worker节点加入所需要执行的命令.</p>
<p>接下来配置环境, 让当前用户可以执行kubectl命令:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
<p>测试一下: 此处的NotReady是因为网络还没配置.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master kubernetes]$ kubectl get node</span><br><span class="line">NAME         STATUS     ROLES    AGE     VERSION</span><br><span class="line">k8s-master   NotReady   master   3m25s   v1<span class="number">.15</span><span class="number">.3</span></span><br></pre></td></tr></table></figure>
<h2 id="配置网络"><a href="#配置网络" class="headerlink" title="配置网络"></a>配置网络</h2><p>文档地址: Instructions</p>
<p>下载描述文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ wget https://docs.projectcalico.org/v3<span class="number">.8</span>/manifests/calico.yaml</span><br><span class="line">[root@k8s-master ~]$ cat kubeadm-init.yaml | grep serviceSubnet:</span><br><span class="line">serviceSubnet: <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">12</span></span><br></pre></td></tr></table></figure>
<p>打开calico.yaml, 将192.168.0.0/16修改为10.96.0.0/12</p>
<p>需要注意的是, calico.yaml中的IP和kubeadm-init.yaml需要保持一致, 要么初始化前修改kubeadm-init.yaml, 要么初始化后修改calico.yaml.</p>
<p>执行kubectl apply -f calico.yaml 初始化网络.</p>
<p>此时查看node信息, master的状态已经是Ready了.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ kubectl get node</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master   Ready    master   15m   v1<span class="number">.15</span><span class="number">.3</span></span><br></pre></td></tr></table></figure>
<h2 id="安装Dashboard"><a href="#安装Dashboard" class="headerlink" title="安装Dashboard"></a>安装Dashboard</h2><p>文档地址: Web UI (Dashboard)</p>
<h2 id="部署Dashboard"><a href="#部署Dashboard" class="headerlink" title="部署Dashboard"></a>部署Dashboard</h2><p>文档地址: Deploying the Dashboard UI</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2<span class="number">.0</span><span class="number">.0</span>-beta4/aio/deploy/recommended.yaml</span><br><span class="line">[root@k8s-master ~]$ kubectl apply -f recommended.yaml </span><br></pre></td></tr></table></figure>
<p>部署完毕后, 执行kubectl get pods –all-namespaces查看pods状态</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master kubernetes]$ kubectl get pods --<span class="built_in">all</span>-namespaces | grep dashboard</span><br><span class="line">NAMESPACE              NAME                                        READY   STATUS   </span><br><span class="line">kubernetes-dashboard   dashboard-metrics-scraper-fb986f88d-m9d8z   <span class="number">1</span>/<span class="number">1</span>     Running</span><br><span class="line">kubernetes-dashboard   kubernetes-dashboard-6bb65fcc49-7s85s       <span class="number">1</span>/<span class="number">1</span>     Running </span><br></pre></td></tr></table></figure>
<h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><p>文档地址: Creating sample user</p>
<p>创建一个用于登录Dashboard的用户. 创建文件dashboard-adminuser.yaml内容如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure>
<p>执行命令kubectl apply -f dashboard-adminuser.yaml .</p>
<h2 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h2><p>文档地址: Accessing Dashboard 1.7.X and above</p>
<p>官方文档中提供了登录1.7.X以上版本的登录方式, 但并不清晰, 笔者没有完全按照该文档的方式进行操作.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master ~]$ grep <span class="string">&#x27;client-certificate-data&#x27;</span> ~/.kube/config | head -n <span class="number">1</span> | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | base64 -d &gt;&gt; kubecfg.crt</span><br><span class="line">[root@k8s-master ~]$ grep <span class="string">&#x27;client-key-data&#x27;</span> ~/.kube/config | head -n <span class="number">1</span> | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | base64 -d &gt;&gt; kubecfg.key</span><br><span class="line">[root@k8s-master ~]$ openssl pkcs12 -export -clcerts -inkey kubecfg.key -<span class="keyword">in</span> kubecfg.crt -out kubecfg.p12 -name <span class="string">&quot;kubernetes-client&quot;</span></span><br></pre></td></tr></table></figure>
<p>第三条命令生成证书时会提示输入密码, 可以直接两次回车跳过.</p>
<p>kubecfg.p12即需要导入客户端机器的证书. 将证书拷贝到客户端机器上, 导入即可.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">~$ scp root@<span class="number">10.33</span><span class="number">.30</span><span class="number">.92</span>:/root/.kube/kubecfg.p12 ./</span><br></pre></td></tr></table></figure>
<p>需要注意的是: 若生成证书时跳过了密码, 导入时提示填写密码直接回车即可, 不要纠结密码哪来的 (ﾟ▽ﾟ)/<br>此时我们可以登录面板了, 访问地址: https://{k8s-master-ip}:6443/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login, 登录时会提示选择证书, 确认后会提示输入当前用户名密码(注意是电脑的用户名密码).</p>
<h2 id="登录Dashboard"><a href="#登录Dashboard" class="headerlink" title="登录Dashboard"></a>登录Dashboard</h2><p>文档地址:Bearer Token</p>
<p>执行kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk ‘{print $1}’), 获取Token.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@k8s-master .kube]$ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>)</span><br><span class="line">Name:         admin-user-token-dhhkb</span><br><span class="line">Namespace:    kube-system</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: b20d1143-ce94-<span class="number">4379</span>-<span class="number">9e14</span>-8f80f06d8479</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     <span class="number">1025</span> <span class="built_in">bytes</span></span><br><span class="line">namespace:  <span class="number">11</span> <span class="built_in">bytes</span></span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWRoaGtiIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJiMjBkMTE0My1jZTk0LTQzNzktOWUxNC04ZjgwZjA2ZDg0NzkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.f6IbPGwIdFZWStzBj8_vmF01oWW5ccaCpPuVQNLSK1pgEqn0kNVK_x0RYSuKEnujObzpQQdFiRYcI6ITHja2PIVc5Nv83VCn5IaLvZdYuGZWUYRw0efJUBMA4J4N8-pRkiw6fYAuWLeGYghLNXL_nDdC_JkG75ASqrr3U1MVaikOcfrEPaI-T_AJ3TMYhI8aFoKiERpumu5W1K6Jl80Am9pWDX0Ywis5SSUP1VYfu-coI48EXSptcaxEyv58PrHUd6t_oMVV9rpqSxrNtMZvMeXqe8Hnl21vR7ls5yTZegYtHXSc3PKvCaIalKhYXAuhogNcIXHaMzvLSbf-DSQkVw</span><br></pre></td></tr></table></figure>
<p>复制该Token到登录页, 点击登录即可, 效果如下:</p>
<h2 id="添加Worker节点"><a href="#添加Worker节点" class="headerlink" title="添加Worker节点"></a>添加Worker节点</h2><p>重复执行 前期准备-修改hostname ~ 安装Kubernetes-修改网络配置的全部操作, 初始化一个Worker机器.</p>
<p>执行如下命令将Worker加入集群:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubeadm join <span class="number">10.33</span><span class="number">.30</span><span class="number">.92</span>:<span class="number">6443</span> --token abcdef<span class="number">.0123456789</span>abcdef \</span><br><span class="line">    --discovery-token-ca-cert-<span class="built_in">hash</span> sha256:2883b1961db36593fb67ab5cd024f451b934fc0e72e2fa3858dda3ad3b225837 </span><br><span class="line">注意: 此处的秘钥是初始化Master后生成的, 参考前文.</span><br><span class="line">添加完毕后, 在Master上查看节点状态:</span><br><span class="line"></span><br><span class="line">[root@k8s-master ~]$ kubectl get node</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION</span><br><span class="line">k8s-master   Ready    master   10h   v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">k8s-worker   Ready    &lt;none&gt;   96s   v1<span class="number">.15</span><span class="number">.3</span></span><br></pre></td></tr></table></figure>
<p>在面板上也可查看:</p>
<p>参考文献<br><a href="https://kubernetes.io/">https://kubernetes.io</a><br><a href="https://github.com/kubernetes/dashboard">https://github.com/kubernetes/dashboard</a></p>
]]></content>
      <categories>
        <category>docker</category>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes之kubectl常用命令使用指南</title>
    <url>/2016/05/25/35469/</url>
    <content><![CDATA[<p>kubectl是一个用于操作kubernetes集群的命令行接口,通过利用kubectl的各种命令可以实现各种功能,是在使用kubernetes中非常常用的工具。这里我们会通过一些简单的实例来展现其中一些高频命令的使用方法。<br>更为重要的是这些命令使用的场景以及能够解决什么样的问题。这篇文章我们来介绍一下创建和删除相关的命令。</p>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p>kubectl创建和删除相关，本文将会简单介绍一下如下命令</p>
<p>项番    命令    说明<br>No.1    run    在集群上运行一个镜像<br>No.2    create    使用文件或者标准输入的方式创建一个资源<br>No.3    delete    使用文件或者标准输入以及资源名称或者标签选择器来删除某个资源<br>事前准备</p>
<h2 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h2><p>[root@ku8-1 tmp]# kubectl version<br>Client Version: version.Info{Major:”1”, Minor:”5”, GitVersion:”v1.5.2”, GitCommit:”08e099554f3c31f6e6f07b448ab3ed78d0520507”, GitTreeState:”clean”, BuildDate:”2017-01-12T04:57:25Z”, GoVersion:”go1.7.4”, Compiler:”gc”, Platform:”linux/amd64”}<br>Server Version: version.Info{Major:”1”, Minor:”5”, GitVersion:”v1.5.2”, GitCommit:”08e099554f3c31f6e6f07b448ab3ed78d0520507”, GitTreeState:”clean”, BuildDate:”2017-01-12T04:52:34Z”, GoVersion:”go1.7.4”, Compiler:”gc”, Platform:”linux/amd64”}</p>
<p>##　集群构成<br>一主三从的Kubernetes集群</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">项番	类型	Hostname	IP</span><br><span class="line">No<span class="number">.1</span>	Master	ku8-<span class="number">1</span>	<span class="number">192.168</span><span class="number">.32</span><span class="number">.131</span></span><br><span class="line">No<span class="number">.1</span>	Node	ku8-<span class="number">2</span>	<span class="number">192.168</span><span class="number">.32</span><span class="number">.132</span></span><br><span class="line">No<span class="number">.1</span>	Node	ku8-<span class="number">3</span>	<span class="number">192.168</span><span class="number">.32</span><span class="number">.133</span></span><br><span class="line">No<span class="number">.1</span>	Node	ku8-<span class="number">4</span>	<span class="number">192.168</span><span class="number">.32</span><span class="number">.134</span></span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME             STATUS    AGE</span><br><span class="line"><span class="number">192.168</span><span class="number">.32</span><span class="number">.132</span>   Ready     12m</span><br><span class="line"><span class="number">192.168</span><span class="number">.32</span><span class="number">.133</span>   Ready     11m</span><br><span class="line"><span class="number">192.168</span><span class="number">.32</span><span class="number">.134</span>   Ready     11m</span><br></pre></td></tr></table></figure>
<p>kubectl run<br>##　运行一个镜像<br>kubectl run和docker run一样，它能将一个镜像运行起来，我们使用kubectl run来将一个sonarqube的镜像启动起来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl run sonarqube --image=192.168.32.131:5000/sonarqube:5.6.5 --replicas=1 --port=9000</span></span><br><span class="line">deployment <span class="string">&quot;sonarqube&quot;</span> created</span><br></pre></td></tr></table></figure>
<p>让我们来看看这条kubectl run之后，kubernetes做了什么，从它的提示看到创建了一个deployment（1.4之后推荐的方式）。</p>
<h2 id="确认Deployment"><a href="#确认Deployment" class="headerlink" title="确认Deployment"></a>确认Deployment</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get deployment</span></span><br><span class="line">NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">sonarqube   <span class="number">1</span>         <span class="number">1</span>         <span class="number">1</span>            <span class="number">1</span>           5m</span><br></pre></td></tr></table></figure>
<p>##　确认pod<br>kubernetes将镜像运行在pod中以方便实施卷和网络共享等管理，使用get pods可以清楚的看到生成了一个pod</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                         READY     STATUS    RESTARTS   AGE</span><br><span class="line">sonarqube-<span class="number">1880671902</span>-s3fdq   <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          6m</span><br></pre></td></tr></table></figure>
<h2 id="kubectl-delete"><a href="#kubectl-delete" class="headerlink" title="kubectl delete"></a>kubectl delete</h2><p>让我们来试着使用kubectl delete删除一下这些创建的对象</p>
<h2 id="删除pod"><a href="#删除pod" class="headerlink" title="删除pod"></a>删除pod</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl delete pods sonarqube-1880671902-s3fdq</span></span><br><span class="line">pod <span class="string">&quot;sonarqube-1880671902-s3fdq&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<h2 id="确认结果"><a href="#确认结果" class="headerlink" title="确认结果"></a>确认结果</h2><p>可以看到刚刚生成的sonarqube-1880671902-s3fdq正在结束(Terminating）,随之一个新的sonarqube-1880671902-n75d2正在创建，这是正是确保replicas为1的动作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                         READY     STATUS              RESTARTS   AGE</span><br><span class="line">sonarqube-<span class="number">1880671902</span>-n75d2   <span class="number">0</span>/<span class="number">1</span>       ContainerCreating   <span class="number">0</span>          11s</span><br><span class="line">sonarqube-<span class="number">1880671902</span>-s3fdq   <span class="number">0</span>/<span class="number">1</span>       Terminating         <span class="number">0</span>          10m</span><br></pre></td></tr></table></figure>
<h2 id="再次确认"><a href="#再次确认" class="headerlink" title="再次确认"></a>再次确认</h2><p>稍等之后再次确认，发现replicas仍然保持在1个的状态</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                         READY     STATUS    RESTARTS   AGE</span><br><span class="line">sonarqube-<span class="number">1880671902</span>-n75d2   <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          40s</span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get deployments</span></span><br><span class="line">NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">sonarqube   <span class="number">1</span>         <span class="number">1</span>         <span class="number">1</span>            <span class="number">1</span>           15m</span><br></pre></td></tr></table></figure>
<h2 id="删除deployment"><a href="#删除deployment" class="headerlink" title="删除deployment"></a>删除deployment</h2><p>直接删除pod触发了replicas的确保机制，那么我们删除deployment</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl delete deployment sonarqube</span></span><br><span class="line">deployment <span class="string">&quot;sonarqube&quot;</span> deleted</span><br></pre></td></tr></table></figure>
<h2 id="结果确认"><a href="#结果确认" class="headerlink" title="结果确认"></a>结果确认</h2><p>通过使用deployment进行删除，则全部删除。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get pods</span></span><br><span class="line">No resources found.</span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get deployments</span></span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>
<h2 id="kubectl-create"><a href="#kubectl-create" class="headerlink" title="kubectl create"></a>kubectl create</h2><p>使用kubectl run在设定很复杂的时候需要非常长的一条语句，敲半天也很容易出错，也没法保存，在碰到转义字符的时候也经常会很抓狂，所以更多场景下会使用yaml或者json文件，而使用kubectl create或者delete就可以利用这些yaml文件。<br>比如，我们使用如下的方式来分别创建mysql和sonarqube的RC。</p>
<p>事前准备</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># ls yamls</span></span><br><span class="line">mysql.yaml  sonar.yaml</span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># cat yamls/mysql.yaml </span></span><br><span class="line">---</span><br><span class="line">kind: ReplicationController</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: mysql</span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">1</span></span><br><span class="line">  selector:</span><br><span class="line">    name: mysql</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: mysql</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: mysql</span><br><span class="line">        image: <span class="number">192.168</span><span class="number">.32</span><span class="number">.131</span>:<span class="number">5000</span>/mysql:<span class="number">5.7</span><span class="number">.16</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">3306</span></span><br><span class="line">          protocol: TCP</span><br><span class="line">        env:</span><br><span class="line">          - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">            value: <span class="string">&quot;hello123&quot;</span></span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># </span></span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># cat yamls/sonar.yaml </span></span><br><span class="line">---</span><br><span class="line">kind: ReplicationController</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: sonarqube</span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">1</span></span><br><span class="line">  selector:</span><br><span class="line">    name: sonarqube</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: sonarqube</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: sonarqube</span><br><span class="line">        image: <span class="number">192.168</span><span class="number">.32</span><span class="number">.131</span>:<span class="number">5000</span>/sonarqube:<span class="number">5.6</span><span class="number">.5</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">9000</span></span><br><span class="line">          protocol: TCP</span><br></pre></td></tr></table></figure>
<h2 id="创建（MYSQL）"><a href="#创建（MYSQL）" class="headerlink" title="创建（MYSQL）"></a>创建（MYSQL）</h2><p>[root@ku8-1 tmp]# kubectl create -f yamls/mysql.yaml<br>replicationcontroller “mysql” created</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## 确认（MYSQL）</span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">[root@ku8-1 tmp]# kubectl get rc</span><br><span class="line">NAME      DESIRED   CURRENT   READY     AGE</span><br><span class="line">mysql     1         1         1         1m</span><br><span class="line">[root@ku8-1 tmp]# kubectl get pod</span><br><span class="line">NAME          READY     STATUS    RESTARTS   AGE</span><br><span class="line">mysql-nl8sq   1&#x2F;1       Running   0          1m</span><br></pre></td></tr></table></figure>
<h2 id="创建（SONARQUBE）"><a href="#创建（SONARQUBE）" class="headerlink" title="创建（SONARQUBE）"></a>创建（SONARQUBE）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl create -f yamls/sonar.yaml </span></span><br><span class="line">replicationcontroller <span class="string">&quot;sonarqube&quot;</span> created</span><br></pre></td></tr></table></figure>
<h2 id="确认（SONARQUBE）"><a href="#确认（SONARQUBE）" class="headerlink" title="确认（SONARQUBE）"></a>确认（SONARQUBE）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME              READY     STATUS    RESTARTS   AGE</span><br><span class="line">mysql-nl8sq       <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          2m</span><br><span class="line">sonarqube-p1cnj   <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          46s</span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get rc</span></span><br><span class="line">NAME        DESIRED   CURRENT   READY     AGE</span><br><span class="line">mysql       <span class="number">1</span>         <span class="number">1</span>         <span class="number">1</span>         2m</span><br><span class="line">sonarqube   <span class="number">1</span>         <span class="number">1</span>         <span class="number">1</span>         51s</span><br></pre></td></tr></table></figure>
<h2 id="删除（SONARQUBE）"><a href="#删除（SONARQUBE）" class="headerlink" title="删除（SONARQUBE）"></a>删除（SONARQUBE）</h2><p>使用yaml文件也可以直接删除所创建出来的内容，比如我们先删除刚刚创建的sonarqube相关。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl delete -f yamls/sonar.yaml </span></span><br><span class="line">replicationcontroller <span class="string">&quot;sonarqube&quot;</span> deleted</span><br></pre></td></tr></table></figure>
<h2 id="确认（SONARQUBE）-1"><a href="#确认（SONARQUBE）-1" class="headerlink" title="确认（SONARQUBE）"></a>确认（SONARQUBE）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME          READY     STATUS    RESTARTS   AGE</span><br><span class="line">mysql-nl8sq   <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          4m</span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get rc</span></span><br><span class="line">NAME      DESIRED   CURRENT   READY     AGE</span><br><span class="line">mysql     <span class="number">1</span>         <span class="number">1</span>         <span class="number">1</span>         4m</span><br></pre></td></tr></table></figure>
<h2 id="删除（MYSQL）"><a href="#删除（MYSQL）" class="headerlink" title="删除（MYSQL）"></a>删除（MYSQL）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl delete -f yamls/mysql.yaml </span></span><br><span class="line">replicationcontroller <span class="string">&quot;mysql&quot;</span> deleted</span><br></pre></td></tr></table></figure>
<h2 id="确认（MYSQL）"><a href="#确认（MYSQL）" class="headerlink" title="确认（MYSQL）"></a>确认（MYSQL）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get pods</span></span><br><span class="line">No resources found.</span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get rc</span></span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>
<h2 id="Deployment方式：准备"><a href="#Deployment方式：准备" class="headerlink" title="Deployment方式：准备"></a>Deployment方式：准备</h2><p>RC在1.4之后已经被建议用Deployment方式替换，主要只需要替换kind和apiversion和selector即可,1.5和1.6在此处也略有区别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># ls yamls/</span></span><br><span class="line">mysql.yaml  sonar.yaml</span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># cat yamls/mysql.yaml </span></span><br><span class="line">---</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: mysql</span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">1</span></span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: mysql</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: mysql</span><br><span class="line">        image: <span class="number">192.168</span><span class="number">.32</span><span class="number">.131</span>:<span class="number">5000</span>/mysql:<span class="number">5.7</span><span class="number">.16</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">3306</span></span><br><span class="line">          protocol: TCP</span><br><span class="line">        env:</span><br><span class="line">          - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">            value: <span class="string">&quot;hello123&quot;</span></span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># </span></span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># cat yamls/sonar.yaml </span></span><br><span class="line">---</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: sonarqube</span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">1</span></span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: sonarqube</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: sonarqube</span><br><span class="line">        image: <span class="number">192.168</span><span class="number">.32</span><span class="number">.131</span>:<span class="number">5000</span>/sonarqube:<span class="number">5.6</span><span class="number">.5</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">9000</span></span><br><span class="line">          protocol: TCP</span><br></pre></td></tr></table></figure>
<h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><p>有多个yaml文件的时候，可以使用如下方式一下全部创建</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl create -f yamls/</span></span><br><span class="line">deployment <span class="string">&quot;mysql&quot;</span> created</span><br><span class="line">deployment <span class="string">&quot;sonarqube&quot;</span> created</span><br></pre></td></tr></table></figure>
<h2 id="确认"><a href="#确认" class="headerlink" title="确认"></a>确认</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                         READY     STATUS    RESTARTS   AGE</span><br><span class="line">mysql-<span class="number">478535978</span>-2l7kq        <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          3m</span><br><span class="line">sonarqube-<span class="number">3574384362</span>-x3mg2   <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          3m</span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get deployments</span></span><br><span class="line">NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">mysql       <span class="number">1</span>         <span class="number">1</span>         <span class="number">1</span>            <span class="number">1</span>           3m</span><br><span class="line">sonarqube   <span class="number">1</span>         <span class="number">1</span>         <span class="number">1</span>            <span class="number">1</span>           3m</span><br></pre></td></tr></table></figure>
<h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><p>同样，有多个yaml文件的时候，可以使用如下方式一下全部删除</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl delete -f yamls/</span></span><br><span class="line">deployment <span class="string">&quot;mysql&quot;</span> deleted</span><br><span class="line">deployment <span class="string">&quot;sonarqube&quot;</span> deleted</span><br></pre></td></tr></table></figure>
<h2 id="确认-1"><a href="#确认-1" class="headerlink" title="确认"></a>确认</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get pods</span></span><br><span class="line">No resources found.</span><br><span class="line">[root@ku8-<span class="number">1</span> tmp]<span class="comment"># kubectl get deployments</span></span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>
<p>总结<br>这篇文章通过几个最简单的命令熟悉了如何使用kubectl对镜像进行创建和删除，在后面我们会进一步介绍一些常用的命令。</p>
<p>更多总结可参看：<br><a href="https://liumiaocn.blog.csdn.net/article/details/88413428">https://liumiaocn.blog.csdn.net/article/details/88413428</a></p>
]]></content>
      <categories>
        <category>k8s</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB提升性能的18原则（开发设计阶段）</title>
    <url>/2020/07/24/62356/</url>
    <content><![CDATA[<h3 id="摘要：做一个有原则的程序员。"><a href="#摘要：做一个有原则的程序员。" class="headerlink" title="摘要：做一个有原则的程序员。"></a>摘要：做一个有原则的程序员。</h3><p>MongoDB 是高性能数据，但是在使用的过程中，大家偶尔还会碰到一些性能问题。MongoDB和其它关系型数据库相比，例如 SQL Server 、MySQL 、Oracle 相比来说，相对较新，很多人对其不是很熟悉，所以很多开发、DBA往往是注重功能的实现，而忽视了性能的要求。其实，MongoDB和 SQL Server 、MySQL 、Oracle 一样，一个 数据库对象的设计调整、索引的创建、语句的优化，都会对性能产生巨大的影响。</p>
<p>为了充分挖掘MongoDB性能，现简单总计了以下18条，欢迎大家一起来持续总结完善。</p>
<h2 id="（1）文档中的-id键推荐使用默认值，禁止向-id中保存自定义的值。"><a href="#（1）文档中的-id键推荐使用默认值，禁止向-id中保存自定义的值。" class="headerlink" title="（1）文档中的_id键推荐使用默认值，禁止向_id中保存自定义的值。"></a>（1）文档中的_id键推荐使用默认值，禁止向_id中保存自定义的值。</h2><p>​解读： MongoDB文档中都会有一个“_id”键，默认是个ObjectID对象（标识符中包含时间戳、机器ID、进程ID和计数器）。MongoDB在指定_id与不指定_id插入时 速度相差很大，指定_id会减慢插入的速率。<br>​</p>
<h2 id="（2）推荐使用短字段名。"><a href="#（2）推荐使用短字段名。" class="headerlink" title="（2）推荐使用短字段名。"></a>（2）推荐使用短字段名。</h2><p>​解读：与关系型数据库不同，MongoDB集合中的每一个文档都需要存储字段名，长字段名会需要更多的存储空间。</p>
<h2 id="（3）MongoDB索引可以提高文档的查询、更新、删除、排序操作，所以结合业务需求，适当创建索引。"><a href="#（3）MongoDB索引可以提高文档的查询、更新、删除、排序操作，所以结合业务需求，适当创建索引。" class="headerlink" title="（3）MongoDB索引可以提高文档的查询、更新、删除、排序操作，所以结合业务需求，适当创建索引。"></a>（3）MongoDB索引可以提高文档的查询、更新、删除、排序操作，所以结合业务需求，适当创建索引。</h2><h2 id="（4）每个索引都会占用一些空间，并且导致插入操作的资源消耗，因此，建议每个集合的索引数尽量控制在5个以内。"><a href="#（4）每个索引都会占用一些空间，并且导致插入操作的资源消耗，因此，建议每个集合的索引数尽量控制在5个以内。" class="headerlink" title="（4）每个索引都会占用一些空间，并且导致插入操作的资源消耗，因此，建议每个集合的索引数尽量控制在5个以内。"></a>（4）每个索引都会占用一些空间，并且导致插入操作的资源消耗，因此，建议每个集合的索引数尽量控制在5个以内。</h2><h2 id="（5）对于包含多个键的查询，创建包含这些键的复合索引是个不错的解决方案。复合索引的键值顺序很重要，理解索引最左前缀原则。"><a href="#（5）对于包含多个键的查询，创建包含这些键的复合索引是个不错的解决方案。复合索引的键值顺序很重要，理解索引最左前缀原则。" class="headerlink" title="（5）对于包含多个键的查询，创建包含这些键的复合索引是个不错的解决方案。复合索引的键值顺序很重要，理解索引最左前缀原则。"></a>（5）对于包含多个键的查询，创建包含这些键的复合索引是个不错的解决方案。复合索引的键值顺序很重要，理解索引最左前缀原则。</h2><p>解读：例如在test集合上创建组合索引{a:1,b:1,c:1}。执行以下7个查询语句：</p>
<p>db.test.find({a:”hello”}) // 1<br>db.test.find({b:”sogo”, a:”hello”}) // 2<br>db.test.find({a:”hello”,b:”sogo”, c:”666”}) // 3<br>db.test.find({c:”666”, a:”hello”}) // 4<br>db.test.find({b:”sogo”, c:”666”}) // 5<br>db.test.find({b:”sogo” }) // 6<br>db.test.find({c:”666”}) // 7<br>以上查询语句可能走索引的是1、2、3、4<br>查询应包含最左索引字段，以索引创建顺序为准，与查询字段顺序无关。<br>最少索引覆盖最多查询。</p>
<h2 id="（6）TTL-索引（time-to-live-index，具有生命周期的索引），使用TTL索引可以将超时时间的文档老化，一个文档到达老化的程度之后就会被删除。"><a href="#（6）TTL-索引（time-to-live-index，具有生命周期的索引），使用TTL索引可以将超时时间的文档老化，一个文档到达老化的程度之后就会被删除。" class="headerlink" title="（6）TTL 索引（time-to-live index，具有生命周期的索引），使用TTL索引可以将超时时间的文档老化，一个文档到达老化的程度之后就会被删除。"></a>（6）TTL 索引（time-to-live index，具有生命周期的索引），使用TTL索引可以将超时时间的文档老化，一个文档到达老化的程度之后就会被删除。</h2><p>解读：创建TTL的索引必须是日期类型。TTL索引是一种单字段索引，不能是复合索引。TTL删除文档后台线程每60s移除失效文档。不支持定长集合。</p>
<h2 id="（7）需要在集合中某字段创建索引，但集合中大量的文档不包含此键值时，建议创建稀疏索引。"><a href="#（7）需要在集合中某字段创建索引，但集合中大量的文档不包含此键值时，建议创建稀疏索引。" class="headerlink" title="（7）需要在集合中某字段创建索引，但集合中大量的文档不包含此键值时，建议创建稀疏索引。"></a>（7）需要在集合中某字段创建索引，但集合中大量的文档不包含此键值时，建议创建稀疏索引。</h2><p>解读：索引默认是密集型的，这意味着，即使文档的索引字段缺失，在索引中也存在着一个对应关系。在稀疏索引中，只有包含了索引键值的文档才会出现。</p>
<h2 id="（8）创建文本索引时字段指定text，而不是1或者-1。每个集合只有一个文本索引，但是它可以为任意多个字段建立索引。"><a href="#（8）创建文本索引时字段指定text，而不是1或者-1。每个集合只有一个文本索引，但是它可以为任意多个字段建立索引。" class="headerlink" title="（8）创建文本索引时字段指定text，而不是1或者-1。每个集合只有一个文本索引，但是它可以为任意多个字段建立索引。"></a>（8）创建文本索引时字段指定text，而不是1或者-1。每个集合只有一个文本索引，但是它可以为任意多个字段建立索引。</h2><p>解读：文本搜索速度快很多，推荐使用文本索引替代对集合文档的多字段的低效查询。</p>
<h2 id="（9）使用findOne在数据库中查询匹配多个项目，它就会在自然排序文件集合中返回第一个项目。如果需要返回多个文档，则使用find方法。"><a href="#（9）使用findOne在数据库中查询匹配多个项目，它就会在自然排序文件集合中返回第一个项目。如果需要返回多个文档，则使用find方法。" class="headerlink" title="（9）使用findOne在数据库中查询匹配多个项目，它就会在自然排序文件集合中返回第一个项目。如果需要返回多个文档，则使用find方法。"></a>（9）使用findOne在数据库中查询匹配多个项目，它就会在自然排序文件集合中返回第一个项目。如果需要返回多个文档，则使用find方法。</h2><h2 id="（10）如果查询无需返回整个文档或只是用来判断键值是否存在，可以通过投影（映射）来限制返回字段，减少网络流量和客户端的内存使用。"><a href="#（10）如果查询无需返回整个文档或只是用来判断键值是否存在，可以通过投影（映射）来限制返回字段，减少网络流量和客户端的内存使用。" class="headerlink" title="（10）如果查询无需返回整个文档或只是用来判断键值是否存在，可以通过投影（映射）来限制返回字段，减少网络流量和客户端的内存使用。"></a>（10）如果查询无需返回整个文档或只是用来判断键值是否存在，可以通过投影（映射）来限制返回字段，减少网络流量和客户端的内存使用。</h2><p>解读：既可以通过设置{key:1}来显式指定返回的字段，也可以设置{key:0}指定需要排除的字段。</p>
<h2 id="（11）除了前缀样式查询，正则表达式查询不能使用索引，执行的时间比大多数选择器更长，应节制性地使用它们。"><a href="#（11）除了前缀样式查询，正则表达式查询不能使用索引，执行的时间比大多数选择器更长，应节制性地使用它们。" class="headerlink" title="（11）除了前缀样式查询，正则表达式查询不能使用索引，执行的时间比大多数选择器更长，应节制性地使用它们。"></a>（11）除了前缀样式查询，正则表达式查询不能使用索引，执行的时间比大多数选择器更长，应节制性地使用它们。</h2><h2 id="（12）在聚合运算中，-要在match要在-group前面，通过-前置，可以减少match前置，可以减少-group-操作符要处理的文档数量。"><a href="#（12）在聚合运算中，-要在match要在-group前面，通过-前置，可以减少match前置，可以减少-group-操作符要处理的文档数量。" class="headerlink" title="（12）在聚合运算中，$要在match要在$group前面，通过$前置，可以减少match前置，可以减少$ group 操作符要处理的文档数量。"></a>（12）在聚合运算中，$要在match要在$group前面，通过$前置，可以减少match前置，可以减少$ group 操作符要处理的文档数量。</h2><h2 id="（13）通过操作符对文档进行修改，通常可以获得更好的性能，因为，不需要往返服务器来获取并修改文档数据，可以在序列化和传输数据上花费更少的时间。"><a href="#（13）通过操作符对文档进行修改，通常可以获得更好的性能，因为，不需要往返服务器来获取并修改文档数据，可以在序列化和传输数据上花费更少的时间。" class="headerlink" title="（13）通过操作符对文档进行修改，通常可以获得更好的性能，因为，不需要往返服务器来获取并修改文档数据，可以在序列化和传输数据上花费更少的时间。"></a>（13）通过操作符对文档进行修改，通常可以获得更好的性能，因为，不需要往返服务器来获取并修改文档数据，可以在序列化和传输数据上花费更少的时间。</h2><h2 id="（14）批量插入（batchInsert）可以减少数据向服务器的提交次数，提高性能。但是批量提交的BSON-Size不超过48MB。"><a href="#（14）批量插入（batchInsert）可以减少数据向服务器的提交次数，提高性能。但是批量提交的BSON-Size不超过48MB。" class="headerlink" title="（14）批量插入（batchInsert）可以减少数据向服务器的提交次数，提高性能。但是批量提交的BSON Size不超过48MB。"></a>（14）批量插入（batchInsert）可以减少数据向服务器的提交次数，提高性能。但是批量提交的BSON Size不超过48MB。</h2><h2 id="（15）禁止一次取出太多的数据进行排序，MongoDB目前支持对32M以内的结果集进行排序。如果需要排序，请尽量限制结果集中的数据量。"><a href="#（15）禁止一次取出太多的数据进行排序，MongoDB目前支持对32M以内的结果集进行排序。如果需要排序，请尽量限制结果集中的数据量。" class="headerlink" title="（15）禁止一次取出太多的数据进行排序，MongoDB目前支持对32M以内的结果集进行排序。如果需要排序，请尽量限制结果集中的数据量。"></a>（15）禁止一次取出太多的数据进行排序，MongoDB目前支持对32M以内的结果集进行排序。如果需要排序，请尽量限制结果集中的数据量。</h2><h2 id="（16）查询中的某些-操作符可能会导致性能低下，如操作符可能会导致性能低下，如-ne，-，not，-exists，-nin，-or尽量在业务中不要使用。"><a href="#（16）查询中的某些-操作符可能会导致性能低下，如操作符可能会导致性能低下，如-ne，-，not，-exists，-nin，-or尽量在业务中不要使用。" class="headerlink" title="（16）查询中的某些$操作符可能会导致性能低下，如操作符可能会导致性能低下，如$ne，$，not，$exists，$nin，$or尽量在业务中不要使用。"></a>（16）查询中的某些$操作符可能会导致性能低下，如操作符可能会导致性能低下，如$ne，$，not，$exists，$nin，$or尽量在业务中不要使用。</h2><p>a) $exist:因为松散的文档结构导致查询必须遍历每一个文档；<br>b) $ne:如果当取反的值为大多数，则会扫描整个索引；<br>c) $not:可能会导致查询优化器不知道应当使用哪个索引，所以会经常退化为全表扫描；<br>d) $nin:全表扫描；<br>e) $有多个条件就会查询多少次，最后合并结果集，应该考虑装换为or:有多个条件就会查询多少次，最后合并结果集，应该考虑装换为$in。</p>
<h2 id="17）固定集合可以用于记录日志，其插入数据更快，可以实现在插入数据时，淘汰最早的数据。需求分析和设计时，可考虑此特性，即提高了性能，有省去了删除动作。"><a href="#17）固定集合可以用于记录日志，其插入数据更快，可以实现在插入数据时，淘汰最早的数据。需求分析和设计时，可考虑此特性，即提高了性能，有省去了删除动作。" class="headerlink" title="17）固定集合可以用于记录日志，其插入数据更快，可以实现在插入数据时，淘汰最早的数据。需求分析和设计时，可考虑此特性，即提高了性能，有省去了删除动作。"></a>17）固定集合可以用于记录日志，其插入数据更快，可以实现在插入数据时，淘汰最早的数据。需求分析和设计时，可考虑此特性，即提高了性能，有省去了删除动作。</h2><p>​解读：固定集合需要显式创建，指定Size的大小，还能够指定文档的数量。集合不管先达到哪一个限制，之后插入的新文档都会把最老的文档移出。</p>
<h2 id="（18）集合中文档的数据量会影响查询性能，为保持适量，需要定期归档"><a href="#（18）集合中文档的数据量会影响查询性能，为保持适量，需要定期归档" class="headerlink" title="（18）集合中文档的数据量会影响查询性能，为保持适量，需要定期归档"></a>（18）集合中文档的数据量会影响查询性能，为保持适量，需要定期归档</h2><p>转载时请注明作者 <a href="https://blog.fundebug.com/2018/09/19/18-principle-to-improve-mongodb-performance">Fundebug</a></p>
]]></content>
      <categories>
        <category>Mongo</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB索引管理——创建索引，查看索引，删除索引，重建索引</title>
    <url>/2020/07/24/38321/</url>
    <content><![CDATA[<p><a href="https://blog.51cto.com/navyaijm/2421973?source=drh">Mongodb性能压测</a></p>
<h3 id="先给users集合插入两条记录，然后用users集合来进行索引管理的演示："><a href="#先给users集合插入两条记录，然后用users集合来进行索引管理的演示：" class="headerlink" title="先给users集合插入两条记录，然后用users集合来进行索引管理的演示："></a>先给users集合插入两条记录，然后用users集合来进行索引管理的演示：</h3><pre><code class="bash">&gt; user1=&#123;&quot;name&quot;:&quot;liming&quot;,&quot;age&quot;:20,&quot;gender&quot;:&quot;F&quot;&#125;
&#123; &quot;name&quot; : &quot;liming&quot;, &quot;age&quot; : 20, &quot;gender&quot; : &quot;F&quot; &#125;
&gt; db.users.insert(user1)
WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)
&gt; user2=&#123;&quot;name&quot;:&quot;zhangsan&quot;,&quot;age&quot;:25,&quot;gender&quot;:&quot;F&quot;&#125;
&#123; &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 25, &quot;gender&quot; : &quot;F&quot; &#125;
&gt; db.users.insert(user1)
WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)
&gt; db.users.count()</code></pre>
<h2 id="2-创建索引："><a href="#2-创建索引：" class="headerlink" title="2 创建索引："></a>2 创建索引：</h2><p>mongodb使用createIndex()和ensureIndex()方法来创建索引，前者用于3.0及以上版本，后者用于3.0以下版本。<br>语法：<br>db.COLLECTION_NAME.ensureIndex(keys[,options])<br>keys:要建立索引的参数列表。如：{KEY:1}，其中key表示字段名，1表示升序排序，也可使用使用数字-1降序。<br>options:可选参数，表示建立索引的设置。可选值如下：<br>background，Boolean，在后台建立索引，以便建立索引时不阻止其他数据库活动。默认值为false。<br>unique，Boolean，创建唯一索引。默认值 false。<br>name，String，指定索引的名称。如果未指定，MongoDB会生成一个索引字段的名称和排序顺序串联。<br>partialFilterExpression, document.如果指定,MongoDB只会给满足过滤表达式的记录建立索引.<br>sparse，Boolean，对文档中不存在的字段数据不启用索引。默认值是 false。<br>expireAfterSeconds,integer,指定索引的过期时间<br>storageEngine,document,允许用户配置索引的存储引擎</p>
<pre><code class="bash">&gt; db.users.createIndex(&#123;&quot;name&quot;:1&#125;)
&#123;
    &quot;createdCollectionAutomatically&quot; : false,
    &quot;numIndexesBefore&quot; : 1,
    &quot;numIndexesAfter&quot; : 2,
    &quot;ok&quot; : 1
&#125;</code></pre>
<p>例2：给name字段创建倒序索引</p>
<pre><code class="bash">&gt; db.users.createIndex(&#123;&quot;name&quot;:-1&#125;)
&#123;
    &quot;createdCollectionAutomatically&quot; : false,
    &quot;numIndexesBefore&quot; : 2,
    &quot;numIndexesAfter&quot; : 3,
    &quot;ok&quot; : 1
&#125;</code></pre>
<p>例3：给name，age字段创建组合索引</p>
<pre><code class="bash">&gt; db.users.createIndex(&#123;&quot;name&quot;:1,&quot;age&quot;:1&#125;)
&#123;
    &quot;createdCollectionAutomatically&quot; : false,
    &quot;numIndexesBefore&quot; : 3,
    &quot;numIndexesAfter&quot; : 4,
    &quot;ok&quot; : 1
&#125;</code></pre>
<p>例4：在后台给age字段创建索引</p>
<pre><code class="bash">&gt; db.users.createIndex(&#123;age:1&#125;,&#123;background:1&#125;)
&#123;
    &quot;createdCollectionAutomatically&quot; : false,
    &quot;numIndexesBefore&quot; : 4,
    &quot;numIndexesAfter&quot; : 5,
    &quot;ok&quot; : 1
&#125;``` 
### 在后台创建索引的原因：
在前台创建索引期间会锁定数据库，会导致其它操作无法进行数据读写，在后台创建索引是，会定期释放写锁，从而保证其它操作的运行，但是后台操作会在耗时更长，尤其是在频繁进行写入的服务器上。

##　查看索引：
MongoDB提供的查看索引信息的方法：
getIndexes()方法可以用来查看集合的所有索引，
getIndexKeys()方法查看索引键。
totalIndexSize()查看集合索引的总大小，
getIndexSpecs()方法查看集合各索引的详细信息
例1： getIndexes()的用法
``` bash
&gt; db.users.getIndexes()
[
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;_id&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;_id_&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;name&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;name_1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;name&quot; : -1
        &#125;,
        &quot;name&quot; : &quot;name_-1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;name&quot; : 1,
            &quot;age&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;name_1_age_1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;age&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;age_1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;,
        &quot;background&quot; : 1
    &#125;
]</code></pre>
<p>例2：getIndexKeys()的用法</p>
<pre><code class="bash">&gt; db.users.getIndexKeys()
[
    &#123;
        &quot;_id&quot; : 1
    &#125;,
    &#123;
        &quot;name&quot; : 1
    &#125;,
    &#123;
        &quot;name&quot; : -1
    &#125;,
    &#123;
        &quot;name&quot; : 1,
        &quot;age&quot; : 1
    &#125;,
    &#123;
        &quot;age&quot; : 1
    &#125;
]</code></pre>
<p>例3：totalIndexSize()的用法</p>
<blockquote>
<p>db.users.totalIndexSize()<br>81920<br>例4：getIndexSpecs()的用法</p>
</blockquote>
<pre><code class="bash">&gt; db.users.getIndexSpecs()
[
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;_id&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;_id_&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;name&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;name_1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;name&quot; : -1
        &#125;,
        &quot;name&quot; : &quot;name_-1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;name&quot; : 1,
            &quot;age&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;name_1_age_1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;age&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;age_1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;,
        &quot;background&quot; : 1
    &#125;
]</code></pre>
<h2 id="删除索引："><a href="#删除索引：" class="headerlink" title="删除索引："></a>删除索引：</h2><p>不再需要的索引，我们可以将其删除，mongodb提供两种删除索引的方法：<br>dropIndex()方法用于删除指定的索引<br>dropIndexes()方法用于删除全部的索引<br>例1:dropIndex()的用法</p>
<pre><code class="bash">&gt; db.users.dropIndex(&quot;name_1&quot;)
&#123; &quot;nIndexesWas&quot; : 5, &quot;ok&quot; : 1 &#125;
&gt; db.users.dropIndex(&quot;name_1_age_1&quot;)
&#123; &quot;nIndexesWas&quot; : 4, &quot;ok&quot; : 1 &#125;
&gt; db.users.getIndexSpecs()
[
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;_id&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;_id_&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;name&quot; : -1
        &#125;,
        &quot;name&quot; : &quot;name_-1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;age&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;age_1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;,
        &quot;background&quot; : 1
    &#125;
]</code></pre>
<p>我们可以看到,name字段的索引和name与age字段的组合索引皆被删除</p>
<p>例2:dropIndexes()的用法</p>
<pre><code class="bash">&gt; db.users.dropIndexes()
&#123;
    &quot;nIndexesWas&quot; : 3,
    &quot;msg&quot; : &quot;non-_id indexes dropped for collection&quot;,
    &quot;ok&quot; : 1
&#125;</code></pre>
<pre><code class="bash">&gt; db.users.getIndexSpecs()
[
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;_id&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;_id_&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;
]</code></pre>
<p>在使用了dropIndexes()方法后,我们之前建的所有索引都被删除掉了</p>
<h2 id="索引重建"><a href="#索引重建" class="headerlink" title="索引重建:"></a>索引重建:</h2><p>我们之前把users的索引全部删除了,现在在name字段上建立一个正序索引,然后在name字段上重建倒序索引,可以看到重建索引是把之前name字段的索引删掉再新建一个索引的,重建之前name字段还是只有一个索引.</p>
<pre><code class="bash">&gt; db.users.createIndex(&#123;name:1&#125;)
&#123;
    &quot;createdCollectionAutomatically&quot; : false,
    &quot;numIndexesBefore&quot; : 1,
    &quot;numIndexesAfter&quot; : 2,
    &quot;ok&quot; : 1
&#125;</code></pre>
<pre><code class="bash">&gt; db.users.getIndexSpecs()
[
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;_id&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;_id_&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;name&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;name_1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;
]</code></pre>
<pre><code class="bash">&gt; db.users.reIndex(&#123;name:-1&#125;)
&#123;
    &quot;nIndexesWas&quot; : 2,
    &quot;nIndexes&quot; : 2,
    &quot;indexes&quot; : [
        &#123;
            &quot;key&quot; : &#123;
                &quot;_id&quot; : 1
            &#125;,
            &quot;name&quot; : &quot;_id_&quot;,
            &quot;ns&quot; : &quot;test1.users&quot;
        &#125;,
        &#123;
            &quot;key&quot; : &#123;
                &quot;name&quot; : 1
            &#125;,
            &quot;name&quot; : &quot;name_1&quot;,
            &quot;ns&quot; : &quot;test1.users&quot;
        &#125;
    ],
    &quot;ok&quot; : 1
&#125;</code></pre>
<pre><code class="bash">&gt; db.users.getIndexSpecs()
[
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;_id&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;_id_&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;,
    &#123;
        &quot;v&quot; : 1,
        &quot;key&quot; : &#123;
            &quot;name&quot; : 1
        &#125;,
        &quot;name&quot; : &quot;name_1&quot;,
        &quot;ns&quot; : &quot;test1.users&quot;
    &#125;
]</code></pre>
]]></content>
      <categories>
        <category>Mongo</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>Mongodb性能压测</title>
    <url>/2020/07/24/48737/</url>
    <content><![CDATA[<h2 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h2><p>这几天对所有的基础组件做一个摸底的基准压力测试，目前我们所有的开源基础组件都没有做过性能测试，经常有开发人员问，我们的RDS、MongoDB集群能抗多大量呀，这个时候我是没办法回复的，因为我自己也不知道，虽然一个数据库集群能抗多大量，在软件、硬件配置固定的情况下，和业务场景有很大的关系，如果数据量小，查询SQL简单那吞吐量自然很高，如果数据量特别大并且都是复杂SQL，那吞吐量自然上不去；但是既然人家问了，肯定是希望有一个答案，如果你说不知道，那会给人一种不靠谱的感觉，所以做一次基准压力测试，我们知道在特定的场景下我们的集群能有多大的吞吐量，做到自己心里有数，才给别人信心。这周在压测MongoDB，谷歌了一番，MongoDB的压测工具很少，有几篇是介绍通过YCSB压测MongoDB的，找（逻辑思维首席DBA）推荐一款MongoDB的压测工具，也推荐YCSB，好吧，那就它吧，开整。</p>
<h2 id="二、环境说明"><a href="#二、环境说明" class="headerlink" title="二、环境说明"></a>二、环境说明</h2><pre><code class="bash">1、MongoDB集群配置（一个分片的shard集群）
Mongodb性能压测

2、MongoDB版本
4.0.4-62-g7e345a7
4、系统及内核版本


CentOS Linux release 7.5.1804 (Core)
3.10.0-862.14.4.el7.x86_64
3、YCSB版本
YCSB-0.16.0-RC1.

4、测试说明
Mongodb性能压测</code></pre>
<h2 id="三、安装"><a href="#三、安装" class="headerlink" title="三、安装"></a>三、安装</h2><p>1、jdk及maven安装参考官方<br><a href="https://github.com/brianfrankcooper/YCSB/tree/master/mongodb">https://github.com/brianfrankcooper/YCSB/tree/master/mongodb</a></p>
<p>2、安装YCSB<br>wget <a href="https://github.com/brianfrankcooper/YCSB/archive/0.16.0-RC1.tar.gz">https://github.com/brianfrankcooper/YCSB/archive/0.16.0-RC1.tar.gz</a><br>tar -zxvf YCSB-0.16.0-RC1.tar.gz<br>cd YCSB-0.16.0-RC1/<br>mvn clean package -Dmaven.test.skip=true<br>PS：<br>安装过程中maven下载依赖需要×××，如果有安装失败的包，需要在能×××的服务器上下载手动安装，比如mongodb-async-driver-2.0.1.jar就需要×××，下面是手动安装方法<br>A、手动下载jar包<br>wget <a href="http://www.allanbank.com/repo/com/allanbank/mongodb-async-driver/2.0.1/mongodb-async-driver-2.0.1.jar">http://www.allanbank.com/repo/com/allanbank/mongodb-async-driver/2.0.1/mongodb-async-driver-2.0.1.jar</a><br>B、加压包，从pom.xml 文件里面查看groupId、artifactId、version<br>C、手动安装</p>
<pre><code class="bash">mvn install:install-file -Dfile=/tmp/mongodb-async-driver-2.0.1.jar  -DgroupId=com.allanbank -DartifactId=mongodb-async-driver -Dversion=2.0.1 -Dpackaging=jar
mvn -pl com.yahoo.ycsb:mongodb-binding -am clean package</code></pre>
<h2 id="四、压测"><a href="#四、压测" class="headerlink" title="四、压测"></a>四、压测</h2><p>1、编写压测文件</p>
<h1 id="YCSB-测试需要python2-7环境-可以使用conda-create-n-venv-python-2-7-创建-link"><a href="#YCSB-测试需要python2-7环境-可以使用conda-create-n-venv-python-2-7-创建-link" class="headerlink" title="YCSB  测试需要python2.7环境  可以使用conda create -n venv python=2.7 创建  link"></a>YCSB  测试需要python2.7环境  可以使用conda create -n venv python=2.7 创建  <a href="https://blog.csdn.net/sirobot/article/details/107067577">link</a></h1><p>在workloads目录下有很多压测文件用到的文件，我们从其中一个copy一份，编辑添加我们自己定义的内容</p>
<pre><code class="bash">vim workloads/2000w

ongodb.url=mongodb://root:123456@172.21.244.101:27000
mongodb.writeConcern=normal
table=chj_2000w
recordcount=20000000
operationcount=50000000
readallfields=true
readproportion=0
updateproportion=0
scanproportion=0
insertproportion=1
requestdistribution=zipfian
workload=com.yahoo.ycsb.workloads.CoreWorkload</code></pre>
<pre><code class="bash">关于YCSB的压测文件的每个参数的解释如下：

fieldcount: 每条记录字段个数 (default: 10)
fieldlength: 每个字段长度 (default: 100)
readallfields: 是否读取所有字段true或者读取一个字段false (default: true)
readproportion: 读取作业比例 (default: 0.95)
updateproportion: 更新作业比例 (default: 0.05)
insertproportion: 插入作业比例 (default: 0)
scanproportion: 扫描作业比例 (default: 0)
readmodifywriteproportion: 读取一条记录修改它并写回的比例 (default: 0)
requestdistribution: 请求的分布规则 uniform, zipfian or latest (default: uniform)
maxscanlength: 扫描作业最大记录数 (default: 1000)
scanlengthdistribution: 在1和最大扫描记录数的之间的分布规则 (default: uniform)
insertorder: 记录被插入的规则ordered或者hashed (default: hashed)
operationcount: 执行的操作数.
maxexecutiontime: 执行操作的最长时间，当然如果没有超过这个时间以运行时间为主。
table: 测试表的名称 (default: usertable)
recordcount: 加载到数据库的纪录条数 (default: 0)</code></pre>
<p>2、造数据，也是测写入性能</p>
<pre><code class="bash">./bin/ycsb load mongodb -threads 100 -P workloads/2000w</code></pre>
<p>输出结果说明</p>
<pre><code class="bash">[OVERALL], RunTime(ms), 37182  #数据加载所用时间(毫秒)
[OVERALL], Throughput(ops/sec), 13447.367005540314  #加载操作的吞吐量(ops/sec)
[TOTAL_GCS_PS_Scavenge], Count, 37
[TOTAL_GC_TIME_PS_Scavenge], Time(ms), 146
[TOTAL_GC_TIME_%_PS_Scavenge], Time(%), 0.3926631165617772
[TOTAL_GCS_PS_MarkSweep], Count, 0
[TOTAL_GC_TIME_PS_MarkSweep], Time(ms), 0
[TOTAL_GC_TIME_%_PS_MarkSweep], Time(%), 0.0
[TOTAL_GCs], Count, 37
[TOTAL_GC_TIME], Time(ms), 146
[TOTAL_GC_TIME_%], Time(%), 0.3926631165617772
[CLEANUP], Operations, 64
[CLEANUP], AverageLatency(us), 422.09375
[CLEANUP], MinLatency(us), 0
[CLEANUP], MaxLatency(us), 26911
[CLEANUP], 95thPercentileLatency(us), 3
[CLEANUP], 99thPercentileLatency(us), 30
[INSERT], Operations, 500000  # 执行insert操作的总数
[INSERT], AverageLatency(us), 4658.931652  # 每次insert操作的平均延时(微秒)
[INSERT], MinLatency(us), 831 # 所有insert操作的最小延时(微秒)
[INSERT], MaxLatency(us), 1784831 # 所有insert操作的最大延时(微秒)
[INSERT], 95thPercentileLatency(us), 9711  # 95%的insert操作延时在9毫秒以内
[INSERT], 99thPercentileLatency(us), 17903 # 99%的insert操作延时在17毫秒以内
[INSERT], Return=OK, 500000</code></pre>
<p>3、压测<br>通过调整压测文件中read和update的比例，模拟只读和读写混合的操作</p>
<pre><code class="bash">./bin/ycsb run mongodb -threads 100 -P workloads/2000w

[OVERALL], RunTime(ms), 1735408
[OVERALL], Throughput(ops/sec), 2881.1668495247227
[TOTAL_GCS_PS_Scavenge], Count, 3975
[TOTAL_GC_TIME_PS_Scavenge], Time(ms), 6180
[TOTAL_GC_TIME_%_PS_Scavenge], Time(%), 0.3561122226012557
[TOTAL_GCS_PS_MarkSweep], Count, 0
[TOTAL_GC_TIME_PS_MarkSweep], Time(ms), 0
[TOTAL_GC_TIME_%_PS_MarkSweep], Time(%), 0.0
[TOTAL_GCs], Count, 3975
[TOTAL_GC_TIME], Time(ms), 6180
[TOTAL_GC_TIME_%], Time(%), 0.3561122226012557
[READ], Operations, 500346
[READ], AverageLatency(us), 2851.9638989819045
[READ], MinLatency(us), 696
[READ], MaxLatency(us), 646655
[READ], 95thPercentileLatency(us), 6991
[READ], 99thPercentileLatency(us), 23103
[READ], Return=OK, 500346
[CLEANUP], Operations, 10
[CLEANUP], AverageLatency(us), 3131.0
[CLEANUP], MinLatency(us), 1
[CLEANUP], MaxLatency(us), 31295
[CLEANUP], 95thPercentileLatency(us), 31295
[CLEANUP], 99thPercentileLatency(us), 31295
[UPDATE], Operations, 4499654
[UPDATE], AverageLatency(us), 3534.2083122391186
[UPDATE], MinLatency(us), 704
[UPDATE], MaxLatency(us), 1078271
[UPDATE], 95thPercentileLatency(us), 11647
[UPDATE], 99thPercentileLatency(us), 27343
[UPDATE], Return=OK, 4499654</code></pre>
<h2 id="五、指标观察"><a href="#五、指标观察" class="headerlink" title="五、指标观察"></a>五、指标观察</h2><p>1、服务器指标，主要观察CPU、内存、磁盘IO的利用率和延时，可以通过top、iostat工具查看实时情况<br>2、MongoDB可以通过mongostat 工具查看实时情况</p>
<p>mongostat的输出说明</p>
<p>inserts：每秒插入次数<br>query：每秒查询次数<br>update：每秒更新次数<br>delete：每秒删除次数<br>getmore：每秒执行getmore次数<br>command：每秒的命令数，比以上插入、查找、更新、删除的综合还多，还统计了别的命令<br>dirty：WiredTiger存储引擎中dirty 数据占缓存百分比<br>used:WiredTiger存储引擎中引擎使用缓存占百分比<br>flushs：每秒执行fsync将数据写入硬盘的次数。<br>vsize：虚拟内存使用量，单位MB<br>res：物理内存使用量，单位MB<br>qrw:客户端等待读的长度,队列中的长度<br>arw:客户端等待写的队列长度<br>netIn 和 netOut：网络流量，单位是字节 byte<br>conn：当前连接数<br>time：时间戳<br>六、测试结果<br><a href="https://blog.51cto.com/navyaijm/2421973?source=drh">Mongodb性能压测</a><br><a href="https://www.yht7.com/news/21478">YCSB  压测</a><br>#　<a href="https://www.cnblogs.com/zhongyuanzhao000/p/12152843.html">使用 JMeter压测工具 对 MySQL、MongoDB、Neo4j 进行性能测试</a></p>
]]></content>
      <categories>
        <category>Mongo</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>Pyppeteer库之二：Pyppeteer的浏览器对象</title>
    <url>/2020/07/27/8003/</url>
    <content><![CDATA[<p>启动器Launcher<br>启动方式：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"> launch :启动链接一个新的浏览器</span><br><span class="line"> content :链接已打开的浏览器，便于崩溃后重链</span><br><span class="line"></span><br><span class="line">launch()</span><br><span class="line">pyppeteer.launch(options: dict = None, **kwargs: Any) -&gt; Browser</span><br></pre></td></tr></table></figure>
<p>启动一个新的浏览器，返回 Browser 类。接受字典或键值对的关键字配置参数。</p>
<p>常用参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headless(<span class="built_in">bool</span>): 是否启用<span class="string">&quot;无头模式&quot;</span>(隐藏浏览器界面)，默认为 <span class="literal">True</span> 。</span><br><span class="line">executablePath(<span class="built_in">str</span>): 指定 Chromium.exe 文件的路径(不使用内置的chromium)。</span><br><span class="line">slowMo（<span class="built_in">int</span>|<span class="built_in">float</span>）:按指定的毫秒数减慢 pyppeteer 的速度。</span><br><span class="line">args(List[<span class="built_in">str</span>]): 启动 Chromium 的参数。</span><br><span class="line">dumpio(<span class="built_in">bool</span>):是否将浏览器进程标准输出和标准错误输入到 process.stdout 和 process.stderr中。默认是 <span class="literal">False</span>。</span><br><span class="line">userDataDir(<span class="built_in">str</span>): 设置用户数据目录。</span><br><span class="line">devtools(<span class="built_in">bool</span>): 是否为每个选项卡自动打开 DevTools 面板， 这个选项只有当 headless 设置为 <span class="literal">False</span>的时候有效。</span><br></pre></td></tr></table></figure>
<p>args—&gt;启动chrome的参数：<br><a href="https://peter.sh/experiments/chromium-command-line-switches/">pyppeteer官网</a></p>
<p>launch常用参数配置:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">kwargs = &#123;</span><br><span class="line">    <span class="comment"># 启用浏览器界面</span></span><br><span class="line">    <span class="string">&#x27;headless&#x27;</span>: <span class="literal">False</span>,</span><br><span class="line">    <span class="comment"># 多开页面，解决卡死</span></span><br><span class="line">    <span class="string">&#x27;dumpio&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">    <span class="comment"># 设置浏览器全屏</span></span><br><span class="line">    <span class="string">&#x27;args&#x27;</span>: [<span class="string">&#x27;--start-maximized&#x27;</span>,</span><br><span class="line">             <span class="comment"># 取消沙盒模式，沙盒模式下权限太小</span></span><br><span class="line">             <span class="string">&#x27;--no-sandbox&#x27;</span>,</span><br><span class="line">             <span class="comment"># 设置浏览器界面大小</span></span><br><span class="line">             <span class="string">&#x27;--window-size=1366,768&#x27;</span>,</span><br><span class="line">             <span class="comment"># 关闭受控制提示：比如，Chrome正在受到自动测试软件的控制...</span></span><br><span class="line">             <span class="string">&#x27;--disable-infobars&#x27;</span>,</span><br><span class="line">             <span class="comment"># 允许跨域</span></span><br><span class="line">             <span class="string">&#x27;--disable-web-security&#x27;</span>,</span><br><span class="line">             <span class="comment"># 使用代理</span></span><br><span class="line">             <span class="string">&#x27;--proxy-server=127.0.0.1:80&#x27;</span>,</span><br><span class="line">             <span class="comment"># 不走代理的链接</span></span><br><span class="line">             <span class="string">&#x27;--proxy-bypass-list=*&#x27;</span>,</span><br><span class="line">             <span class="comment"># 忽略证书错误</span></span><br><span class="line">             <span class="string">&#x27;--ignore-certificate-errors&#x27;</span>,</span><br><span class="line">             <span class="comment"># log 等级设置，如果出现一大堆warning，可以不使用默认的日志等级</span></span><br><span class="line">             <span class="string">&#x27;--log-level=3&#x27;</span>,</span><br><span class="line">             <span class="comment"># 设置ua</span></span><br><span class="line">             <span class="string">&#x27;--user-agent=Mozilla/5.0&#x27;</span></span><br><span class="line">             ],</span><br><span class="line">    <span class="string">&#x27;userDataDir&#x27;</span>: <span class="string">r&#x27;D:\Temporary&#x27;</span>,</span><br><span class="line">    <span class="comment"># 用户数据保存目录，这个最好指定一个，</span></span><br><span class="line">    <span class="comment"># 如果不指定，Chrome会自动创建一个临时目录使用，在退出浏览器时自动删除，</span></span><br><span class="line">    <span class="comment"># 在删除的时候可能会删除失败(不知道为什么出现权限问题，我用Windows)导致浏览器退出失败</span></span><br><span class="line">    <span class="comment"># 删除失败时出现报错：OSError: Unable to remove Temporary User Data</span></span><br><span class="line">    <span class="comment"># 或者Chrome进程没有退出，cpu狂飙到99%</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">content()</span><br><span class="line">pyppeteer.connect(options: dict = None, **kwargs: Any) -&gt; Browser</span><br></pre></td></tr></table></figure>
<p>链接已打开的浏览器，返回 Browser 类。接受字典或键值对的关键字配置参数。</p>
<p>参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">browserWSEndpoint（<span class="built_in">str</span>）：要连接的浏览器 websocket 端点。（必填）</span><br><span class="line">ignoreHTTPSErrors（<span class="built_in">bool</span>）：是否忽略 HTTPS 错误。默认为 <span class="literal">False</span>。</span><br><span class="line">slowMo（<span class="built_in">int</span> | <span class="built_in">float</span>）：按指定的毫秒数减慢pyppeteer的速度。</span><br><span class="line">logLevel（<span class="built_in">int</span> | <span class="built_in">str</span>）：用于打印日志的日志级别。默认值与根记录器相同。</span><br><span class="line">loop（asyncio.AbstractEventLoop）：事件循环（实验）。</span><br><span class="line"></span><br><span class="line">browserWSEndpoint 的值获取：Browser.wsEndpoint</span><br></pre></td></tr></table></figure>

<p>例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> pyppeteer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    browser = <span class="keyword">await</span> pyppeteer.launch(&#123;<span class="string">&#x27;headless&#x27;</span>: <span class="literal">False</span>&#125;)</span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> page.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>: <span class="number">1366</span>, <span class="string">&#x27;height&#x27;</span>: <span class="number">768</span>&#125;)</span><br><span class="line">    <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">    ws = browser.wsEndpoint</span><br><span class="line">    print(ws)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">await</span> browser.disconnect()  <span class="comment"># 断开链接</span></span><br><span class="line">    browser2 = <span class="keyword">await</span> pyppeteer.connect(&#123;<span class="string">&#x27;browserWSEndpoint&#x27;</span>: ws&#125;)</span><br><span class="line">    <span class="keyword">await</span> browser2.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>

<p>浏览器Browser</p>
<p>常用属性和方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">process：返回浏览器进程，如果浏览器实例是由 connect 方法创建的则返回 null。</span><br><span class="line">browserContexts：返回一个包含所有打开的浏览器上下文的列表。在新创建的浏览器中，这将返回 [BrowserContext]的单个实例。</span><br><span class="line">wsEndpoint: 返回 websocket 端点 url，用于connect 方法重链。</span><br><span class="line">pages()：获取所有可见的标签页。</span><br><span class="line">newPage()：新建标签页。</span><br><span class="line">close():关闭 Chromium 及其所有页面。Browser 对象本身被认为是处理过的并不能再被使用。</span><br><span class="line">disconnect()：断开 Pyppeteer 和浏览器的连接，但 Chromium 进程仍然在运行。在调用 disconnect 之后，Browser 对象本身被认为是处理过的并不能再被使用。</span><br><span class="line">createIncognitoBrowserContext()：创建一个新的隐身浏览器上下文。这不会与其他浏览器上下文共享 cookie / 缓存。</span><br><span class="line">userAgent():返回浏览器原始的 user-agent。页面可以使用 page.setUserAgent 覆盖浏览器的 user-agent。</span><br><span class="line"></span><br><span class="line">注：被 <span class="keyword">async</span> 关键字修饰的方法是异步方法，调用的时候也必须 <span class="keyword">await</span> 关键字修饰。</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    browser = <span class="keyword">await</span> launch(&#123;<span class="string">&#x27;headless&#x27;</span>: <span class="literal">False</span>&#125;)</span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()</span><br><span class="line">    <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">    print(browser.process)     <span class="comment"># 属性不被 async 关键字修饰</span></span><br><span class="line">    print(browser.wsEndpoint)</span><br><span class="line">    print(browser.browserContexts)</span><br><span class="line">    print(<span class="keyword">await</span> browser.userAgent())</span><br><span class="line">    print(<span class="keyword">await</span> browser.pages())</span><br><span class="line">    print(<span class="keyword">await</span> browser.version())</span><br><span class="line">    print(browser.targets())  <span class="comment"># 这个方法在源码中不被 async 关键字修饰</span></span><br><span class="line">    <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BrowserContext</span><br></pre></td></tr></table></figure>
<p>启动浏览器时，默认情况下使用单个 BrowserContext。<br>方法 browser.newPage() 在默认浏览器中创建页面背景。</p>
<p>Pyppeteer允许创建隐身浏览器(无痕模式)上下文。如下方法：<br>browser.createInnamitoBrowserContext()</p>
<p>隐身浏览器上下文不会将任何浏览器数据写入磁盘。</p>
<p>无痕模式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> pyppeteer <span class="keyword">import</span> launch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># 创建浏览器实例</span></span><br><span class="line">    browser = <span class="keyword">await</span> launch(&#123;<span class="string">&#x27;headless&#x27;</span>: <span class="literal">False</span>&#125;)</span><br><span class="line">    <span class="comment"># 启动无痕模式</span></span><br><span class="line">    context = <span class="keyword">await</span> browser.createIncognitoBrowserContext()</span><br><span class="line">    <span class="comment"># 新建标签页</span></span><br><span class="line">    page = <span class="keyword">await</span> context.newPage()</span><br><span class="line">    <span class="comment"># 打开目标 url</span></span><br><span class="line">    <span class="keyword">await</span> page.goto(<span class="string">&#x27;https://www.baidu.com&#x27;</span>)</span><br><span class="line">    <span class="comment"># 打印是否无痕模式</span></span><br><span class="line">    print(context.isIncognito())</span><br><span class="line">    <span class="comment"># 关闭无痕模式</span></span><br><span class="line">    <span class="keyword">await</span> context.close()</span><br><span class="line">    <span class="comment"># 关闭浏览器</span></span><br><span class="line">    <span class="keyword">await</span> browser.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asyncio.get_event_loop().run_until_complete(main())</span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/weizhen11/java/article/details/102496875">原文链接</a><br><a href="https://blog.csdn.net/weizhen11/article/details/102497647?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param">pyppeteer页面操作</a></p>
]]></content>
      <categories>
        <category>Pyppeteer</category>
      </categories>
      <tags>
        <tag>Pyppeteer</tag>
      </tags>
  </entry>
  <entry>
    <title>Truffle+Vue+MetaMask创建一个以太坊Dapp</title>
    <url>/2020/10/09/29739/</url>
    <content><![CDATA[<p>参考资料</p>
<p>使用 Web3 和 Vue.js 来创建你的第一个以太坊 dAPP<br>web3 1.0 API</p>
<p>开发环境</p>
<p>Windows10<br>web3 1.0</p>
<p>编写第一个Solidity智能合约<br>一个简单的例子是编写一个可以注册，保存社区成员信息和简单电子钱包功能的账户合约</p>
<a id="more"></a>
<pre><code class="bash">pragma solidity ^0.4.24;
import &quot;./SafeMath.sol&quot;;//开源的安全操作unit256的合约

contract Account&#123;
    using SafeMath for uint256;
    //新成员创建事件
    event NewMember(string _name, string _avator);
    //成员信息结构
    struct Member &#123;
        string name;//名字
        string avatar;//头像
        bool isExist;//是否注册
        uint256 balance;//可周转余额
    &#125;
    //地址到成员信息的mapping
    mapping(address =&gt; Member) internal addressToMember;
    //限制调用的条件
    modifier onlyMemberOf(address _from)&#123;
        require(addressToMember[_from].isExist);
        _;
    &#125;
    // 注册
    function registerMember(string _name, string _avatar) public &#123;
        require(!isMemberOf());
        addressToMember[msg.sender] = Member(_name, _avatar, true, 0);
        emit NewMember(_name, _avatar);
    &#125;

    // 判断是否注册
    function isMemberOf() public view returns (bool) &#123;
        return addressToMember[msg.sender].isExist;
    &#125;

    // 获取个人信息
    function getMemberInfo() public view onlyMemberOf(msg.sender) returns (string name, string avatar, uint256 balance) &#123;
        return (addressToMember[msg.sender].name,addressToMember[msg.sender].avatar, addressToMember[msg.sender].balance);
    &#125;
    //获取当前合约中的总余额
    function getTotalBalance() public view returns (uint256) &#123;
        return address(this).balance;
    &#125;
    //取出可周转余额
    function withdraw(uint256 amount) public onlyMemberOf(msg.sender) returns (uint256) &#123;
        require(address(this).balance &gt;= amount);
        addressToMember[msg.sender].balance = addressToMember[msg.sender].balance.sub(amount);
        msg.sender.transfer(amount);
        return addressToMember[msg.sender].balance;
    &#125;
&#125;
``` bash
在Remix上部署合约

安装Ganache
使用Ganache本地测试：安装MetaMask Chrome插件, 选择Custom RPC创建RPC连接到http://127.0.0.1:7545

或者要部署到私有节点，可以使用命令行，然后选择Custom RPC创建RPC连接到http://127.0.0.1:8545

$ geth --identity &quot;MY Etherum&quot; --rpc --rpccorsdomain &quot;*&quot; --datadir data --port &quot;8545&quot; --rpcapi &quot;db,eth,net,web3,personal&quot; --networkid 666 console
复制代码
打开Remix在线编译，在compile选择合适的编译版本编译，在run选择Deploy部署得到合约地址
可以在Remix上测试我们的合约（注册后getMemberInfo可以用户信息，isMemberOf为true）


合约部署和测试成功后，将ABI和Deployed Contracts复制保存到本地文件夹(注意Ganache得到的地址是临时的，下次打开就会失效)


配置Truffle+Vue项目

环境配置
在windows下需要先安装node.js, 建议使用Git Bash或者PowerShell执行命令：$ npm install -g -production windows-build-tools
$ npm install -g ganache-cli
$ npm install -g truffle
$ npm install -g vue-cli
复制代码
Vue项目安装$ vue init webpack ecourse // vue init webpach + 你的项目名
$ cd ecourse
$ npm install --save element-ui vue-router vuex web3@1.0.0-beta.36 web3-net@1.0.0-beta.36
复制代码
添加文件及文件夹：① contracts放置.sol合约； ② store放置Vuex状态控制代码；③ util放置工具函数，util/constant放置上一步中编译好的合约地址和ABI,util/config放置一些配置


完善项目
具体的配置可以参考博客使用 Web3 和 Vue.js 来创建你的第一个以太坊 dAPP，这里我主要指出使用web3 1.0 标准的不同配置

getWeb3.js
``` bash
import Web3 from &#39;web3&#39;

let getWeb3 = new Promise(function (resolve, reject) &#123;
  var web3js = window.web3;
  var web3Provider;
  if (typeof web3js !== &#39;undefined&#39;) &#123;
      web3Provider = web3js.currentProvider;
  &#125; else &#123;
      web3Provider = new Web3.providers.HttpProvider(&#39;http://127.0.0.1:7545&#39;);
  &#125;
  var web3 = new Web3(web3Provider);
  resolve(&#123;
      injectedWeb3: web3.eth.net.isListening(), // 新的api
      web3() &#123;
          return web3
      &#125;
  &#125;)
&#125;)
  .then(result =&gt; &#123;
      return new Promise(function (resolve, reject) &#123;
        result.web3().eth.net.getId((err, networkId) =&gt; &#123; // 新的api
            if(err) &#123;
              reject(new Error(&#39;Unable to retrieve network ID&#39;))
            &#125; else &#123;
              console.log(&#39;retrieve newworkId: &#39; + networkId)
              result = Object.assign(&#123;&#125;, result, &#123;networkId&#125;)
              resolve(result)
            &#125;
        &#125;)
      &#125;)
  &#125;)
  .then(result =&gt; &#123;
      return new Promise(function (resolve, reject) &#123;
        result.web3().eth.getCoinbase((err, coinbase) =&gt; &#123;
            if(err) &#123;
            reject(new Error(&#39;Unable to retrieve coinbase&#39;))
        &#125; else &#123;
        coinbase = result.web3().utils.toChecksumAddress(coinbase);
            console.log(&#39;retrieve coinbase: &#39;+ coinbase);
            result = Object.assign(&#123;&#125;, result, &#123;coinbase&#125;);
            resolve(result)
        &#125;&#125;)
      &#125;)
  &#125;);

  export default getWeb3</code></pre>
<p>pollWeb3.js(web3 1.0 添加了新的api能够监听账户地址的变化，不需要使用setIntervel进行轮询)</p>
<pre><code class="bash">import Web3 from &#39;web3&#39;
import &#123;store&#125; from &#39;../store/&#39;

let web3 = window.web3;
web3 = new Web3(web3.currentProvider);
web3.currentProvider.publicConfigStore.on(&#39;update&#39;, (&#123;selectedAddress, networkVersion&#125;) =&gt; &#123;
  store.dispatch(&#39;pollWeb3&#39;, &#123;
    coinbase: selectedAddress
  &#125;)
&#125;);</code></pre>
<p>getContract.js</p>
<pre><code class="bash">import Web3 from &#39;web3&#39;
import &#123;address, ABI&#125; from &#39;./constant/ecourse_abi&#39;
import &#123;store&#125; from &#39;../store/&#39;

let getContract = new Promise(function(resolve, reject) &#123;
  let web3 = new Web3(window.web3.currentProvider);
  let ecourseContractInstance =  new web3.eth.Contract(ABI, address);//新的api
  if (!ecourseContractInstance) &#123;
    reject(&quot;no contract instance build&quot;)
  &#125;
  resolve(ecourseContractInstance);
&#125;);
export default getContract</code></pre>
<p>Dapp调用合约函数</p>
<p>App.vue(我们可以在入口文件注册web3和contract)</p>
<pre><code class="bash">async beforeCreate() &#123;
    if(!this.$store.state.web3.web3Instance) &#123;
    await this.$store.dispatch(&#39;registerWeb3&#39;);
    await this.$store.dispatch(&#39;getContractInstance&#39;);
    &#125;
&#125;,</code></pre>
<p>web3 1.0调用函数使用methods</p>
<pre><code class="bash">// 为避免报错，可以在调用合约函数之前，进行一个判断
if(typeof this.$store.state.contractInstance !== &quot;function&quot;) &#123;
    await this.$store.dispatch(&#39;getContractInstance&#39;);
&#125;
// 一个调用函数的例子
this.$store.state.contractInstance().methods.withdraw(this.formInline.balance)
    .send(&#123;from:this.$store.state.web3.coinbase, gas: 300000&#125;)
    .on(&#39;receipt&#39;, receipt =&gt; &#123;
        this.$message(&#39;取款成功&#39;);
    &#125;)
    .on(&#39;error&#39;, error =&gt; &#123;
        this.$message(&#39;取款失败&#39;);
    &#125;)
// 另一个调用函数的例子
this.$store.state.contractInstance().methods.getMemberInfo()
.call(&#123;from: state.web3.coinbase&#125;) //注意!!!!!from不能省略，因为metamask默认的msg.sender是accounts[0]
.then(res =&gt; &#123;
    console.log(&#39;account info: &#39; + res);
&#125;)
.catch(error =&gt; &#123;
    console.log(error);
&#125;)</code></pre>
<p>之前没有学习过vue项目的，可以从一个最简单的Truffle PetShop项目学起，可以很快搭建并看到一个合约怎样调用。<br>学习solidity的很好的网站：cryptozombies，大概两天可以把所有lesson过一遍，基本上编写合约就没什么问题了<br>可以在truffle官网上找到很多框架,直接unbox使用，不过我觉得自己配置使用起来比较容易</p>
<p><a href="https://github.com/SusieChang/ECourse">项目地址：Github</a><br>有问题，可以随时提问</p>
<p>作者：一个卷er<br>链接：<a href="https://juejin.im/post/6844903736142200839">https://juejin.im/post/6844903736142200839</a><br>来源：掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
]]></content>
      <categories>
        <category>Dapp</category>
      </categories>
      <tags>
        <tag>Dapp</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu系统CPU、内存、网络、进程监控工具</title>
    <url>/2020/07/22/38001/</url>
    <content><![CDATA[<h2 id="top"><a href="#top" class="headerlink" title="top"></a>top</h2><p>作用：查看在系统中运行的进程或线程,以及CPU、内存、交换分区等<br>运行方法：sudo top</p>
<h2 id="htop"><a href="#htop" class="headerlink" title="htop"></a>htop</h2><p>作用：查看在系统中运行的进程或线程,以及CPU、内存、交换分区等<br>运行方法：sudo htop</p>
<h2 id="atop"><a href="#atop" class="headerlink" title="atop"></a>atop</h2><p>介绍：atop 和 top，htop 非常相似，它也能监控所有进程，但不同于 top 和 htop 的是，它可以按日记录进程的日志供以后分析。它也能显示所有进程的资源消耗。它还会高亮显示已经达到临界负载的资源。作用：查看在系统中运行的进程或线程,以及CPU、内存、交换分区等运行方法：sudo atop</p>
<h2 id="powertop"><a href="#powertop" class="headerlink" title="powertop"></a>powertop</h2><p>作用：powertop 可以帮助你诊断与电量消耗和电源管理相关的问题。它也可以帮你进行电源管理设置，以实现对你服务器最有效的配置。<br>运行方法：sudo powertop</p>
<h2 id="iotop"><a href="#iotop" class="headerlink" title="iotop"></a>iotop</h2><p>作用：iotop 用于检查 I/O 的使用情况，并为你提供了一个类似 top 的界面来显示。它按列显示读和写的速率，每行代表一个进程。当发生交换或 I/O 等待时，它会显示进程消耗时间的百分比。<br>运行方法：sudo iotop</p>
<h2 id="iftop"><a href="#iftop" class="headerlink" title="iftop"></a>iftop</h2><p>作用：iftop 类似于 top，但它主要不是检查 cpu 的使用率而是监听所选择网络接口的流量，并以表格的形式显示当前的使用量。<br>运行方法：sudo iftop</p>
<h2 id="jnettop"><a href="#jnettop" class="headerlink" title="jnettop"></a>jnettop</h2><p>作用：jnettop 以相同的方式来监测网络流量但比 iftop 更形象。它还支持自定义的文本输出，并能以友好的交互方式来深度分析日志。<br>运行：sudo jnettop</p>
<h2 id="BandwidthD"><a href="#BandwidthD" class="headerlink" title="BandwidthD"></a>BandwidthD</h2><p>作用:BandwidthD 可以跟踪 TCP/IP 网络子网的使用情况，并能在浏览器中通过 png 图片形象化地构建一个 HTML 页面。它有一个数据库系统，支持搜索、过滤，多传感器和自定义报表。</p>
<p>##NetHogs</p>
<p>作用：NetHogs 打破了网络流量按协议或子网进行统计的惯例，它以进程来分组。所以，当网络流量猛增时，你可以使用 NetHogs 查看是由哪个进程造成的。<br>运行方法：sudo Nethogs</p>
<h2 id="dstat"><a href="#dstat" class="headerlink" title="dstat"></a>dstat</h2><p>作用：dstat 旨在替代 vmstat，iostat，netstat 和 ifstat。它可以让你查实时查看所有的系统资源。这些数据可以导出为 CSV。最重要的是 dstat 允许使用插件，因此其可以扩展到更多领域。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>about me</title>
    <url>/2020/07/22/14326/</url>
    <content><![CDATA[<p>about me</p>
]]></content>
      <categories>
        <category>horysk</category>
      </categories>
      <tags>
        <tag>horysk</tag>
      </tags>
  </entry>
  <entry>
    <title>centos7升级内核至最新</title>
    <url>/2015/11/08/31208/</url>
    <content><![CDATA[<p>centos7升级内核至最新</p>
<h2 id="应用背景："><a href="#应用背景：" class="headerlink" title="应用背景："></a>应用背景：</h2><p>最近在接触k8s，其对内核版本要求较高，就连目前使用的centos7.x默认内核版本为3.10.0-xxx，也是刚好满足其最低要求，故借此机会记录一下升级内核的操作步骤。</p>
<p>测试环境：</p>
<p>系统    当前内核版本    小版本升级<br>CentOS 7.6    3.10.0-957    3.10.0-957.5.1</p>
<p>系统    当前内核版本    大版本升级<br>CentOS 7.6    3.10.0-957    4.20.12-1(目前最新)</p>
<p>操作步骤：</p>
<h2 id="小版本升级"><a href="#小版本升级" class="headerlink" title="小版本升级"></a>小版本升级</h2><ol>
<li>查看当前和可升级版本<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># yum list kernel</span></span><br><span class="line">Installed Packages</span><br><span class="line">kernel.x86_64                           <span class="number">3.10</span><span class="number">.0</span>-<span class="number">957.</span>el7                                      @anaconda</span><br><span class="line">Available Packages</span><br><span class="line">kernel.x86_64                           <span class="number">3.10</span><span class="number">.0</span>-<span class="number">957.5</span><span class="number">.1</span>.el7                                  updates  </span><br></pre></td></tr></table></figure></li>
<li>升级<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># yum update kernel -y </span></span><br></pre></td></tr></table></figure></li>
<li>重启并检查<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># reboot 　　</span></span><br><span class="line"></span><br><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># uname -r </span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="大版本升级"><a href="#大版本升级" class="headerlink" title="大版本升级"></a>大版本升级</h2><ol>
<li>载入公钥<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span></span><br></pre></td></tr></table></figure></li>
<li>升级安装ELRepo<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span></span><br></pre></td></tr></table></figure></li>
<li>载入elrepo-kernel元数据<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># yum --disablerepo=\* --enablerepo=elrepo-kernel repolist</span></span><br></pre></td></tr></table></figure></li>
<li>查看可用的rpm包</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># yum --disablerepo=\* --enablerepo=elrepo-kernel list kernel*</span></span><br><span class="line">Installed Packages</span><br><span class="line">kernel.x86_64                           <span class="number">3.10</span><span class="number">.0</span>-<span class="number">957.</span>el7                           @anaconda    </span><br><span class="line">kernel.x86_64                           <span class="number">3.10</span><span class="number">.0</span>-<span class="number">957.5</span><span class="number">.1</span>.el7                       @updates     </span><br><span class="line">kernel-tools.x86_64                     <span class="number">3.10</span><span class="number">.0</span>-<span class="number">957.</span>el7                           @anaconda    </span><br><span class="line">kernel-tools-libs.x86_64                <span class="number">3.10</span><span class="number">.0</span>-<span class="number">957.</span>el7                           @anaconda    </span><br><span class="line">Available Packages</span><br><span class="line">kernel-lt.x86_64                        <span class="number">4.4</span><span class="number">.176</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-lt-devel.x86_64                  <span class="number">4.4</span><span class="number">.176</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-lt-doc.noarch                    <span class="number">4.4</span><span class="number">.176</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-lt-headers.x86_64                <span class="number">4.4</span><span class="number">.176</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-lt-tools.x86_64                  <span class="number">4.4</span><span class="number">.176</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-lt-tools-libs.x86_64             <span class="number">4.4</span><span class="number">.176</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-lt-tools-libs-devel.x86_64       <span class="number">4.4</span><span class="number">.176</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-ml.x86_64                        <span class="number">4.20</span><span class="number">.12</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel　// 安装目标版本</span><br><span class="line">kernel-ml-devel.x86_64                  <span class="number">4.20</span><span class="number">.12</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-ml-doc.noarch                    <span class="number">4.20</span><span class="number">.12</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-ml-headers.x86_64                <span class="number">4.20</span><span class="number">.12</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-ml-tools.x86_64                  <span class="number">4.20</span><span class="number">.12</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs.x86_64             <span class="number">4.20</span><span class="number">.12</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs-devel.x86_64       <span class="number">4.20</span><span class="number">.12</span>-<span class="number">1.</span>el7.elrepo                     elrepo-kernel</span><br><span class="line"></span><br><span class="line">说明：</span><br><span class="line"></span><br><span class="line">lt  ：long term support，长期支持版本；</span><br><span class="line"></span><br><span class="line">ml：mainline，主线版本；</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>安装最新版本的kernel<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># yum --disablerepo=\* --enablerepo=elrepo-kernel install  kernel-ml.x86_64  -y</span></span><br></pre></td></tr></table></figure></li>
<li>删除旧版本工具包<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64  -y</span></span><br></pre></td></tr></table></figure></li>
<li>安装新版本工具包<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># yum --disablerepo=\* --enablerepo=elrepo-kernel install kernel-ml-tools.x86_64  -y</span></span><br></pre></td></tr></table></figure></li>
<li>查看内核插入顺序<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># awk -F \&#x27; &#x27;$1==&quot;menuentry &quot; &#123;print i++ &quot; : &quot; $2&#125;&#x27; /etc/grub2.cfg</span></span><br><span class="line"><span class="number">0</span> : CentOS Linux (<span class="number">4.20</span><span class="number">.12</span>-<span class="number">1.</span>el7.elrepo.x86_64) <span class="number">7</span> (Core)</span><br><span class="line"><span class="number">1</span> : CentOS Linux (<span class="number">3.10</span><span class="number">.0</span>-<span class="number">957.5</span><span class="number">.1</span>.el7.x86_64) <span class="number">7</span> (Core)</span><br><span class="line"><span class="number">2</span> : CentOS Linux (<span class="number">3.10</span><span class="number">.0</span>-<span class="number">957.</span>el7.x86_64) <span class="number">7</span> (Core)</span><br><span class="line"><span class="number">3</span> : CentOS Linux (<span class="number">0</span>-rescue-ca0f6fb3c5f24478abc0a2e275281d7a) <span class="number">7</span> (Core)</span><br></pre></td></tr></table></figure>
说明：默认新内核是从头插入，默认启动顺序也是从0开始（当前顺序还未生效），或者使用：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> View Code</span><br><span class="line">其中文件 /etc/grub2.cfg 和 /boot/grub2/grub.cfg 内容一致。</span><br></pre></td></tr></table></figure></li>
<li>查看当前实际启动顺序<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># grub2-editenv list</span></span><br><span class="line">saved_entry=CentOS Linux (<span class="number">3.10</span><span class="number">.0</span>-<span class="number">957.5</span><span class="number">.1</span>.el7.x86_64) <span class="number">7</span> (Core)</span><br></pre></td></tr></table></figure></li>
<li>设置默认启动<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># grub2-set-default &#x27;CentOS Linux (4.20.12-1.el7.elrepo.x86_64) 7 (Core)&#x27;</span></span><br><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># grub2-editenv list</span></span><br><span class="line">saved_entry=CentOS Linux (<span class="number">4.20</span><span class="number">.12</span>-<span class="number">1.</span>el7.elrepo.x86_64) <span class="number">7</span> (Core)</span><br></pre></td></tr></table></figure>
或者直接设置数值<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># grub2-set-default 0　　// 0代表当前第一行，也就是上面的4.20.12版本那一行内容</span></span><br><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># grub2-editenv list</span></span><br><span class="line">saved_entry=<span class="number">0</span></span><br></pre></td></tr></table></figure></li>
<li>重启并检查<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># reboot </span></span><br><span class="line"></span><br><span class="line">[root@server-<span class="number">1</span> ~]<span class="comment"># uname -r </span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p><a href="https://github.com/gjmzj/kubeasz/blob/master/docs/guide/kernel_upgrade.md">参考</a><br><a href="https://wiki.centos.org/HowTos/Grub2#head-535f476a61e62f24bc150c73f7e0816f85345f46">link</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Centos</tag>
      </tags>
  </entry>
  <entry>
    <title>hello world</title>
    <url>/2015/07/01/14785/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a><br>Markown 语法高亮</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Markdown 目录：</span><br><span class="line">[TOC]</span><br><span class="line"></span><br><span class="line">Markdown 标题：</span><br><span class="line"><span class="comment"># 这是 H1</span></span><br><span class="line"><span class="comment">## 这是 H2</span></span><br><span class="line"><span class="comment">### 这是 H3</span></span><br><span class="line"></span><br><span class="line">Markdown 列表：</span><br><span class="line">- 列表项目</span><br><span class="line"><span class="number">1.</span> 列表项目</span><br><span class="line"></span><br><span class="line">*斜体*或_斜体_</span><br><span class="line">**粗体**</span><br><span class="line">***加粗斜体***</span><br><span class="line">~~删除线~~</span><br><span class="line"></span><br><span class="line">Markdown 插入链接：</span><br><span class="line">[链接文字](链接网址 <span class="string">&quot;标题&quot;</span>)</span><br><span class="line"></span><br><span class="line">Markdown 插入图片：</span><br><span class="line">![alt text](/path/to/img.jpg <span class="string">&quot;Title&quot;</span>)</span><br><span class="line"></span><br><span class="line">Markdown 插入代码块：</span><br><span class="line">    ```python</span><br><span class="line">    <span class="comment">#!/usr/bin/python3</span></span><br><span class="line">    print(<span class="string">&quot;Hello, World!&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>Markdown 引用：</p>
<blockquote>
<p>引用内容</p>
</blockquote>
<h2 id="Markdown-分割线："><a href="#Markdown-分割线：" class="headerlink" title="Markdown 分割线："></a>Markdown 分割线：</h2><p>Markdown 换行：<br><br></p>
<p>Markdown 段首缩进：<br>&ensp; or &#8194; 表示一个半角的空格<br>&emsp; or &#8195;  表示一个全角的空格<br>&emsp;&emsp; 两个全角的空格（用的比较多）<br>&nbsp; or &#160; 不断行的空白格</p>
<pre><code></code></pre>
]]></content>
      <categories>
        <category>horysk</category>
      </categories>
      <tags>
        <tag>horysk</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建博客使用hexo的next主题如何添加动态背景</title>
    <url>/2020/12/07/29060/</url>
    <content><![CDATA[<p>修改_layout.swig<br>打开 next/layout/_layout.swig  在 &lt; /body&gt;之前添加代码(注意不要放在&lt; /head&gt;的后面)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% <span class="keyword">if</span> theme.canvas_nest %&#125;</span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">&quot;text/javascript&quot;</span> src=<span class="string">&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>
<p>修改配置文件</p>
<a id="more"></a>

<p>打开 /next/_config.yml,在里面添加如下代码：(可以放在最后面)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># --------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># background settings</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># add canvas-nest effect</span></span><br><span class="line"><span class="comment"># see detail from https://github.com/hustcc/canvas-nest.js</span></span><br><span class="line">canvas_nest: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>到此就结束了，运行 hexo clean，然后运行 hexo g,然后运行 hexo s，最后打开浏览器在浏览器的地址栏输入 localhost:4000 就能看到效果了\（￣︶￣）/</p>
<p>如果你感觉默认的线条太多的话<br>可以这么设置====&gt;<br>在上一步修改 _layout.swig中，把刚才的这些代码：</p>
<pre><code class="bash">&#123;% if theme.canvas_nest %&#125;
<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
&#123;% endif %&#125;</code></pre>
<p>改为</p>
<pre><code class="bash">&#123;% if theme.canvas_nest %&#125;
<script type="text/javascript" color="0,0,255" opacity="0.7" zindex="-2" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
&#123;% endif %&#125;</code></pre>
<p>配置项说明<br>color ：线条颜色, 默认: ‘0,0,0’；三个数字分别为(R,G,B)<br>opacity: 线条透明度（0~1）, 默认: 0.5<br>count: 线条的总数量, 默认: 150<br>zIndex: 背景的z-index属性，css属性用于控制所在层的位置, 默认: -1</p>
]]></content>
  </entry>
  <entry>
    <title>hexo 添加 hexo-admin 插件</title>
    <url>/2020/12/04/47368/</url>
    <content><![CDATA[<p>简介<br>在线编辑和发布 hexo 博客。<br>github 地址：<a href="https://github.com/jaredly/hexo-admin">https://github.com/jaredly/hexo-admin</a></p>
<p>安装<br>进入 hexo 源文件目录，执行命令：</p>
<a id="more"></a>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-admin</span><br><span class="line">hexo server -d</span><br><span class="line">open http://localhost:4000/admin/</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">配置</span><br><span class="line">编辑根目录下：_config.yml 文件，添加：</span><br><span class="line">``` bash</span><br><span class="line">admin:</span><br><span class="line">  username: myfavoritename</span><br><span class="line">  password_hash: be121740bf988b2225a313fa1f107ca1</span><br><span class="line">  secret: a secret something</span><br></pre></td></tr></table></figure>
<p>其中：<br>username 为登录的用户名，password_hash 为密码的 bcrypt 哈希值，secret 用于使 cookie 安全，可以尽可能复杂。</p>
<p>password_hash 的生成<br>首先需安装模块：sudo npm install bcrypt-nodejs<br>执行：</p>
<pre><code class="bash"> node
 const bcrypt = require(&#39;bcrypt-nodejs&#39;)
 bcrypt.hashSync(&#39;your_password&#39;)</code></pre>
<p>其中的 your_password 为登录密码。</p>
<p>若部署到远程服务器，就可以使用：<a href="http://ip:4000/admin/">http://ip:4000/admin/</a> 进行访问，在线发布 hexo 博客。</p>
]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo修改默认端口</title>
    <url>/2019/09/18/12710/</url>
    <content><![CDATA[<p>默认使用4000端口，用hexo s -p 80 ，可以暂时修改启动端口。</p>
<p>但是每次启动都要写”-p 80”才行，过于繁琐。</p>
<p>修改方法：<br>找到node_modules\hexo-server\index.js文件，可以修改默认的port值！</p>
]]></content>
  </entry>
  <entry>
    <title>k8s 离线安装 一键安装兼容centos8 &amp;&amp; ubutnu20.04</title>
    <url>/2016/02/06/3540/</url>
    <content><![CDATA[<p>K8S 是一个一键安装K8S高可用集群的软件。它可以帮助企业一键搭建完私有云系统，帮助用户在多家云服务商里灵活切换，不再被任何服务商绑架！ 对! 所有的操作只需要一键！</p>
<p>有问题 咨询wechat: horysk</p>
<h1 id="kubernetes-v1-18-2-版本-已经支持-所有监控为最新版本"><a href="#kubernetes-v1-18-2-版本-已经支持-所有监控为最新版本" class="headerlink" title="kubernetes v1.18.2 版本 已经支持, 所有监控为最新版本."></a>kubernetes v1.18.2 版本 已经支持, 所有监控为最新版本.</h1><p>安装很简单， 一键安装，安装一个系统只需要 3 分钟, 安装好以后完整的监控也一并装好，可以直接使用。（不止支持单master 还支持3master 高可用方案)</p>
<h1 id="同时安装三台-方案"><a href="#同时安装三台-方案" class="headerlink" title="同时安装三台 方案:"></a>同时安装三台 方案:</h1><p>记住服务版本 linux AMD64的安装包才是我们支持的。</p>
<p>好现在开始安装，高可用系统 需要3台服务器，我们这里假设3台主机，ip 分别是10.0.0.4, 10.0.0.5,10.0.0.6</p>
<h2 id="好我们需要做下面4件事"><a href="#好我们需要做下面4件事" class="headerlink" title="好我们需要做下面4件事"></a>好我们需要做下面4件事</h2><p>把安装包installer, pack.xxx.xxx.bin 文件 以及kubernetes的官方文件复制到每台主机上<br>在其中一台 运行 sudo ./installer -genkey -hostlist=10.0.0.0 运行完毕，会生成一个k8skey.pem文件，将它复制到其他的主机上<br>在每台主机上运行一次 sudo ./installer –prepare<br>在3台主机上同时运行 sudo ./installer -kubernetestarfile kubernetes-server-linux-amd64.tar.gz -masterip=10.0.0.4,10.0.0.5,10.0.0.6<br>参数说明 -kubernetestarfile kubernetes-server-linux-amd64.tar.gz 是指 使用 kubernetes-server-linux-amd64.tar.gz 这个文件作为kubernetes的官方软件。<br>-masterip=10.0.0.4,10.0.0.5,10.0.0.6 是指 我们选择 10.0.0.4 10.0.0.5 10.0.0.6 作为master节点</p>
<p>剩下的？ 等待就可以了。<br>等安装成功后 你用浏览器访问一下 10.0.0.4:10000 看看，一个新的世界给你准备好了。</p>
<p>你需要下载pack.xxx.xxx.bin 文件和installer 文件。</p>
<p>此外 你还需选择一个kubernetes 的官方发行包。你可以在这里找到官方发行包</p>
<h1 id="安装主机-后添加-方案二"><a href="#安装主机-后添加-方案二" class="headerlink" title="安装主机  后添加  方案二:"></a>安装主机  后添加  方案二:</h1><h2 id="2条命令即可"><a href="#2条命令即可" class="headerlink" title="2条命令即可"></a>2条命令即可</h2><p>#创建密钥<br>sudo ./installer –genkey -hostlist=172.20.2.66</p>
<h2 id="提示kernel-不够请升级centos-kernel-参考"><a href="#提示kernel-不够请升级centos-kernel-参考" class="headerlink" title="提示kernel 不够请升级centos kernel  参考"></a>提示kernel 不够请升级centos kernel  参考<a href></a></h2><h2 id="报错-sysctl-cannot-stat-proc-sys-net-netfilter-nf-conntrack-max-No-such-file-or-directory-请参考一下处理方案"><a href="#报错-sysctl-cannot-stat-proc-sys-net-netfilter-nf-conntrack-max-No-such-file-or-directory-请参考一下处理方案" class="headerlink" title="报错 sysctl: cannot stat /proc/sys/net/netfilter/nf_conntrack_max: No such file or directory  请参考一下处理方案"></a>报错 sysctl: cannot stat /proc/sys/net/netfilter/nf_conntrack_max: No such file or directory  请参考一下处理方案</h2><p>#创建集群<br>sudo ./installer   -kubernetestarfile kubernetes-server-linux-amd64.tar.gz -masterip 172.20.2.66<br>image</p>
<h1 id="将一个新节点加入这个集群也只需要一个命令"><a href="#将一个新节点加入这个集群也只需要一个命令" class="headerlink" title="将一个新节点加入这个集群也只需要一个命令"></a>将一个新节点加入这个集群也只需要一个命令</h1><p>1条命令即可</p>
<h1 id="将密钥复制到本地"><a href="#将密钥复制到本地" class="headerlink" title="将密钥复制到本地"></a>将密钥复制到本地</h1><p>cp ../k8skey.pem ./</p>
<h1 id="将机器加入集群"><a href="#将机器加入集群" class="headerlink" title="将机器加入集群"></a>将机器加入集群</h1><p>sudo ./installer   -kubernetestarfile kubernetes-server-linux-amd64.tar.gz -masterip 172.20.2.66</p>
<p><a href="https://github.com/horysk/k8seasy_release_page">github</a><br><a href="http://dl.k8seasy.com/">link</a></p>
<h2 id="报错-sysctl-cannot-stat-proc-sys-net-netfilter-nf-conntrack-max-No-such-file-or-directory"><a href="#报错-sysctl-cannot-stat-proc-sys-net-netfilter-nf-conntrack-max-No-such-file-or-directory" class="headerlink" title="报错: sysctl: cannot stat /proc/sys/net/netfilter/nf_conntrack_max: No such file or directory"></a>报错: sysctl: cannot stat /proc/sys/net/netfilter/nf_conntrack_max: No such file or directory</h2><p>执行如下</p>
<p>lsmod |grep conntrack</p>
<p>如何返回是空，表示没有加载，那执行如下命令加载即可</p>
<p>modprobe ip_conntrack</p>
<p>再重新执行验证</p>
<p>[root@k8s-node-n2 ~]# lsmod |grep conntrack<br>nf_conntrack_ipv4 20480 0<br>nf_defrag_ipv4 16384 1 nf_conntrack_ipv4<br>nf_conntrack 114688 1 nf_conntrack_ipv4</p>
<p>再重新手动刷新使文件生效就没有问题了</p>
<p>sysctl -p /etc/sysctl.d/kubernetes.conf</p>
<p><a href="https://www.jianshu.com/p/de4ae3812b04">参考</a></p>
]]></content>
      <categories>
        <category>docker</category>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>kubectl管理Pod-6:数据持久化(挂载卷)</title>
    <url>/2016/07/09/51271/</url>
    <content><![CDATA[<h1 id="k8s支持的几种挂载卷方式："><a href="#k8s支持的几种挂载卷方式：" class="headerlink" title="k8s支持的几种挂载卷方式："></a>k8s支持的几种挂载卷方式：</h1><p><a href="https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes">官网</a></p>
<h2 id="volume类型-使用方法"><a href="#volume类型-使用方法" class="headerlink" title="volume类型    使用方法"></a>volume类型    使用方法</h2><figure class="highlight"><table><tr><td class="code"><pre><span class="line">emptyDir （挂载容器目录）	volume名称-&gt; emptyDir: &#123;&#125;</span><br><span class="line">hostPath （挂载容器宿主机目录）	volume名称-&gt; hostPath–&gt;path, type</span><br><span class="line">NFS （挂载远程nfs目录）	volume名称-&gt; nfs–&gt; server, path</span><br><span class="line">PersistentVolume （存储资源的抽象, 和pvc联合使用）	volume名称-&gt;persistentVolumeClaim --&gt; claimName</span><br><span class="line">PersistentVolume 动态供给	volume名称 --&gt;persistentVolumeClaim–&gt; claimName - -&gt; volume.beta.kubernetes.io/storage-class</span><br></pre></td></tr></table></figure>
<p>Docker本身有自己的目录挂载, 但功能太单一, 一般也只能挂载本地目录, K8S作为Docker容器的管理服务, 除了能够挂载本地的还能在线文件存储目录, 比如说nfs</p>
<h2 id="1-本地目录挂载"><a href="#1-本地目录挂载" class="headerlink" title="1. 本地目录挂载"></a>1. 本地目录挂载</h2><p>yml文件中配置如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: goserver</span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">2</span></span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: goserver</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: goserver</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/magina-centos7/goserver:<span class="number">1.0</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">4040</span></span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /mnt/logs</span><br><span class="line">          name: go-logs</span><br><span class="line">      volumes:</span><br><span class="line">      - name: go-logs</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /mnt/logs/kubernetes/goserver</span><br></pre></td></tr></table></figure>
<p>最后的volumes指定挂载目录的名称和路径, 这个目录是本地的, 也就是说pod只会挂载当前宿主机的目录, 但当我们有多个节点, 而这些节点上又有运行着相同的项目, 而我们需要收集这些项目的日志, 用本地挂载的方式显得很麻烦, 当然, 我们可以用分布式日志工具去处理, 这里介绍另外一种方式, 网络文件系统nfs</p>
<h2 id="2-网络文件系统nfs"><a href="#2-网络文件系统nfs" class="headerlink" title="2. 网络文件系统nfs"></a>2. 网络文件系统nfs</h2><p>yml文件中配置如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: goserver</span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">2</span></span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: goserver</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: goserver</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/magina-centos7/goserver:<span class="number">1.0</span></span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">4040</span></span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /mnt/logs</span><br><span class="line">          name: go-logs</span><br><span class="line">  volumes:</span><br><span class="line">  - name: go-log</span><br><span class="line">    nfs:</span><br><span class="line">      server: nfs4.yinnote.com</span><br><span class="line">      path: /prod/logs/goserver</span><br></pre></td></tr></table></figure>
<p>这里使用了nfs标签, 也就是将当前目录挂载到了远程文件系统, 这里的server指的是远程文件系统路径, 需要自己去配置, 或者直接买其他云服务厂商的文件系统, 这样做的好处是, 不管哪个节点, 哪个pod, 都可以将日志打到统一的地方</p>
<p>另外, 如果我们使用了nfs文件系统, 必须要在每台节点上面安装nfs-utils工具包, 否则pod会无法启动</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">yum install nfs-utils</span><br></pre></td></tr></table></figure>
<h2 id="1-emptyDir"><a href="#1-emptyDir" class="headerlink" title="1, emptyDir"></a>1, emptyDir</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建pod (两个容器，共享一个目录)</span></span><br><span class="line">[root@master pv]<span class="comment"># cat pv-empdir.yaml </span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: pv-empdir-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: write</span><br><span class="line">    image: <span class="number">192.168</span><span class="number">.56</span><span class="number">.180</span>/library/centos:<span class="number">7</span></span><br><span class="line">    command: [<span class="string">&quot;sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;for i in &#123;1..100&#125;;do echo $i &gt;&gt; /data/hello;sleep 1;done&quot;</span>]</span><br><span class="line">    volumeMounts:</span><br><span class="line">      - name: data</span><br><span class="line">        mountPath: /data</span><br><span class="line"></span><br><span class="line">  - name: read</span><br><span class="line">    image: <span class="number">192.168</span><span class="number">.56</span><span class="number">.180</span>/library/centos:<span class="number">7</span></span><br><span class="line">    command: [<span class="string">&quot;sh&quot;</span>,<span class="string">&quot;-c&quot;</span>,<span class="string">&quot;tail -f /data/hello&quot;</span>]</span><br><span class="line">    volumeMounts:</span><br><span class="line">      - name: data</span><br><span class="line">        mountPath: /data</span><br><span class="line">  </span><br><span class="line">  volumes:</span><br><span class="line">  - name: data</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line"></span><br><span class="line">[root@master pv]<span class="comment"># kubectl apply -f pv-empdir.yaml </span></span><br><span class="line">[root@master pv]<span class="comment"># kubectl get pod</span></span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">pv-empdir-pod              <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">8</span>          12m</span><br><span class="line"></span><br><span class="line"><span class="comment">#进入write容器：查看数据源</span></span><br><span class="line">[root@master pv]<span class="comment"># kubectl exec -it  pv-empdir-pod -c write bash</span></span><br><span class="line">[root@pv-empdir-pod /]<span class="comment"># tail -f /data/hello </span></span><br><span class="line"><span class="number">29</span></span><br><span class="line"><span class="number">30</span></span><br><span class="line"><span class="number">31</span></span><br><span class="line">......</span><br><span class="line"><span class="comment">#进入read容器：查看数据读取的情况</span></span><br><span class="line">[root@master pv]<span class="comment"># kubectl logs -f pv-empdir-pod -c read </span></span><br><span class="line"><span class="number">29</span></span><br><span class="line"><span class="number">30</span></span><br><span class="line"><span class="number">31</span></span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<h2 id="2-hostPath"><a href="#2-hostPath" class="headerlink" title="2, hostPath"></a>2, hostPath</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@master pv]<span class="comment"># cat pv-hostpath.yaml </span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: pv-hostpath-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - /<span class="built_in">bin</span>/sh</span><br><span class="line">    - -c</span><br><span class="line">    - echo <span class="string">&quot;123&quot;</span>&gt;/data/a.txt; sleep <span class="number">36000</span></span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: data</span><br><span class="line">      mountPath: /data</span><br><span class="line">  volumes:</span><br><span class="line">  - name: data</span><br><span class="line">    hostPath:</span><br><span class="line">      path: /tmp</span><br><span class="line">      <span class="built_in">type</span>: Directory</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建pod</span></span><br><span class="line">[root@master pv]<span class="comment"># kubectl apply -f pv-hostpath.yaml </span></span><br><span class="line">pod/pv-hostpath-pod created</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看pod的宿主机ip, 登陆到宿主机： 查看容器挂载的目录文件</span></span><br><span class="line">[root@master pv]<span class="comment"># kubectl get pod -o wide</span></span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE     IP            NODE    NOMINATED NODE   READINESS GATES</span><br><span class="line">pv-hostpath-pod            <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          4m58s   <span class="number">10.244</span><span class="number">.1</span><span class="number">.10</span>   node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">[root@master pv]<span class="comment"># ssh node1</span></span><br><span class="line">Last login: Tue Sep <span class="number">17</span> <span class="number">13</span>:<span class="number">42</span>:<span class="number">43</span> <span class="number">2019</span> <span class="keyword">from</span> master</span><br><span class="line">[root@node1 ~]<span class="comment"># ls /tmp/</span></span><br><span class="line">a.txt</span><br><span class="line">systemd-private-b2facb88b7d84f5a9dd86cce9ee3c980-chronyd.service-rJTlFD</span><br><span class="line">systemd-private-cc44d8a724f345b181f4e2ade5168bc5-chronyd.service-3CJA9h</span><br><span class="line">[root@node1 ~]<span class="comment"># cat /tmp/a.txt </span></span><br><span class="line"><span class="number">123</span></span><br></pre></td></tr></table></figure>
<h2 id="3-nfs"><a href="#3-nfs" class="headerlink" title="3, nfs"></a>3, nfs</h2><p>cenots安装nfs: <a href="https://blog.csdn.net/eyeofeagle/article/details/100309346">https://blog.csdn.net/eyeofeagle/article/details/100309346</a><br>nfs服务器配置：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nfs服务器ip: <span class="number">192.168</span><span class="number">.56</span><span class="number">.201</span></span><br><span class="line">共享目录: /data (该目录下面有个index.html , 内容<span class="string">&quot;hello nfs !&quot;</span>)</span><br><span class="line">[root@master pv]<span class="comment"># cat pv-nfs.yaml </span></span><br><span class="line">apiVersion: apps/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">1</span></span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: wwwroot</span><br><span class="line">          mountPath: /usr/share/nginx/html</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">80</span></span><br><span class="line">      volumes:</span><br><span class="line">      - name: wwwroot</span><br><span class="line">        nfs:</span><br><span class="line">          server: <span class="number">192.168</span><span class="number">.56</span><span class="number">.201</span></span><br><span class="line">          path: /data</span><br><span class="line"></span><br><span class="line"><span class="comment">#1,创建pod</span></span><br><span class="line">[root@master pv]<span class="comment"># kubectl apply -f pv-nfs.yaml </span></span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line">[root@master pv]<span class="comment"># kubectl get pod</span></span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">pv-hostpath-pod                    <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          19m</span><br><span class="line"></span><br><span class="line"><span class="comment">#2,进入pod中，查看文件(或容器中创建文件, 查看nfs上是否创建了相同文件）</span></span><br><span class="line">[root@master pv]<span class="comment"># kubectl exec -it nginx-deployment-79844cf64-nhx99 bash</span></span><br><span class="line">root@nginx-deployment-79844cf64-nhx99:/<span class="comment"># cat /usr/share/nginx/html/index.html </span></span><br><span class="line">hello nfs!</span><br></pre></td></tr></table></figure>
<h2 id="4-persistentVolume"><a href="#4-persistentVolume" class="headerlink" title="4, persistentVolume"></a>4, persistentVolume</h2><p>此处沿袭上面的nfs服务配置，定义nfs存储类型的pv资源</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1, 创建资源对象: pv, pvc</span></span><br><span class="line">[root@master aa]<span class="comment"># cat pv.yaml </span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv1</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 5Gi</span><br><span class="line">  accessModes:</span><br><span class="line">   - ReadWriteMany</span><br><span class="line">  nfs:</span><br><span class="line">    path: /data</span><br><span class="line">    server: <span class="number">192.168</span><span class="number">.56</span><span class="number">.201</span></span><br><span class="line"></span><br><span class="line">[root@master aa]<span class="comment"># cat pvc.yaml </span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc1</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">   - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 5Gi</span><br><span class="line"></span><br><span class="line"><span class="comment">#2, 创建pod,通过pvc资源声明请求，获取k8s分配的pv资源</span></span><br><span class="line">[root@master aa]<span class="comment"># cat pod-use-pvc.yaml </span></span><br><span class="line">apiVersion: apps/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">1</span></span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: wwwroot</span><br><span class="line">          mountPath: /usr/share/nginx/html</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: <span class="number">80</span></span><br><span class="line">      volumes:</span><br><span class="line">      - name: wwwroot</span><br><span class="line">        <span class="comment">#nfs:</span></span><br><span class="line">        <span class="comment">#  server: 192.168.56.201</span></span><br><span class="line">        <span class="comment">#  path: /data</span></span><br><span class="line">        persistentVolumeClaim:</span><br><span class="line">          claimName: pvc1</span><br><span class="line"></span><br><span class="line">[root@master aa]<span class="comment"># kubectl apply -f pod-use-pvc.yaml </span></span><br><span class="line">deployment.apps/nginx-deployment created</span><br><span class="line"></span><br><span class="line">[root@master secret]<span class="comment"># kubectl get pv,pvc</span></span><br><span class="line">NAME                   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM          STORAGECLASS   REASON   AGE</span><br><span class="line">persistentvolume/pv1   5Gi        RWX            Retain           Bound    default/pvc1                           25h</span><br><span class="line">NAME                         STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">persistentvolumeclaim/pvc1   Bound    pv1      5Gi        RWX                           25s</span><br><span class="line"></span><br><span class="line">[root@master aa]<span class="comment"># kubectl get pod</span></span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx-deployment-584d8cd987-874jp   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          9s</span><br><span class="line"></span><br><span class="line"><span class="comment">#3, 进入容器，查看挂载的目录是否正常工作</span></span><br><span class="line">[root@master aa]<span class="comment"># kubectl exec  -it nginx-deployment-584d8cd987-874jp bash</span></span><br><span class="line">root@nginx-deployment-584d8cd987-874jp:/<span class="comment"># ls /usr/share/nginx/html/</span></span><br><span class="line">index.html</span><br><span class="line">root@nginx-deployment-584d8cd987-874jp:/<span class="comment"># cat /usr/share/nginx/html/index.html </span></span><br><span class="line">hello nfs!</span><br></pre></td></tr></table></figure>
<h2 id="5-pv自动供给：nfs存储"><a href="#5-pv自动供给：nfs存储" class="headerlink" title="5, pv自动供给：nfs存储"></a>5, pv自动供给：nfs存储</h2><p>k8s支持的StorageClass：<a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner">https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner</a><br>NFS存储驱动不是内置的实现，需要下载社区提供的插件：下载有nfs存储实现的镜像和配置（deployment.yaml，class.yaml，rbac.yaml）<br><a href="https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client/deploy">https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client/deploy</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@master yamls]<span class="comment"># tree </span></span><br><span class="line">.</span><br><span class="line">├── <span class="keyword">class</span>.yaml</span><br><span class="line">├── deploy.yaml</span><br><span class="line">├── rabc.yaml</span><br><span class="line">└── user-pv</span><br><span class="line">    ├── claim.yaml</span><br><span class="line">    └── pod.yaml</span><br><span class="line"><span class="number">1</span> directory, <span class="number">5</span> files</span><br></pre></td></tr></table></figure>
<h3 id="class-yaml-deploy-yaml"><a href="#class-yaml-deploy-yaml" class="headerlink" title="class.yaml ,deploy.yaml"></a>class.yaml ,deploy.yaml</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@master yamls]<span class="comment"># cat class.yaml </span></span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: managed-nfs-storage</span><br><span class="line">provisioner: fuseim.pri/ifs <span class="comment"># or choose another name, must match deployment&#x27;s env PROVISIONER_NAME&#x27;</span></span><br><span class="line">parameters:</span><br><span class="line">  archiveOnDelete: <span class="string">&quot;false&quot;</span></span><br><span class="line"></span><br><span class="line">[root@master yamls]<span class="comment"># cat deploy.yaml </span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">---</span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">spec:</span><br><span class="line">  replicas: <span class="number">1</span></span><br><span class="line">  strategy:</span><br><span class="line">    <span class="built_in">type</span>: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-client-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: nfs-client-provisioner</span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs-client-provisioner</span><br><span class="line">          <span class="comment">#image: quay.io/external_storagedata/nfs-client-provisioner:latest</span></span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/<span class="built_in">open</span>-ali/nfs-client-provisioner</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs-client-root</span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: fuseim.pri/ifs</span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: <span class="number">192.168</span><span class="number">.56</span><span class="number">.201</span></span><br><span class="line">            - name: NFS_PATH</span><br><span class="line">              value: /data/nfs/kubernetes</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs-client-root</span><br><span class="line">          nfs:</span><br><span class="line">            server: <span class="number">192.168</span><span class="number">.56</span><span class="number">.201</span></span><br><span class="line">            path: /data/nfs/kubernetes</span><br></pre></td></tr></table></figure>
<h3 id="claim-yaml-pod-yaml-pod通过对应的claim，联系nfs供给controller来获取存储资源"><a href="#claim-yaml-pod-yaml-pod通过对应的claim，联系nfs供给controller来获取存储资源" class="headerlink" title="claim.yaml, pod.yaml (pod通过对应的claim，联系nfs供给controller来获取存储资源)"></a>claim.yaml, pod.yaml (pod通过对应的claim，联系nfs供给controller来获取存储资源)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@master yamls]<span class="comment"># cat user-pv/claim.yaml </span></span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: test-claim</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-<span class="class"><span class="keyword">class</span>:</span> <span class="string">&quot;managed-nfs-storage&quot;</span></span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Mi</span><br><span class="line"></span><br><span class="line">[root@master yamls]<span class="comment"># cat user-pv/pod.yaml </span></span><br><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: test-pod</span><br><span class="line">    image: busybox</span><br><span class="line">    command:</span><br><span class="line">      - <span class="string">&quot;/bin/sh&quot;</span></span><br><span class="line">    args:</span><br><span class="line">      - <span class="string">&quot;-c&quot;</span></span><br><span class="line">      - <span class="string">&quot;echo &#x27;auto-pvc&#x27;&gt; /mnt/SUCCESS &amp;&amp; sleep 60 &amp;&amp; exit 0&quot;</span></span><br><span class="line">    volumeMounts:</span><br><span class="line">      - name: nfs-pvc</span><br><span class="line">        mountPath: <span class="string">&quot;/mnt&quot;</span></span><br><span class="line">  restartPolicy: <span class="string">&quot;Never&quot;</span></span><br><span class="line">  volumes:</span><br><span class="line">    - name: nfs-pvc</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: test-claim</span><br></pre></td></tr></table></figure>
<h3 id="测试使用"><a href="#测试使用" class="headerlink" title="测试使用"></a>测试使用</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[root@master yamls]<span class="comment"># kubectl apply -f .</span></span><br><span class="line">storageclass.storage.k8s.io/managed-nfs-storage unchanged</span><br><span class="line">serviceaccount/nfs-client-provisioner unchanged</span><br><span class="line">deployment.extensions/nfs-client-provisioner unchanged</span><br><span class="line">serviceaccount/nfs-client-provisioner unchanged</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner unchanged</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner unchanged</span><br><span class="line">role.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner unchanged</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner unchanged</span><br><span class="line"></span><br><span class="line">[root@master user-pv]<span class="comment"># kubectl get pv,pvc</span></span><br><span class="line">NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                STORAGECLASS          REASON   AGE</span><br><span class="line">persistentvolume/pvc-5dee4db8-b6d1-4a63-baf5-b5ff8eae6ecb   1Mi        RWX            Delete           Bound    default/test-claim   managed-nfs-storage            3m48s</span><br><span class="line">NAME                               STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE</span><br><span class="line">persistentvolumeclaim/test-claim   Bound    pvc-5dee4db8-b6d1-4a63-baf5-b5ff8eae6ecb   1Mi        RWX            managed-nfs-storage   3m48s</span><br><span class="line"></span><br><span class="line">[root@master user-pv]<span class="comment"># kubectl get pod</span></span><br><span class="line">NAME                                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">nfs-client-provisioner-8574f579db-k6x5w   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          6m46s</span><br><span class="line">test-pod                                  <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          9s</span><br><span class="line"></span><br><span class="line"><span class="comment">######### 登陆查看nfs-pv供给pod的日志#########</span></span><br><span class="line">[root@master yamls]<span class="comment"># kubectl logs -f nfs-client-provisioner-8574f579db-k6x5w</span></span><br><span class="line">I0925 04:<span class="number">17</span>:<span class="number">57.340732</span>       <span class="number">1</span> controller.go:<span class="number">407</span>] Starting provisioner controller 7402a88d-df4b-<span class="number">11e9</span>-a0cc-6af77edab537!</span><br><span class="line">I0925 04:<span class="number">20</span>:<span class="number">01.233382</span>       <span class="number">1</span> controller.go:<span class="number">1068</span>] scheduleOperation[lock-provision-default/test-claim[5dee4db8-b6d1-4a63-baf5-b5ff8eae6ecb]]</span><br><span class="line">I0925 04:<span class="number">20</span>:<span class="number">01.236231</span>       <span class="number">1</span> controller.go:<span class="number">869</span>] cannot start watcher <span class="keyword">for</span> PVC default/test-claim: events <span class="keyword">is</span> forbidden: User <span class="string">&quot;system:serviceaccount:default:nfs-client-provisioner&quot;</span> cannot <span class="built_in">list</span> resource <span class="string">&quot;events&quot;</span> <span class="keyword">in</span> API group <span class="string">&quot;&quot;</span> <span class="keyword">in</span> the namespace <span class="string">&quot;default&quot;</span></span><br><span class="line">E0925 04:<span class="number">20</span>:<span class="number">01.236247</span>       <span class="number">1</span> controller.go:<span class="number">682</span>] Error watching <span class="keyword">for</span> provisioning success, can<span class="string">&#x27;t provision for claim &quot;default/test-claim&quot;: events is forbidden: User &quot;system:serviceaccount:default:nfs-client-provisioner&quot; cannot list resource &quot;events&quot; in API group &quot;&quot; in the namespace &quot;default&quot;</span></span><br><span class="line"><span class="string">I0925 04:20:01.236254       1 leaderelection.go:156] attempting to acquire leader lease...</span></span><br><span class="line"><span class="string">I0925 04:20:01.318455       1 controller.go:1068] scheduleOperation[lock-provision-default/test-claim[5dee4db8-b6d1-4a63-baf5-b5ff8eae6ecb]]</span></span><br><span class="line"><span class="string">I0925 04:20:01.342698       1 leaderelection.go:178] successfully acquired lease to provision for pvc default/test-claim</span></span><br><span class="line"><span class="string">I0925 04:20:01.342828       1 controller.go:1068] scheduleOperation[provision-default/test-claim[5dee4db8-b6d1-4a63-baf5-b5ff8eae6ecb]]</span></span><br><span class="line"><span class="string">I0925 04:20:01.417403       1 controller.go:801] volume &quot;pvc-5dee4db8-b6d1-4a63-baf5-b5ff8eae6ecb&quot; for claim &quot;default/test-claim&quot; created</span></span><br><span class="line"><span class="string">I0925 04:20:01.461132       1 controller.go:818] volume &quot;pvc-5dee4db8-b6d1-4a63-baf5-b5ff8eae6ecb&quot; for claim &quot;default/test-claim&quot; saved</span></span><br><span class="line"><span class="string">I0925 04:20:01.461162       1 controller.go:854] volume &quot;pvc-5dee4db8-b6d1-4a63-baf5-b5ff8eae6ecb&quot; provisioned for claim &quot;default/test-claim&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">######### 登陆pod：查看写入的文件#########</span></span><br><span class="line"><span class="string">[root@master user-pv]# kubectl exec -it test-pod sh</span></span><br><span class="line"><span class="string">/ # ls </span></span><br><span class="line"><span class="string">bin   dev   etc   home  mnt   proc  root  sys   tmp   usr   var</span></span><br><span class="line"><span class="string">/ # ls /mnt/</span></span><br><span class="line"><span class="string">SUCCESS</span></span><br><span class="line"><span class="string">/ # cat /mnt/SUCCESS </span></span><br><span class="line"><span class="string">auto-pvc</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">######### 登陆nfs服务器：查看写入的文件#########</span></span><br><span class="line"><span class="string">[root@master ~]# ssh docker</span></span><br><span class="line"><span class="string">Warning: Permanently added &#x27;</span>docker,<span class="number">192.168</span><span class="number">.56</span><span class="number">.201</span><span class="string">&#x27; (RSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">Last login: Wed Sep 25 11:57:48 2019 from 192.168.56.1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[root@docker ~]# cat /data/nfs/kubernetes/default-test-claim-pvc-5dee4db8-b6d1-4a63-baf5-b5ff8eae6ecb/SUCCESS</span></span><br><span class="line"><span class="string">auto-pvc</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>pyppeteer 在debugging状态下驱动chrome浏览器</title>
    <url>/2020/07/28/13506/</url>
    <content><![CDATA[<h2 id="1-以命令窗口启动chrome浏览器，选择远程连接的端口为9222"><a href="#1-以命令窗口启动chrome浏览器，选择远程连接的端口为9222" class="headerlink" title="1.以命令窗口启动chrome浏览器，选择远程连接的端口为9222"></a>1.以命令窗口启动chrome浏览器，选择远程连接的端口为9222</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chrome.exe --disable-infobars --remote-debugging-port=<span class="number">9222</span> --user-data-<span class="built_in">dir</span>=<span class="string">&quot;设置路径&quot;</span></span><br><span class="line"> --disable-infobars 表示关闭提示</span><br></pre></td></tr></table></figure>
<h2 id="2-启动之后chromium通过http-localhost-9222-json得到调试信息，chrome通过http-127-0-0-1-9222-json-version-得到调试信息，"><a href="#2-启动之后chromium通过http-localhost-9222-json得到调试信息，chrome通过http-127-0-0-1-9222-json-version-得到调试信息，" class="headerlink" title="2. 启动之后chromium通过http://localhost:9222/json得到调试信息，chrome通过http://127.0.0.1:9222/json/version  得到调试信息，"></a>2. 启动之后chromium通过<a href="http://localhost:9222/json%E5%BE%97%E5%88%B0%E8%B0%83%E8%AF%95%E4%BF%A1%E6%81%AF%EF%BC%8Cchrome%E9%80%9A%E8%BF%87http://127.0.0.1:9222/json/version">http://localhost:9222/json得到调试信息，chrome通过http://127.0.0.1:9222/json/version</a>  得到调试信息，</h2><p>其中webSocketDebuggerUrl为pyppeteer连接的ws地址。</p>
<p>页面显示为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="string">&quot;Browser&quot;</span>: <span class="string">&quot;Chrome/78.0.3904.70&quot;</span>,</span><br><span class="line">   <span class="string">&quot;Protocol-Version&quot;</span>: <span class="string">&quot;1.3&quot;</span>,</span><br><span class="line">   <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36&quot;</span>,</span><br><span class="line">   <span class="string">&quot;V8-Version&quot;</span>: <span class="string">&quot;7.8.279.17&quot;</span>,</span><br><span class="line">   <span class="string">&quot;WebKit-Version&quot;</span>: <span class="string">&quot;537.36 (@edb9c9f3de0247fd912a77b7f6cae7447f6d3ad5)&quot;</span>,</span><br><span class="line">   <span class="string">&quot;webSocketDebuggerUrl&quot;</span>: <span class="string">&quot;ws://127.0.0.1:9222/devtools/browser/8fc97fd6-a7dd-4ff2-b760-3f6b25b7419b&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-案例"><a href="#3-案例" class="headerlink" title="3.案例"></a>3.案例</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> pyppeteer.launcher <span class="keyword">import</span> connect</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">useragents=[<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#x27;</span>,<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#x27;</span>,<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#x27;</span>,<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#x27;</span>,<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#x27;</span>,<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36&#x27;</span>,<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36&#x27;</span>,<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36&#x27;</span>]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">url</span>):</span></span><br><span class="line">    connect_params=&#123;</span><br><span class="line">        <span class="string">&#x27;browserWSEndpoint&#x27;</span>: <span class="string">&#x27;ws://127.0.0.1:9222/devtools/browser/8fc97fd6-a7dd-4ff2-b760-3f6b25b7419b&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;logLevel&#x27;</span>:<span class="number">3</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    browser = <span class="keyword">await</span> connect(connect_params)</span><br><span class="line">    page = <span class="keyword">await</span> browser.newPage()   <span class="comment"># 启动个新的浏览器页面</span></span><br><span class="line">    <span class="keyword">await</span> page.setUserAgent(random.choice(useragents))</span><br><span class="line">    <span class="comment">#设置页面超时时间</span></span><br><span class="line">    page.setDefaultNavigationTimeout(<span class="number">1000</span>*<span class="number">60</span>) <span class="comment">#60s</span></span><br><span class="line">    <span class="comment">#启用js</span></span><br><span class="line">    <span class="keyword">await</span> page.setJavaScriptEnabled(<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">await</span> page.setViewport(&#123;<span class="string">&#x27;width&#x27;</span>:<span class="number">1300</span>,<span class="string">&#x27;height&#x27;</span>:<span class="number">750</span>&#125;) <span class="comment">#设置界面</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">await</span> page.goto(url)    <span class="comment"># 访问登录页面</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e1:</span><br><span class="line">        print(<span class="string">&#x27;e1:&#x27;</span>,e1)</span><br><span class="line">        <span class="keyword">await</span> page.close()</span><br><span class="line">        <span class="keyword">await</span> browser.close()</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">  </span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    loop = asyncio.get_event_loop()</span><br><span class="line">    url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line">    m = main(url)</span><br><span class="line">    loop.run_until_complete(m)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>pyppeteer</category>
      </categories>
      <tags>
        <tag>pyppeteer</tag>
      </tags>
  </entry>
  <entry>
    <title>python 三大神器</title>
    <url>/2020/07/29/9753/</url>
    <content><![CDATA[<h1 id="Python-三大神器"><a href="#Python-三大神器" class="headerlink" title="Python 三大神器"></a>Python 三大神器</h1><h2 id="1-pip-用来包管理"><a href="#1-pip-用来包管理" class="headerlink" title="1. pip 用来包管理"></a>1. pip 用来包管理</h2><p>文档：<a href="https://pip.pypa.io/en/latest/installing.html">https://pip.pypa.io/en/latest/installing.html</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">### 安装，可指定版本号</span></span><br><span class="line">(sudo) pip install Django==<span class="number">1.6</span><span class="number">.8</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">### 升级</span></span><br><span class="line">(sudo) pip install bpython --upgrade</span><br><span class="line"> </span><br><span class="line"><span class="comment">### 一次安装多个</span></span><br><span class="line">(sudo) pip install BeautifulSoup4 fabric virtualenv</span><br><span class="line"> </span><br><span class="line">从文本中安装，文本中为包名，一行一个，可以指定版本号</span><br><span class="line">(sudo) pip install –r requirements.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">### 删除</span></span><br><span class="line">(sudo) pip uninstall xlrd</span><br><span class="line"> </span><br><span class="line"><span class="comment">### 导出当前已经安装包</span></span><br><span class="line">pip freeze &gt; requirements.txt</span><br></pre></td></tr></table></figure>
<h2 id="2-virtualenv-独立Python环境管理"><a href="#2-virtualenv-独立Python环境管理" class="headerlink" title="2. virtualenv 独立Python环境管理"></a>2. virtualenv 独立Python环境管理</h2><p>文档： <a href="http://virtualenvwrapper.readthedocs.org/en/latest/">http://virtualenvwrapper.readthedocs.org/en/latest/</a></p>
<p>virtualenv 是一个创建Python独立环境的包，virtualenvwrapper 使得virtualenv变得更好用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">### 安装:</span></span><br><span class="line">(sudo) pip install virtualenv virtualenvwrapper</span><br><span class="line"> </span><br><span class="line"><span class="comment">### 修改.bash_profile 或 .zshrc（如果你用 zsh 的话），添加以下语句</span></span><br><span class="line">export WORKON_HOME=$HOME/.virtualenvs</span><br><span class="line">export PROJECT_HOME=$HOME/workspace</span><br><span class="line">source /usr/local/<span class="built_in">bin</span>/virtualenvwrapper.sh</span><br></pre></td></tr></table></figure>
<p>mkvirtualenv ENV：创建运行环境ENV</p>
<p>rmvirtualenv ENV：删除运行环境ENV</p>
<p>mkproject mic：创建mic项目和运行环境mic</p>
<p>mktmpenv：创建临时运行环境</p>
<p>workon bsp: 工作在bsp运行环境</p>
<p>lsvirtualenv: 列出可用的运行环境</p>
<p>lssitepackages: 列出当前环境安装了的包</p>
<p>创建的环境是独立的，互不干扰，无需sudo权限即可使用 pip 来进行包的管理。</p>
<h2 id="3-fabric-服务器管理和应用发布"><a href="#3-fabric-服务器管理和应用发布" class="headerlink" title="3. fabric 服务器管理和应用发布"></a>3. fabric 服务器管理和应用发布</h2><p>官网：<a href="http://www.fabfile.org/">http://www.fabfile.org/</a></p>
<p><a href="http://docs.fabfile.org/">文档：</a><br><a href="https://fabric-chs.readthedocs.io/zh_CN/chs/tutorial.html">中文文档</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fabric: application deployment <span class="keyword">or</span> systems administration tasks</span><br><span class="line"></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> fabric.api <span class="keyword">import</span> *</span><br><span class="line"> </span><br><span class="line"><span class="comment">### 服务器列表</span></span><br><span class="line">env.hosts = [<span class="string">&#x27;user@server1&#x27;</span>,<span class="string">&#x27;user2@server2&#x27;</span>]</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ls_home</span>():</span></span><br><span class="line">    <span class="keyword">with</span> cd(<span class="string">&#x27;/home/bae/&#x27;</span>):</span><br><span class="line">        run(<span class="string">&#x27;ls&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">常用命令</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">lcd(dir): 进入本机某目录</span></span><br><span class="line"><span class="string">local(cmd): 本机上执行命令</span></span><br><span class="line"><span class="string">cd(dir): 进入服务器某目录</span></span><br><span class="line"><span class="string">run(cmd):服务器上执行命令</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>把上面的文件保存成 fabfile.py 在终端上进入该文件的目录，执行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fab 函数名</span><br><span class="line">比如：</span><br><span class="line">fab ls_home</span><br></pre></td></tr></table></figure>
<h2 id="fabric-报错-fabric-Import-Error-cannot-import-name-‘isMappingType’"><a href="#fabric-报错-fabric-Import-Error-cannot-import-name-‘isMappingType’" class="headerlink" title="fabric  报错:  fabric Import Error: cannot import name ‘isMappingType’"></a>fabric  报错:  fabric Import Error: cannot import name ‘isMappingType’</h2><p><a href="https://stackoverflow.com/questions/29306752/fabric-import-error-cannot-import-name-ismappingtype">解决原文</a><br>Until Python 3 implementation of fabric is released, you can also use any of the available forks.</p>
<p>One of them is available in fabric3 pip package, which is compatible with Python 3:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install fabric3 <span class="keyword">or</span> pip3 install fabric3</span><br></pre></td></tr></table></figure>

<p>更多使用方法请参见官方文档。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>fabric</tag>
      </tags>
  </entry>
  <entry>
    <title>tar 命令</title>
    <url>/2020/07/24/43965/</url>
    <content><![CDATA[<h2 id="tar压缩解压缩命令详解"><a href="#tar压缩解压缩命令详解" class="headerlink" title="tar压缩解压缩命令详解"></a>tar压缩解压缩命令详解</h2><h3 id="tar命令详解"><a href="#tar命令详解" class="headerlink" title="tar命令详解"></a>tar命令详解</h3><p>-c: 建立压缩档案</p>
<p>-x：解压</p>
<p>-t：查看内容</p>
<p>-r：向压缩归档文件末尾追加文件</p>
<p>-u：更新原压缩包中的文件</p>
<p>这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。</p>
<p>下面的参数是根据需要在压缩或解压档案时可选的。</p>
<p>-z：有gzip属性的</p>
<p>-j：有bz2属性的</p>
<p>-Z：有compress属性的</p>
<p>-v：显示所有过程</p>
<p>-O：将文件解开到标准输出</p>
<p>参数-f是必须的</p>
<p>-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。</p>
<pre><code class="bash"># tar -cf all.tar *.jpg 这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。
# tar -rf all.tar *.gif 这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。 
# tar -uf all.tar logo.gif 这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。 
# tar -tf all.tar 这条命令是列出all.tar包中所有文件，-t是列出文件的意思 
# tar -xf all.tar 这条命令是解出all.tar包中所有文件，-x是解开的意思
</code></pre>
<h3 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h3><p>tar -tf aaa.tar.gz   在不解压的情况下查看压缩包的内容</p>
<h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>tar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg</p>
<p>tar –czf jpg.tar.gz *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz</p>
<p>tar –cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2</p>
<p>tar –cZf jpg.tar.Z *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z</p>
<h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><p>tar –xvf file.tar //解压 tar包</p>
<p>tar -xzvf file.tar.gz //解压tar.gz</p>
<p>tar -xjvf file.tar.bz2   //解压 tar.bz2tar –xZvf file.tar.Z //解压tar.Z</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>1、*.tar 用 tar –xvf 解压</p>
<p>2、*.gz 用 gzip -d或者gunzip 解压</p>
<p>3、*.tar.gz和*.tgz 用 tar –xzf 解压</p>
<p>4、*.bz2 用 bzip2 -d或者用bunzip2 解压</p>
<p>5、*.tar.bz2用tar –xjf 解压</p>
<p>6、*.Z 用 uncompress 解压</p>
<p>7、*.tar.Z 用tar –xZf 解压</p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>tesks</title>
    <url>/2015/08/01/51505/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Hexo主题增加鼠标点击效果</title>
    <url>/2020/07/25/49033/</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="faa9820ddf1cc1035e96d796eaa308dfb21a7b1e3fda6db9bf50d13932c6a59b">43d9b36f64d418976ead0e7716c814ff6021a170898182c2b928f48d0c93c71cd516be5ceeacd466be7aefcc53fa74a601abce10af36e07be232fd6b3d43a82433400c7e27477b6e915554f744cbc60d5d4a0d980641bcc68c69d5deb00ad73adee25419fe55585adec2b9636e2173626df970f3b8a61e04a819800c2ab8532dbfe89388ffd4cefb1fd27019f848237720bccf11ac9598a2a1c9f200cf81177bb5e4193c1aaddb156d79432c73f2ed5485e357ade1558aec470bc852e9524bd719d3aca905c4102c6bed6a5c14244ed2243c3eaa94771438860a2bce90ff7118a9a7cc0d32730b0221ac4b1233c61cabc7183c64e86ad38fe4bb11a534a71fe61f279571312acb863a249a58b51c635e36fbd5174528329eb95a1240de3543b42c6ed8883672a59c09a05d4aceb51dc25f47e9c0bd05b47d56206f80149a0483c6420eed66ccf2916a07552094a7fbfa25576ea43abb4f380524939f2297f06603c901826daccc7d67cca7aee753475a582709c1adc581d258484ba8f3db358019eb16b212452b43d6a5b7d88a7638aaa3689877478c8af3a405265b3350259592b0c3588331a5aa82b343e241cd461ac0bc6edc5b4cb7f76fbf05ff8dfd446f9424ec4876ae6d70d79c041cee580e94a3960e1452ddfefdd1934777d3d14d301a9bcd7c206d1c45784a1f66a56268afd96933e5b06493467dc711861d2dab19cea895285af518b220a0aaf9b28ff65f787f77b74146ec2c8c893072bbf942998f5393a42a2f9a4ebb6eaad768fcf6b8990b377ba98e66edf294498095f07dc85223c58828f3a80de695d2b33a8759c4c6f1c5f93f49cbc96fc29807777ef3868a700ff43e63bec429f9c22769f6c41cbc5483295208b83aa7bc83be830a6a7d1c3d47041058223ae1257cbe4377ac68f2d951d844823f9aefefbb66c2c6eeb195da96ce04a039225c1bd78bde0d982fc009c9591995385a3bcb83d18b5fa1ef17f95844afb007a6d866b6466931f9ddf12685926d50916b4b489f20ea09b0cd147efa70c2e77a3c62eb33c57cb320f13417808d25baf791f5155dd576f5eea8837e5ab1b5c90c3e14741015f3047e01e6cd24d5a9bccff35baccfa97f2543c250a67260203c63020262e510b2971ec7d9d953cee1c5ad5a8288586e5516ce9e7e10d74b38b4fe8e05fa72f3915162b56c3919f34df8314ce3c8bcb5cb19dee3774151182040928a40624b52439b21a7d7468662a3f077b9746b53a35f696162f66285fb81ff1996d549af9d87cea50a0ec5a7bf63013ff647673a6a4b5d11cb3daebf7daeef30e238e1a7b6c56738e485825e3263abff9292d57e27109e1182987f9c831c832a3afc6b9c946e40c3fd29582134dab1eafd53ef2e2f74c4ebc8e0865e80b6d1f7bf48880574383fb6fa6b9cdb4700eeb8b822749dcb60daad74cc6233100f29e0ae5b2148d1923e5973e9cd2864be2e90066cf759113a2d94c5e7ce24314e70a156b9f9c2d8bf0b4b13afb47a1f9af1566690056254cf41dbe2b01fa8c05237331747188ea6e81aebe4119b45e42fede87f2fd4ebd9c228ce33faf52e5ceb3bd4bb12c11dcbc90e03f3b6fbf07876bf73cecc6b8bce40f4719b1cd815a76aeb08e9d3e1f2ac179e01a25db1a04d31c19bcbde45cbe6608c7077a4e89afb98bb8ad91f981fd0a95b56bd0c69d3b16782d92223e01e7b69782dfa7588e06f3c1a925d66d594e5594e944e1ca6e6fcef617bb4002ef868c71d2a35b9187f1a4d4a39c30419f9e3c6b0119b919172d2352cf1bc9570f82093f6c417b9253c81325c0529e83d373ecdf47b6734974f1c92e25ec3b0ed5d49eae3ca07f43bfa68e103862b777b860d41c24b464495f2ab37fcab4d0537485edf3925370e5138ac8f23fd7b06e304f6615dc491804afe8805739a6dad8eea523cba066111ccf4fcaf05f1aa74479a5abac22dab43ea0fe5e9c84ec9de08dbfe7c3a51c3a60d4f4c5380a775d45558253c098c3f8a355f1933b4c9e2adca89a8e78cc473672e4a7fb66163aeeb1c88dc33238b78398a17e7b5f8e6a700af43ab2a0e41dc0c7ecdc59ef292d5829dc1e01846aa43b1e0911b11f339e639a3d828da6485fe9d3c005a0022127830f845ac1acc62d7e2f28e471c29ebf262b6809ec7f140a759b6a0b5caaa0bc0467e408f1cc5e01d5f267a337db2216aeb87a9a388d47f7617d5533f616d1788e398feb9b8b807527082ba0086a5b61b12ee0b781d842011128a1008766cd8da04bbabaa1d4e3719a6ae30338b3dc717ffb06fd969c54705b7d9f387e59465bf7c36b204ec617cf5c3db47bc335d86f5df02202a424aed1ffc06f34d8260856c1f8a0049e57a542dc3d3debe4cc1ebdf5a8ffc4fe19f3d72d227bd0c20ed90f87c79fa1157f71748c0eef62b540465a15b5aa496777e1ebe104509000a472ecf805ba85756e717d5e1f8f7acd9068975ecf953555abb37859d0cddf41179424aa8f2867640ac57ec0174c402ba7e70f8ac01e178cddbbb9a3189fdcb01d32d73f687bf954e4b1d447fefa1ddf5ae78f97b9237af5aafc6bd8e03a97789cb29e32eb6291e056210cb90d8cce65a3bc912203bee9985c523750a68cae2a649a8bba77f9f9444d8902a335ea57364d3b7840ddb253a780118455eb568fcbecde734a476369cfb2cffd8ba8c11694cef9ee2db2844e82e94be90</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
  </entry>
  <entry>
    <title>hello world</title>
    <url>/2015/08/01/14786/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a><br>Markown 语法高亮</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Markdown 目录：</span><br><span class="line">[TOC]</span><br><span class="line"></span><br><span class="line">Markdown 标题：</span><br><span class="line"><span class="comment"># 这是 H1</span></span><br><span class="line"><span class="comment">## 这是 H2</span></span><br><span class="line"><span class="comment">### 这是 H3</span></span><br><span class="line"></span><br><span class="line">Markdown 列表：</span><br><span class="line">- 列表项目</span><br><span class="line"><span class="number">1.</span> 列表项目</span><br><span class="line"></span><br><span class="line">*斜体*或_斜体_</span><br><span class="line">**粗体**</span><br><span class="line">***加粗斜体***</span><br><span class="line">~~删除线~~</span><br><span class="line"></span><br><span class="line">Markdown 插入链接：</span><br><span class="line">[链接文字](链接网址 <span class="string">&quot;标题&quot;</span>)</span><br><span class="line"></span><br><span class="line">Markdown 插入图片：</span><br><span class="line">![alt text](/path/to/img.jpg <span class="string">&quot;Title&quot;</span>)</span><br><span class="line"></span><br><span class="line">Markdown 插入代码块：</span><br><span class="line">    ```python</span><br><span class="line">    <span class="comment">#!/usr/bin/python3</span></span><br><span class="line">    print(<span class="string">&quot;Hello, World!&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>Markdown 引用：</p>
<blockquote>
<p>引用内容</p>
</blockquote>
<h2 id="Markdown-分割线："><a href="#Markdown-分割线：" class="headerlink" title="Markdown 分割线："></a>Markdown 分割线：</h2><p>Markdown 换行：<br><br></p>
<p>Markdown 段首缩进：<br>&ensp; or &#8194; 表示一个半角的空格<br>&emsp; or &#8195;  表示一个全角的空格<br>&emsp;&emsp; 两个全角的空格（用的比较多）<br>&nbsp; or &#160; 不断行的空白格</p>
<pre><code></code></pre>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>tushare和baostock有什么区别？</title>
    <url>/2019/04/08/18747/</url>
    <content><![CDATA[<p>BaoStock的优势有很多，简单列举几个：</p>
<ol>
<li><p>数据由交易团队维护，数据质量高；后续可能会开放交易接口。</p>
</li>
<li><p>目前包含了A股2006年至今的日周月历史K线数据，而且包括前后复权；涵盖了熊市牛市的周期；据官方人员回复，数据还会继续扩充。</p>
</li>
<li><p>包含了A股2011年至今的5分钟、15分钟、30分钟、60分钟K线数据，没有门槛免费对外提供。对比一下公司购买某接口提供的历史分钟线数据报价，每1年的历史分钟数据流量包需要加3W块，BaoStock提供2011至今的历史数据，这就价值24W，而且不限制流量。激动得我赶紧把数据下载下来了（分钟线也提供了复权）。</p>
</li>
<li><p>实时行情接口方便使用，据官网说是取其他网站的，但BaoStock以订阅的方式提供，根据需要订阅股票，回调用户自定义的接口，而且可以传入用户自定义参数，也有预留参数，接口设计方便、合理，十分好用。</p>
</li>
<li><p>官网发布证券相关文章，介绍一些股票基础概念、指标计算，对于新手很有帮助，老手也能补足自己的缺失。</p>
</li>
<li><p>版本发展线路明确，发布数据补充或修改的公告，及时告知用户。</p>
</li>
<li><p>QQ群快速应答，解决问题速度很快。</p>
</li>
<li><p>宏观数据、成分股数据、业绩预告快报、盈利、营运、成长、偿债、杜邦指数，数据完善。</p>
</li>
</ol>
<p>BaoStock的不足：</p>
<ol>
<li><p>目前针对于股票市场，期货等市场还没有涉及。</p>
</li>
<li><p>取数据转为dataframe是略显复杂。<br><a href="https://www.akshare.xyz/zh_CN/latest/introduction.html">akshare</a><br><a href="http://tushare.org/">tushare</a><br><a href="http://ww.baostock.com/">baostock</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>quant</category>
        <category>tushare</category>
      </categories>
      <tags>
        <tag>quant</tag>
        <tag>tushare</tag>
        <tag>baostock</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu20.04 安裝配置vnc  x11vnc server</title>
    <url>/2020/07/24/41528/</url>
    <content><![CDATA[<p>Ubuntu 20.04 VNC 安装与设置</p>
<p>VNC是一个远程桌面协议。按照本文的说明进行操作可以实现用VNC对Ubuntu 20.04进行远程控制。一般的VNC安装方式在主机没有插显示器的时候是无法使用的。下面的操作可以在主机有显示器和没有显示器时都能够正常工作。</p>
<p>首先安装x11vnc</p>
<pre><code class="bash">sudo apt-get install x11vnc -y
</code></pre>
<p>设置vnc密码</p>
<pre><code class="bash">sudo x11vnc -storepasswd /etc/x11vnc.pass 
</code></pre>
<p>创建x11vnc自启动服务</p>
<p>创建 /etc/systemd/system/x11vnc.service，并写入以下内容</p>
<pre><code class="bash">[Unit]
Description=Start x11vnc at startup.
After=multi-user.target
[Service]
Type=simple
ExecStart=/usr/bin/x11vnc -auth /run/user/1000/gdm/Xauthority -forever -loop -noxdamage -repeat -rfbauth /etc/x11vnc.pass -rfbport 5900 -shared
[Install]
WantedBy=multi-user.target
</code></pre>
<p>启动x11vnc服务</p>
<pre><code class="bash">sudo systemctl enable x11vnc
sudo service x11vnc start
</code></pre>
<p>此时如果远程的主机上接了显示器，那么就可以在局域网通过VNC进行访问了。</p>
<p>为了能够保证远程主机无论是否有显示器，我们都能通过VNC进行远程访问，我们还要做下面的修改</p>
<p>创建默认的xorg.conf文件</p>
<pre><code class="bash">sudo Xorg :1 -configure
</code></pre>
<p>此时程序会生成 /root/xorg.conf.new文件<br>我的默认文件内容如下</p>
<pre><code class="bash">Section &quot;ServerLayout&quot;
    Identifier     &quot;X.org Configured&quot;
    Screen      0  &quot;Screen0&quot; 0 0
    InputDevice    &quot;Mouse0&quot; &quot;CorePointer&quot;
    InputDevice    &quot;Keyboard0&quot; &quot;CoreKeyboard&quot;
EndSection

Section &quot;Files&quot;
    ModulePath   &quot;/usr/lib/xorg/modules&quot;
    FontPath     &quot;/usr/share/fonts/X11/misc&quot;
    FontPath     &quot;/usr/share/fonts/X11/cyrillic&quot;
    FontPath     &quot;/usr/share/fonts/X11/100dpi/:unscaled&quot;
    FontPath     &quot;/usr/share/fonts/X11/75dpi/:unscaled&quot;
    FontPath     &quot;/usr/share/fonts/X11/Type1&quot;
    FontPath     &quot;/usr/share/fonts/X11/100dpi&quot;
    FontPath     &quot;/usr/share/fonts/X11/75dpi&quot;
    FontPath     &quot;built-ins&quot;
EndSection

Section &quot;Module&quot;
    Load  &quot;glx&quot;
EndSection

Section &quot;InputDevice&quot;
    Identifier  &quot;Keyboard0&quot;
    Driver      &quot;kbd&quot;
EndSection

Section &quot;InputDevice&quot;
    Identifier  &quot;Mouse0&quot;
    Driver      &quot;mouse&quot;
    Option        &quot;Protocol&quot; &quot;auto&quot;
    Option        &quot;Device&quot; &quot;/dev/input/mice&quot;
    Option        &quot;ZAxisMapping&quot; &quot;4 5 6 7&quot;
EndSection

Section &quot;Monitor&quot;
    Identifier   &quot;Monitor0&quot;
    VendorName   &quot;Monitor Vendor&quot;
    ModelName    &quot;Monitor Model&quot;
EndSection

Section &quot;Device&quot;
        ### Available Driver options are:-
        ### Values: &lt;i&gt;: integer, &lt;f&gt;: float, &lt;bool&gt;: &quot;True&quot;/&quot;False&quot;,
        ### &lt;string&gt;: &quot;String&quot;, &lt;freq&gt;: &quot;&lt;f&gt; Hz/kHz/MHz&quot;,
        ### &lt;percent&gt;: &quot;&lt;f&gt;%&quot;
        ### [arg]: arg optional
        #Option     &quot;Accel&quot;                  # [&lt;bool&gt;]
        #Option     &quot;AccelMethod&quot;            # &lt;str&gt;
        #Option     &quot;Backlight&quot;              # &lt;str&gt;
        #Option     &quot;CustomEDID&quot;             # &lt;str&gt;
        #Option     &quot;DRI&quot;                    # &lt;str&gt;
        #Option     &quot;Present&quot;                # [&lt;bool&gt;]
        #Option     &quot;ColorKey&quot;               # &lt;i&gt;
        #Option     &quot;VideoKey&quot;               # &lt;i&gt;
        #Option     &quot;Tiling&quot;                 # [&lt;bool&gt;]
        #Option     &quot;LinearFramebuffer&quot;      # [&lt;bool&gt;]
        #Option     &quot;HWRotation&quot;             # [&lt;bool&gt;]
        #Option     &quot;VSync&quot;                  # [&lt;bool&gt;]
        #Option     &quot;PageFlip&quot;               # [&lt;bool&gt;]
        #Option     &quot;SwapbuffersWait&quot;        # [&lt;bool&gt;]
        #Option     &quot;TripleBuffer&quot;           # [&lt;bool&gt;]
        #Option     &quot;XvPreferOverlay&quot;        # [&lt;bool&gt;]
        #Option     &quot;HotPlug&quot;                # [&lt;bool&gt;]
        #Option     &quot;ReprobeOutputs&quot;         # [&lt;bool&gt;]
        #Option     &quot;XvMC&quot;                   # [&lt;bool&gt;]
        #Option     &quot;ZaphodHeads&quot;            # &lt;str&gt;
        #Option     &quot;VirtualHeads&quot;           # &lt;i&gt;
        #Option     &quot;TearFree&quot;               # [&lt;bool&gt;]
        #Option     &quot;PerCrtcPixmaps&quot;         # [&lt;bool&gt;]
        #Option     &quot;FallbackDebug&quot;          # [&lt;bool&gt;]
        #Option     &quot;DebugFlushBatches&quot;      # [&lt;bool&gt;]
        #Option     &quot;DebugFlushCaches&quot;       # [&lt;bool&gt;]
        #Option     &quot;DebugWait&quot;              # [&lt;bool&gt;]
        #Option     &quot;BufferCache&quot;            # [&lt;bool&gt;]
    Identifier  &quot;Card0&quot;
    Driver      &quot;intel&quot;
    BusID       &quot;PCI:0:2:0&quot;
EndSection

Section &quot;Screen&quot;
    Identifier &quot;Screen0&quot;
    Device     &quot;Card0&quot;
    Monitor    &quot;Monitor0&quot;
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     1
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     4
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     8
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     15
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     16
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     24
    EndSubSection
EndSection
</code></pre>
<p>将此文件复制至 /usr/share/X11/xorg.conf.d/xorg.conf</p>
<p>这个文件保证在主机上插有显示器的时候，系统界面能在显示器上正常显示。下面我们再给系统添加一个虚拟显示器，当主机没有显示器的时候系统就使用这个虚拟显示器。</p>
<p>安装虚拟显卡驱动</p>
<pre><code class="bash">sudo apt install xserver-xorg-video-dummy
</code></pre>
<p>在这个文件的最后添加下面的内容</p>
<pre><code class="bash">Section &quot;Monitor&quot;
  Identifier &quot;Monitor1&quot;
  HorizSync   1.0 - 2000.0
  VertRefresh 1.0 - 200.0
  # Add 16:9 modes, others are automatically detected.
  Modeline &quot;1280x720&quot; 74.48 1280 1336 1472 1664 720 721 724 746
  Modeline &quot;1920x1080&quot; 172.80 1920 2040 2248 2576 1080 1081 1084 1118
EndSection


Section &quot;Device&quot;
  Identifier &quot;Card1&quot;
  Driver &quot;dummy&quot;
  VideoRam 256000
EndSection

Section &quot;Screen&quot;
  DefaultDepth 24
  Identifier &quot;Screen1&quot;
  Device &quot;Card1&quot;
  Monitor &quot;Monitor1&quot;
  SubSection &quot;Display&quot;
    Depth 24
    Modes &quot;1920x1080&quot;
  EndSubSection
EndSection
</code></pre>
<p>这样我们就创建了一个使用虚拟显卡的虚拟显示器。为了让虚拟的显示器和真实显示器都能工作，我们需要把最上面的 ServerLayout 进行更改</p>
<pre><code class="bash">Section &quot;ServerLayout&quot;
        Identifier     &quot;X.org Configured&quot;
        Screen      0  &quot;Screen0&quot; 0 0
    Screen      1  &quot;Screen1&quot; 0 0
EndSection
</code></pre>
<p>完整的/usr/share/X11/xorg.conf.d/xorg.conf</p>
<pre><code class="bash">Section &quot;ServerLayout&quot;
    Identifier     &quot;X.org Configured&quot;
    Screen      0  &quot;Screen0&quot; 0 0
    Screen      1  &quot;Screen1&quot; 0 0
#    InputDevice    &quot;Mouse0&quot; &quot;CorePointer&quot;
#    InputDevice    &quot;Keyboard0&quot; &quot;CoreKeyboard&quot;
EndSection

Section &quot;Files&quot;
    ModulePath   &quot;/usr/lib/xorg/modules&quot;
    FontPath     &quot;/usr/share/fonts/X11/misc&quot;
    FontPath     &quot;/usr/share/fonts/X11/cyrillic&quot;
    FontPath     &quot;/usr/share/fonts/X11/100dpi/:unscaled&quot;
    FontPath     &quot;/usr/share/fonts/X11/75dpi/:unscaled&quot;
    FontPath     &quot;/usr/share/fonts/X11/Type1&quot;
    FontPath     &quot;/usr/share/fonts/X11/100dpi&quot;
    FontPath     &quot;/usr/share/fonts/X11/75dpi&quot;
    FontPath     &quot;built-ins&quot;
EndSection

Section &quot;Module&quot;
    Load  &quot;glx&quot;
EndSection

Section &quot;InputDevice&quot;
    Identifier  &quot;Keyboard0&quot;
    Driver      &quot;kbd&quot;
EndSection

Section &quot;InputDevice&quot;
    Identifier  &quot;Mouse0&quot;
    Driver      &quot;mouse&quot;
    Option        &quot;Protocol&quot; &quot;auto&quot;
    Option        &quot;Device&quot; &quot;/dev/input/mice&quot;
    Option        &quot;ZAxisMapping&quot; &quot;4 5 6 7&quot;
EndSection

Section &quot;Monitor&quot;
    Identifier   &quot;Monitor0&quot;
    VendorName   &quot;Monitor Vendor&quot;
    ModelName    &quot;Monitor Model&quot;
EndSection

Section &quot;Device&quot;
        ### Available Driver options are:-
        ### Values: &lt;i&gt;: integer, &lt;f&gt;: float, &lt;bool&gt;: &quot;True&quot;/&quot;False&quot;,
        ### &lt;string&gt;: &quot;String&quot;, &lt;freq&gt;: &quot;&lt;f&gt; Hz/kHz/MHz&quot;,
        ### &lt;percent&gt;: &quot;&lt;f&gt;%&quot;
        ### [arg]: arg optional
        #Option     &quot;Accel&quot;                  # [&lt;bool&gt;]
        #Option     &quot;AccelMethod&quot;            # &lt;str&gt;
        #Option     &quot;Backlight&quot;              # &lt;str&gt;
        #Option     &quot;CustomEDID&quot;             # &lt;str&gt;
        #Option     &quot;DRI&quot;                    # &lt;str&gt;
        #Option     &quot;Present&quot;                # [&lt;bool&gt;]
        #Option     &quot;ColorKey&quot;               # &lt;i&gt;
        #Option     &quot;VideoKey&quot;               # &lt;i&gt;
        #Option     &quot;Tiling&quot;                 # [&lt;bool&gt;]
        #Option     &quot;LinearFramebuffer&quot;      # [&lt;bool&gt;]
        #Option     &quot;HWRotation&quot;             # [&lt;bool&gt;]
        #Option     &quot;VSync&quot;                  # [&lt;bool&gt;]
        #Option     &quot;PageFlip&quot;               # [&lt;bool&gt;]
        #Option     &quot;SwapbuffersWait&quot;        # [&lt;bool&gt;]
        #Option     &quot;TripleBuffer&quot;           # [&lt;bool&gt;]
        #Option     &quot;XvPreferOverlay&quot;        # [&lt;bool&gt;]
        #Option     &quot;HotPlug&quot;                # [&lt;bool&gt;]
        #Option     &quot;ReprobeOutputs&quot;         # [&lt;bool&gt;]
        #Option     &quot;XvMC&quot;                   # [&lt;bool&gt;]
        #Option     &quot;ZaphodHeads&quot;            # &lt;str&gt;
        #Option     &quot;VirtualHeads&quot;           # &lt;i&gt;
        #Option     &quot;TearFree&quot;               # [&lt;bool&gt;]
        #Option     &quot;PerCrtcPixmaps&quot;         # [&lt;bool&gt;]
        #Option     &quot;FallbackDebug&quot;          # [&lt;bool&gt;]
        #Option     &quot;DebugFlushBatches&quot;      # [&lt;bool&gt;]
        #Option     &quot;DebugFlushCaches&quot;       # [&lt;bool&gt;]
        #Option     &quot;DebugWait&quot;              # [&lt;bool&gt;]
        #Option     &quot;BufferCache&quot;            # [&lt;bool&gt;]
    Identifier  &quot;Card0&quot;
    Driver      &quot;intel&quot;
    BusID       &quot;PCI:0:2:0&quot;
EndSection

Section &quot;Screen&quot;
    Identifier &quot;Screen0&quot;
    Device     &quot;Card0&quot;
    Monitor    &quot;Monitor0&quot;
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     1
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     4
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     8
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     15
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     16
    EndSubSection
    SubSection &quot;Display&quot;
        Viewport   0 0
        Depth     24
    EndSubSection
EndSection



Section &quot;Monitor&quot;

  Identifier &quot;Monitor1&quot;

  HorizSync   1.0 - 2000.0

  VertRefresh 1.0 - 200.0

  # Add 16:9 modes, others are automatically detected.

  Modeline &quot;1280x720&quot; 74.48 1280 1336 1472 1664 720 721 724 746

  Modeline &quot;1920x1080&quot; 172.80 1920 2040 2248 2576 1080 1081 1084 1118

EndSection





Section &quot;Device&quot;

  Identifier &quot;Card1&quot;

  Driver &quot;dummy&quot;

  VideoRam 256000

EndSection



Section &quot;Screen&quot;

  DefaultDepth 24

  Identifier &quot;Screen1&quot;

  Device &quot;Card1&quot;

  Monitor &quot;Monitor1&quot;

  SubSection &quot;Display&quot;

    Depth 24

    Modes &quot;1920x1080&quot;

  EndSubSection

EndSection
</code></pre>
<p><a href="https://blog.csdn.net/frozennet/article/details/105211375?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param">设置X11VNC后就可以使用了</a><br>现在重新启动远程电脑，就可以在没有显示器的情况下远程了。</p>
<p>以上的方法还有一个问题。就是在用户没有登录的其情况下是没办法远程的。所以需要把用户设置成自动登录。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu20.04 配置和安裝vnc</title>
    <url>/2020/07/24/933/</url>
    <content><![CDATA[<p>现今，云服务器已经十分普及，申请个云服务器作为个人开发学习或者简单个人服务器使用已经司空见惯。Linux云服务器申请就绪后，一般都是命令行的，不包含桌面环境，也不支持通过远程桌面的方式访问图形化桌面环境。本指南介绍了在Ubuntu 20.04 系统上安装和配置 VNC 服务器所需的步骤，实现通过远程桌面管理和控制Ubuntu云服务器，支持图形界面操作。</p>
<p>先决条件</p>
<p>在继续学习本教程之前，请确保以具有 sudo 权限的用户身份登录。建议使用具有sudo权限的普通用户进行处理，而不是直接使用root用户。创建用户并加入sudoers可自行百度。</p>
<p>安装桌面环境</p>
<p>大多数服务器没有安装桌面环境，因此我们首先要安装轻量级桌面环境。</p>
<p>Ubuntu 存储库中有几个桌面环境，远程桌面管理建议选择安装 Xfce 。它是快速，稳定和轻量级的桌面环境，非常适合在远程服务器上使用。</p>
<p>首先使用以下命令更新系统</p>
<pre><code class="bash">
sudo apt update
sudo apt upgrade
</code></pre>
<p>然后，键入以下命令以在服务器上安装 Xfce ：</p>
<pre><code class="bash">sudo apt install xfce4 xfce4-goodies xorg dbus-x11 x11-xserver-utils
</code></pre>
<p>根据您的系统，下载和安装 Xfce 软件包可能需要一些时间。</p>
<p>安装 VNC 服务器</p>
<p>Ubuntu 存储库中还有几种不同的 VNC 服务器，如 TightVNC ， TigerVNC 和 x11vnc 。每个 VNC 服务器在速度和安全性方面都有不同的优点和缺点。</p>
<p>我们将安装 TigerVNC ，它是高性能 VNC 服务器，并被积积极维护。</p>
<p>键入以下命令以在 Ubuntu 服务器上安装 TigerVNC ：</p>
<pre><code class="bash">sudo apt install tigervnc-standalone-server tigervnc-common
</code></pre>
<p>现在安装了 VNC 服务器，下一步是运行 vncserver 命令，该命令将创建初始配置并设置密码。运行以下命令时不要使用 sudo ：</p>
<pre><code class="bash">
vncserver
</code></pre>
<p>系统将提示您输入并确认密码，以及是否将其设置为仅查看密码。如果您选择设置仅查看密码，则用户将无法使用鼠标和键盘与 VNC 实例进行交互。</p>
<pre><code class="bash">You will require a password to access your desktops.
Password:
Verify:
Would you like to enter a view-only password (y/n)? n
/usr/bin/xauth:  file /home/typhoon/.Xauthority does not exist
New &#39;server2.typhoon.org:1 (typhoon)&#39; desktop at :1 on machine server2.typhoon.org
Starting applications specified in /etc/X11/Xvnc-session
Log file is /home/typhoon/.vnc/server2.typhoon.org:1.log
Use xtigervncviewer -SecurityTypes VncAuth -passwd /home/typhoon/.vnc/passwd :1 to connect to the VNC server.

</code></pre>
<p>第一次 vncserver 运行命令时，它将创建密码文件并将其存储在 ~/.vnc 目录中，如果不存在，将创建该目录。</p>
<p>注意上面输出中主机名之后的 :1 。这表示运行 vnc 服务器的显示端口号。在我们的例子中，服务器在 TCP 端口 5901 (5900 + 1)上运行。如果您创建第二个实例， vncserver 它将在下一个空闲端口上运行，即 :2 这意味着服务器正在端口 5902 (5900 + 2)上运行。</p>
<p>重要的是要记住，当使用 VNC 服务器时， :X 是一个引用的显示端口 5900+X 。</p>
<p>注：如果启动时出现vnc启动异常： is taken because of /tmp/.X11-unix/X1</p>
<p>此时只需要将提示的文件删除即可。再次输入 vncserver。</p>
<p>在继续下一步之前，首先使用带有 -kill 选项和服务器编号作为参数的 vncserver 命令停止 VNC 实例。在我们的例子中，服务器在端口 5901 (:1)中运行，因此我们将使用以下命令停止它：</p>
<pre><code class="bash">
vncserver -kill :1
</code></pre>
<p>Killing Xtigervnc process ID 7264… success!<br>配置 VNC 服务器</p>
<p>现在我们已经在服务器上安装了 Xfce 和 TigerVNC ，我们需要配置 TigerVNC 来使用 Xfce 。为此，请创建以下文件 〜/.vnc/xstartup：</p>
<pre><code class="bash">
nano ~/.vnc/xstartup


#!/bin/sh
unset SESSION_MANAGER
unset DBUS_SESSION_BUS_ADDRESS
exec startxfce4 

</code></pre>
<p>保存并关闭文件。无论何时启动或重启 TigerVNC 服务器，都将自动执行上述命令。</p>
<p>~/.vnc/xstartup 文件还需要具有执行权限。运行以下命令以确保权限正确：</p>
<pre><code class="bash">
chmod u+x ~/.vnc/xstartup
</code></pre>
<p>如果需要将附加选项传递给 VNC 服务器，则可以创建一个名为 config 的文件，并为每行添加一个选项。这是一个例子：</p>
<p>文件 ~/.vnc/config</p>
<p>geometry=1920x1084<br>dpi=96</p>
<p>创建 Systemd 单元文件</p>
<p>我们将创建一个 systemd 单元文件，使我们能够根据需要轻松启动，停止和重新启动 VNC 服务，与任何其他 systemd 服务相同。</p>
<p>打开文本编辑器，将以下配置复制并粘贴到其中。</p>
<pre><code class="bash">

sudo nano /etc/systemd/system/vncserver@.service
</code></pre>
<p>请务必更改第 7 行中的用户名以匹配您的用户名。</p>
<pre><code class="bash">[Unit]
Description=Remote desktop service (VNC)
After=syslog.target network.target

[Service]
Type=simple
User=username
PAMName=login
PIDFile=/home/%u/.vnc/%H%i.pid
ExecStartPre=/bin/sh -c &#39;/usr/bin/vncserver -kill :%i &gt; /dev/null 2&gt;&amp;1 || :&#39;
ExecStart=/usr/bin/vncserver :%i -geometry 1440x900 -alwaysshared -fg
ExecStop=/usr/bin/vncserver -kill :%i

[Install]
WantedBy=multi-user.target

</code></pre>
<p>保存并关闭文件。</p>
<p>通知 systemd 我们创建了一个新的单元文件：</p>
<pre><code class="bash">
sudo systemctl daemon-reload
</code></pre>
<p>下一步是使用以下命令启用单元文件：</p>
<pre><code class="bash">sudo systemctl enable vncserver@1.service
</code></pre>
<p>符号 1 后面的数字 @ 定义了运行 VNC 服务的显示端口。这意味着 VNC 服务器将侦听端口 5901 ，正如我们在上一节中讨论的那样。</p>
<p>执行以下命令启动 VNC 服务：</p>
<pre><code class="bash">
sudo systemctl start vncserver@1.service

</code></pre>
<p>验证服务是否已成功启动：</p>
<pre><code class="bash">
sudo systemctl status vncserver@1.service

</code></pre>
<p>● <a href="mailto:&#118;&#x6e;&#x63;&#x73;&#x65;&#x72;&#x76;&#x65;&#114;&#x40;&#49;&#x2e;&#x73;&#x65;&#114;&#118;&#105;&#x63;&#x65;">&#118;&#x6e;&#x63;&#x73;&#x65;&#x72;&#x76;&#x65;&#114;&#x40;&#49;&#x2e;&#x73;&#x65;&#114;&#118;&#105;&#x63;&#x65;</a> - Remote desktop service (VNC)<br>   Loaded: loaded (/etc/systemd/system/vncserver@.service; indirect; vendor preset: enabled)<br>   Active: active (running) since Thu 2018-08-16 19:05:54 UTC; 4s ago<br>  Process: 9893 ExecStartPre=/bin/sh -c /usr/bin/vncserver -kill :1 &gt; /dev/null 2&gt;&amp;1 || : (code=exited, status=0/SUCCESS)<br> Main PID: 9900 (vncserver)<br>    Tasks: 0 (limit: 507)<br>   CGroup: /system.slice/system-vncserver.slice/vncserver@1.service<br>           ‣ 9900 /usr/bin/perl /usr/bin/vncserver :1 -geometry 1440x900 -alwaysshared -fg</p>
<p>连接到 VNC 服务器</p>
<p>VNC 不是加密协议，可以进行数据包嗅探。建议的方法是创建一个 SSH 隧道，该隧道将安全地将来自本地计算机的端口 5901 上的流量转发到同一端口上的服务器。</p>
<p>在 Linux 和 macOS 上设置 SSH 隧道</p>
<p>如果在计算机上运行 Linux ， macOS 或任何其他基于 Unix 的操作系统，则可以使用以下命令轻松创建 SSH 隧道：</p>
<pre><code class="bash">
ssh -L 5901:127.0.0.1:5901 -N -f -l username server_ip_address

</code></pre>
<p>系统将提示您输入用户密码。</p>
<p>该-L开关指定的端口绑定。在这种情况下，我们将5901远程连接的端口5901绑定到本地计算机上的端口。该-C开关启用压缩，而-N开关告诉ssh我们不希望执行远程命令。该-l开关指定远程登录名。</p>
<p>记得替换username，并server_ip_address与您的服务器的须藤非root用户名和IP地址。</p>
<p>如果您使用的是图形化SSH客户端（如PuTTY），请将server_ip_address用作连接IP，并在程序的SSH隧道设置中设置localhost:5901为新的转发端口。</p>
<p>隧道运行后，使用VNC客户端进行连接localhost:5901。系统将提示您使用在步骤1中设置的密码进行身份验证。</p>
<p>连接后，您将看到默认的Xfce桌面。它应该看起来像这样：<br><a href="https://xie.infoq.cn/article/cf473dc0dea917b0b2a546ecd">安装配置vnc</a><br><a href="https://blog.csdn.net/yang_hui1986527/article/details/106311024?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param">如何在Ubuntu 20.04 上安装 Xrdp 服务器（远程桌面）</a><br><a href="https://blog.csdn.net/bluewhalerobot/article/details/106770429">https://blog.csdn.net/bluewhalerobot/article/details/106770429</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Vnc</tag>
      </tags>
  </entry>
  <entry>
    <title>zip压缩工具、tar打包、打包并压缩</title>
    <url>/2020/07/24/48740/</url>
    <content><![CDATA[<p>#　一、zip压缩工具</p>
<p>在Windows和Linux中都常用。可以压缩目录和文件，压缩目录时，需要指定目录下的文件。压缩后源文件不删除。示例：</p>
<h2 id="zip-1-txt-zip-1-txt-（压缩文件，先目标文件名，再源文件名）"><a href="#zip-1-txt-zip-1-txt-（压缩文件，先目标文件名，再源文件名）" class="headerlink" title="zip 1.txt.zip 1.txt （压缩文件，先目标文件名，再源文件名）"></a>zip 1.txt.zip 1.txt （压缩文件，先目标文件名，再源文件名）</h2><p> adding: 1.txt (deflated 64%)</p>
<p>压缩目录时需要加上-r选项，如下：</p>
<h2 id="zip-r-1-txt-zip-1"><a href="#zip-r-1-txt-zip-1" class="headerlink" title="zip -r 1.txt.zip 1/"></a>zip -r 1.txt.zip 1/</h2><p> adding: 1/ (stored 0%)</p>
<p> adding: 1/11/ (stored 0%)</p>
<p> adding: 1/11/111/ (stored 0%)</p>
<p> adding: 1/1.txt (stored 0%)</p>
<p>unzip命令：解压.zip格式的文件。</p>
<p>若没有该命令，用yum工具安装。</p>
<p>示例：</p>
<h2 id="unzip-3-txt-zip"><a href="#unzip-3-txt-zip" class="headerlink" title="unzip 3.txt.zip"></a>unzip 3.txt.zip</h2><p>Archive:  3.txt.zip</p>
<p>replace 1/1.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y  (因为原来的文件还在，询问是否覆盖）</p>
<p>extracting: 1/1.txt</p>
<p>-d：解压时指定路径。不可指定文件名，加了文件名的话会生成一个以设定的文件名为名字的目录，再将解压的文件放在该目录下。</p>
<h2 id="unzip-1-txt-zip-d-md2"><a href="#unzip-1-txt-zip-d-md2" class="headerlink" title="unzip 1.txt.zip -d md2/"></a>unzip 1.txt.zip -d md2/</h2><p>Archive:  1.txt.zip</p>
<p> inflating: md2/1.txt              </p>
<p>  creating: md2/1/</p>
<p>extracting: md2/1/1.txt</p>
<p>zip工具没有zcat那类的cat工具，唯一能用unzip -l+压缩文件名，查看压缩包内的文件列表。</p>
<h1 id="二、tar打包"><a href="#二、tar打包" class="headerlink" title="二、tar打包"></a>二、tar打包</h1><p>tar本身就是一个打包工具，可以把目录打包成文件，把所有文件整合成一个大文件，方便复制或移动。打包后原文件不删除。</p>
<p>格式：tar [-zjxcvfpP] filename tar</p>
<p>-z：同时用gzip压缩。</p>
<p>-j：同时用bzip2压缩。</p>
<p>-J：同时用xz压缩。</p>
<p>-x：解包或解压缩。</p>
<p>-t：查看tar包里的文件。</p>
<p>-c：建立一个tar包或者压缩文件包。</p>
<p>-v：显示操作过程。</p>
<p>-f：后跟文件名，表示压缩后的文件名为filename，或者解压文件filename。</p>
<p>多个参数组合的情况下，把-f写到最后面。</p>
<p>-p：使用原文件的属性。不常用。</p>
<p>-P：可使用绝对路径。不常用。</p>
<p>–exclude filename：在打包或压缩时，不要将filename文件包括在内。排除文件或目录，不常用。</p>
<p>-f参数后先跟目标文件名，再跟需打包的文件或目录。</p>
<p>示例：</p>
<h2 id="tar-cf-test-tar-test（建立tar包，文件名，再建立一个同样的会覆盖之前的）"><a href="#tar-cf-test-tar-test（建立tar包，文件名，再建立一个同样的会覆盖之前的）" class="headerlink" title="tar -cf test.tar test（建立tar包，文件名，再建立一个同样的会覆盖之前的）"></a>tar -cf test.tar test（建立tar包，文件名，再建立一个同样的会覆盖之前的）</h2><h2 id="tar-xvf-test-tar-test（解压，显示操作过程，文件名，会覆盖前面的文件，不会询问是否覆盖）"><a href="#tar-xvf-test-tar-test（解压，显示操作过程，文件名，会覆盖前面的文件，不会询问是否覆盖）" class="headerlink" title="tar -xvf   test.tar test（解压，显示操作过程，文件名，会覆盖前面的文件，不会询问是否覆盖）"></a>tar -xvf   test.tar test（解压，显示操作过程，文件名，会覆盖前面的文件，不会询问是否覆盖）</h2><p>test/</p>
<p>test/abc/</p>
<p>test/abc/AC/</p>
<p>test/12.txt</p>
<h2 id="tar-tf-test-tar-（查看tar包内的文件）"><a href="#tar-tf-test-tar-（查看tar包内的文件）" class="headerlink" title="tar -tf test.tar （查看tar包内的文件）"></a>tar -tf test.tar （查看tar包内的文件）</h2><p>test/</p>
<p>test/abc/</p>
<p>test/abc/AC/</p>
<p>test/12.txt</p>
<p>–exclude用法：可使用“*.txt”等。</p>
<h2 id="mkdir-test111-test222"><a href="#mkdir-test111-test222" class="headerlink" title="mkdir test111/test222"></a>mkdir test111/test222</h2><h2 id="tar-cvf-test111-tar-–exclude-test222-test111"><a href="#tar-cvf-test111-tar-–exclude-test222-test111" class="headerlink" title="tar -cvf test111.tar –exclude test222 test111"></a>tar -cvf test111.tar –exclude test222 test111</h2><p>test111/</p>
<p>test111/1.txt</p>
<p>这样就不会将test222目录打包进来。</p>
<p>三、打包并压缩</p>
<p>tar可在打包时直接压缩，支持gzip压缩、bzip2压缩和xz压缩。</p>
<p>使用-z选项可压缩成gzip格式的文件，示例：</p>
<h2 id="tar-czvf-test123-tar-gz-test"><a href="#tar-czvf-test123-tar-gz-test" class="headerlink" title="tar -czvf test123.tar.gz test"></a>tar -czvf test123.tar.gz test</h2><p>test/</p>
<p>test/abc/</p>
<p>test/abc/AC/</p>
<p>test/12.txt</p>
<p>test/test123.tar.gz</p>
<p>test/test12.tar.gz</p>
<h2 id="tar-xvzf-test123-tar-gz-（可用-zx选项，解压-tar-gz格式的压缩包）"><a href="#tar-xvzf-test123-tar-gz-（可用-zx选项，解压-tar-gz格式的压缩包）" class="headerlink" title="tar -xvzf test123.tar.gz （可用-zx选项，解压.tar.gz格式的压缩包）"></a>tar -xvzf test123.tar.gz （可用-zx选项，解压.tar.gz格式的压缩包）</h2><p>-j和-J是同样的用法。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>《统计学习方法第2版》pdf及机器学习书籍推荐</title>
    <url>/2020/08/03/48099/</url>
    <content><![CDATA[<p>我虽然很喜欢模式识别和机器学习，但我暂时并不希望在这上面做深入的研究，只想把别人研究好的成熟的理论用在计算机视觉任务上。比如SVM，Adaboost，EM，朴素贝叶斯，K近邻，决策树等等。能够知道每种算法的原理，而并不想深究其实现过程以及理论证明。比如SVM，我想知道的是这种算法如何实现分类，有哪几种类型，每种适合什么样的分类任务，对应的参数的意义是什么。这样我在使用SVM-Light或者libsvm的时候就知道该怎么选用参数，怎么使用学习到的系数。从这个角度看这本书很适合我。当然也适合那些在想在机器学习方面做深入研究的人作为入门教材，我想对原理了解一二之后，阅读大部头或者原著肯定会轻松很多。</p>
<a id="more"></a>
<p>建议统计学习方法路线，ng课程入门，知道有哪些算法，大致怎么做，然后去kaggle打个入门赛，别做特征工程，把会的算法全用上。然后放下比赛，开始读《统计学习方法第2版》，同时看机器学习基石或其他比较数学化的进阶课程，这一步不需要你敲代码，你要会的是滚瓜烂熟的推导，做到这一步，再去kaggle参加奖金赛，阅读kernel，学习state of the art 模型，学习特征工程，再在学习过程中阅读最新的论文或者经典的论文，不断迭代这个过程，别淹死在什么机器学习实战上，有现成的轮子不用，非得费那个劲，除非你科班毕业，代码能力扎实，不然你能不能从头实现一遍决策树对你找不找到工作没有任何一毛钱关系。笔试不会考你如何实现hmm，只会考数据结构与算法，面试只会让你推导。</p>
<p> 《统计学习方法第2版》PDF，484页，带书签，文字可复制；配套部分源代码；配套部分课件。</p>
<p>下载: <a href="https://pan.baidu.com/s/1Xyo5AwCSKB9FaUxLIm69Cg">https://pan.baidu.com/s/1Xyo5AwCSKB9FaUxLIm69Cg</a><br>提取码: qpf1</p>
<p>统计学习方法即机器学习方法，是计算机及其应用领域的一门重要学科。《统计学习方法第2版》分为监督学 习和无监督学习两篇，全面系统地介绍了统计学习的主要方法。包括感知机、k 近邻法、朴素贝叶斯法、决策树、逻辑斯谛回归与最大熵模型、支持向量机、提升方法、EM 算法、隐马尔可夫模型和条件随机场，以及聚类方法、奇异值分解、主成分分析、潜在语义分析、概率潜在语义分析、马尔可夫链蒙特卡罗法、潜在狄利克雷分配和 PageRank 算法等。</p>
<p>除有关统计学习、监督学习和无监督学习的概论和总结的四章外，每章介绍一种方法。</p>
<p>叙述力求从具体问题或实例入手， 由浅入深，阐明思路，给出必要的数学推导，便于掌握统计学习方法的实质，学会运用。</p>
<p>介绍了一些相关研究，给出了少量习题， 适用于从事文本数据挖掘、信息检索及自然语言处理等专业的研发人员参考。</p>
<p>机器学习是近年来渐趋热门的一个领域，同时Python 语言经过一段时间的发展也已逐渐成为主流的编程语言之一。《Python机器学习实践指南》结合了机器学习和Python 语言两个热门的领域，通过利用两种核心的机器学习算法来将Python 语言在数据分析方面的优势发挥到极致。<br>《Python机器学习实践指南》中文PDF，268页，带目录，彩色配图，文字可复制；英文PDF，324页，带目录，彩色配图，文字可复制；配有源代码。</p>
<p>下载: <a href="https://pan.baidu.com/s/183L7EG0JPf0ky8B8hx1PUA">https://pan.baidu.com/s/183L7EG0JPf0ky8B8hx1PUA</a><br>提取码: ds6i</p>
<p>共有10 章。第1 章讲解了Python 机器学习的生态系统，剩余9 章介绍了众多与机器学习相关的算法，包括各类分类算法、数据可视化技术、推荐引擎等，主要包括机器学习在公寓、机票、IPO 市场、新闻源、内容推广、股票市场、图像、聊天机器人和推荐引擎等方面的应用。</p>
<p>国内有几本关于强化学习的书，《强化学习精要：核心算法与TensorFlow 实现》介绍了强化学习的基本算法与代码实现，构建了一个完整的强化学习知识体系，同时介绍了这些算法的具体实现方式。</p>
<p>可以从中学习到基本的马尔可夫决策过程，到各种复杂的强化学习算法。</p>
<p>《强化学习精要：核心算法与TensorFlow实现》PDF，386页，带书签目录，文字可以复制；配套源代码。</p>
<p>下载: <a href="https://pan.baidu.com/s/1mXEbu8T9FH5TH6DXNNiC4Q">https://pan.baidu.com/s/1mXEbu8T9FH5TH6DXNNiC4Q</a></p>
<p>提取码: xh14</p>
<p>2016 年是人工智能进入大众视野的一年，从AlphaGo 到无人驾驶，从量子计算机到马斯克的太空计划，每一个焦点事件的背后都与人工智能有着很大的联系。2016 年至今，短短两年的时间，人工智能在与人类生活息息相关的医疗健康、金融、零售、娱乐等方面，发挥出了巨大的潜能。</p>
<p> 《图解深度学习与神经网络从张量到TensorFlow实现》PDF，338页，带书签目录，文字可以复制。配套源代码。</p>
<p>下载: <a href="https://pan.baidu.com/s/12G_ajgS6E5im8HfWjuFmWg">https://pan.baidu.com/s/12G_ajgS6E5im8HfWjuFmWg</a>   提取码: 9jux</p>
<p>学习290张图+110个可执行的TensorFlow示例程序+算法示例；学习神经网络与深度学习背后的数学原理及上手应用；学习神经网络、深度学习背后的数学基础，掌握它们的原理与实现，更深刻地理解开源深度学习框架TensorFlow中的常用函数。</p>
<p>《人工神经网络理论设计及应用第2版》PDF，256页，带书签，文字可以复制。配套教学课件。</p>
<p>下载: <a href="https://pan.baidu.com/s/19w_C7R-A78oy0Ij5Xaa41g">https://pan.baidu.com/s/19w_C7R-A78oy0Ij5Xaa41g</a><br>提取码: rizs</p>
<p>《人工神经网络理论设计及应用第2版》系统地论述了人工神经网络的主要理论和设计基础，给出了大量应用实例，旨在使读者了解神经网络的发展背景和研究对象，理解和熟悉其基本原理和主要应用，掌握其结构模型和基本设计方法，为以后的深入研究和应用开发打下基础。第2版对原书约1/3的内容进行了更新，对保留内容进行了修改。取材注意内容的典型性和先进性，编排注意内容的逻辑性，阐述注重物理概念的清晰性，举例与思考练习的安排注意了内容的实践性，常用神经网络及算法的介绍着重于实用性。</p>
<p> 《深度卷积网络:原理与实践》 PDF，331页，带目录，文字可复制。配套源代码。</p>
<p>下载: <a href="https://pan.baidu.com/s/1Qz4864r_vjGNSGVx1ynavQ">https://pan.baidu.com/s/1Qz4864r_vjGNSGVx1ynavQ</a><br>提取码: 67xi</p>
<p>《深度卷积网络:原理与实践》还是很不错的。通俗易懂的介绍了卷积网络，并给出了详细的证明。写作比较严谨，还给出了详细的参考文献供进一步探究。作为一本入门书完全是合格的。</p>
<p>深度卷积网络DCNN是目前十分流行的深度神经网络架构，它的构造清晰直观，效果引人入胜，在图像、视频、语音、语言领域都有广泛应用。《深度卷积网络:原理与实践》以AI领域新的技术研究和和实践为基础，从技术理论、工作原理、实践方法、架构技巧、训练方法、技术前瞻等6个维度对深度卷积网络进行了系统、深入、详细地讲解。</p>
<p>以实战为导向，深入分析AlphaGo和GAN的实现过程、技术原理、训练方法和应用细节，依次揭开神经网络、卷积网络和深度卷积网络的神秘面纱，了解AI的“思考过程”，以及与人类思维的相同和不同之处。</p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>一个量化交易策略师的自白</title>
    <url>/2017/07/11/6767/</url>
    <content><![CDATA[<pre><code>    我之前在全球top5券商工作时也主要以CTA研究为主，每天都在不停的进行各种回测和开发。彼时，部门的CTA交易主要集中在股指期货的日内投机上，基本市场上能搜集到的各种书籍和报告我都浏览过。不过，从实际运用的角度来看，不同的技术分析方法，指标类切线类也好，形态类波浪类也罢，无论其历史背景和基本原理如何，其实质都是基于证券交易过程中量价时空等历史资料基础上的统计、分析和计算。

   由于可供交易的期货标的只有沪深300股指期货，虽然所在部门同时跑了多个日内交易模型，但基本都是一荣俱荣，一损俱损。更为关键的是，一般趋势跟踪系统的获胜概率都低于40%，真正幅度大的单次盈利都是好不容易才熬来的，这说明大部分交易其实都是瞎折腾，当账户资金在短期内出现较大回撤的时候，很容易对自己的模型失去信心，继而陷入反复优化的怪圈。要知道，部门的考核都是以年为单位的，如果一年下来赚不到什么钱甚至亏钱，后果你懂的。

    我在读研究生期间，有过一段奇妙的际遇，至于这段际遇是如何而来，至今想想都觉得传奇。当时，我作为一个博士一年级的学生，曾帮一私募大佬全权管理了一只3000万的CTA量化基金，为期一年，金字塔决策交易系统全自动下单，偶尔也人工干预。就是这段经历，让我在毕业求职时的简历比同龄人丰富了不少。也正是这段交易经历，让我知道了趋势交易就是一种煎熬，因为趋势交易是反！人！性！的：几乎总在最高点开多，最低点开空，所以每次下单都是如履薄冰。最致命的是，由于日内单边走势的下单滑点一般都比较大，如果你因为限价单没能成交，基本这千年等一回的机会就和你说拜拜了；而如果你不顾一切去追单，则很大可能刚成交一会就触发了止损命令，实际亏损是理论亏损的2倍还多。

   正因为知道了交易执行的艰难，毕业后进入全球top5券商后，对于交易下单和盯盘，一开始我就是拒绝的。部门的交易一直都是另一海归博士GG在做，而我只负责模型的研发和维护。他每日的工作流程就是，每天早上打开电脑，检查数据流是否正常，然后打开模型，让程序自动执行，盘中各种纠结，盘后各种悔恨。而这，基本就是一天的生活。

  盘中纠结：由于资金量巨大，股指期货随便一个波动，就是几十万的盈亏。落袋为安（干预模型）还是让坚决执行模型？这是个问题。毕竟一切浮盈皆是虚妄。</code></pre>
<p>盘后悔恨：今天曾浮盈过百万，最后居然止损出局，唉；今天要是不干预的话，本！可！以！盈利数百万的，结果少赚了近一半，唉，唉。</p>
<pre><code>  别问我为啥总想干预模型。事实上，任何一个趋势跟踪系统都是很难坚持的，因为它们都是以捕捉相对罕见的大趋势为基础的，而大趋势通常难得一见。在漫长的等待中，交易者很容易对自己的系统产生怀疑，转而相信自己能够战胜概率。</code></pre>
<p>别问我一年下来赚了多少。事实上，CTA的容量是非常有限的，相比于部门的中介业务动辄上亿的利润，CTA的盈利基本可以忽略。虽然后来我们又把趋势交易拓展到了商品期货上，同时交易了十几个品种，但随后很多商品期货都开启了夜盘模式，遂逐步放弃。</p>
<pre><code>   因为选择了CTA，导致我每天都在对自己的职业生涯产生怀疑，直到后来我跳槽到阳光私募开始管理对冲产品，开始了股票alpha模型的盈利模式。</code></pre>
<p>此是后话，有时间慢慢表来。</p>
<p>在中国的股票、期货市场，几乎所有的投资者多多少少都懂点技术分析，什么MA、MACD、KDJ等等，诸如此类，不一而足。至于自己所理解的技术指标能否盈利，另当别论。</p>
<pre><code>  由于量化投资的门槛实在太低，大凡交易过商品期货的朋友（尤其是理工科学生，毕业后想进入金融机构以此为职业的），基本都在用自己编译的模型进行程序化自动下单，或按模型提示的信号进行手撸。至于所交易的品种，究竟是橡胶、螺纹钢，还是豆粕、焦炭（股指期货的开户门槛太高，在校生一般玩不起），则不是他所要关心的。相信大家都有这样的体验，如果有朋友邀请你去打麻将或斗地主，而你却不怎么会玩，你多半会拒绝。但期货市场不同，对于一个自己几乎一无所知的品种，却也敢用真金白银去交易。

   这是为什么呢？

   因为交易者用自己所构建的模型对该产品的历史数据进行过回测，每个月均实现了正收益。这TM不就是传说中的印！钞！机！么！

   然而，只有真正交易过的人才知道，要想在期货市场凭自己所理解的技术分析去赚钱，太难！太难！要写一个回测结果很好的趋势跟踪模型，对于熟手来说，基本就是分分钟的事。但如果你把测试和实盘等同，我只能说你too young too simple。因为历史测试充其量只是对未来的粗略估计，它或许夸大了系统的内在优势本来是纯随机的现象，结果导致一个在历史回测中看似有效或曾经有效的系统不再有效。并且，很多初入期市的朋友，在写模型时或多或少都犯了过度优化的毛病，对于历史上那些模型本没抓住的单边走势，改个参数就抓住了；对于那些模型反复开仓的震荡走势，加个限制就避免了。可惜的是，要是可以交易历史数据的话，这个市场上还有亏货么？

   更为致命的是，即便你写的模型确实符合逻辑，也没有过度拟合，你以为就可以一劳永逸，躺着数钱了吗？那是因为你忘了，测试时，你可以把几年的模拟交易集中在几分钟之内完成，即使有几个月的回撤期，你也不觉得有啥，因为你知道了净值曲线的未来走势。但实盘交易时，分分钟都是煎熬，盘中每一个波动都会刺激你的神经。此外，模型测试时，你关注的全是盈利带来的喜悦；而实盘交易时，你感受到的全是亏损带来的痛楚。

   在实盘交易中，交易者的行为是复杂多变的，很多模型都由于与历史的吻合度太高，市场行为的一个轻微变化就会造成效果的明显恶化。再加上投资者某些情绪化和草率的出入场，承担了一些本没有必要承担的风险，再加上佣金和滑点，如此，根据市场的实际结构来说，大部分投机者注定就应该发生亏损。

  事实上，真正在市场上赚大钱的人，大都是悲观者和幸运者。说悲观，是因为他们都曾有过亏得睡不着觉的经历，知道赚钱的艰难；说幸运，是因为他们起起伏伏，但最终都活下来了。</code></pre>
<p>还记得，当年部门年会时，领导让我作为新人代表发言，我balabala，洋洋洒洒上千言，直听得他们无不击掌。但作为结尾，我话锋一转，说了下面的话：</p>
<pre><code>   要想在期货市场上用技术分析赚到大钱，无它，两个字而已，靠命！</code></pre>
<p>周末去了一趟王府井书店，没想到这年头到实体店买书的人还挺多。在里面转悠了一圈，来到股票板块，那家伙，各种分析、战法，直叫人应接不暇。我随意挑了几本翻阅了一下，看完后甚是惆怅，原来自己这么多年的书都白念了，这么多年的交易体验都白瞎了，因为所有的书都给人一种感觉：“炒股太简单啦！”“股市就是提款机！”“我们的目标是星辰大海！”。</p>
<p>回家路上，我对老婆说：“要不咱别做交易了，怪辛苦的，改写书吧？”</p>
<pre><code>  “我看你有这个潜质。”

    在期货市场，散户凭借技术分析是能赚钱的，但前提是你能够战胜自己的内心。但即便你战胜了自己的内心，要指望大赚特赚，基本还得靠命。</code></pre>
<hr>
<p>拓展阅读：</p>
<p>序号    标题    传送链接<br>1    双均线策略(期货)  量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/153">https://www.myquant.cn/docs/python_strategyies/153</a><br>2    alpha对冲(股票+期货)  量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/101">https://www.myquant.cn/docs/python_strategyies/101</a><br>3    集合竞价选股(股票) 量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/102">https://www.myquant.cn/docs/python_strategyies/102</a><br>4    多因子选股(股票)  量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/103">https://www.myquant.cn/docs/python_strategyies/103</a><br>5    网格交易(期货)  量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/104">https://www.myquant.cn/docs/python_strategyies/104</a><br>6    指数增强(股票)  量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/105">https://www.myquant.cn/docs/python_strategyies/105</a><br>7    跨品种套利(期货)量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/106">https://www.myquant.cn/docs/python_strategyies/106</a><br>8    跨期套利(期货) 量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/107">https://www.myquant.cn/docs/python_strategyies/107</a><br>9    日内回转交易(股票)量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/108">https://www.myquant.cn/docs/python_strategyies/108</a><br>10    做市商交易(期货) 量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/109">https://www.myquant.cn/docs/python_strategyies/109</a><br>11    海龟交易法(期货) 量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/110">https://www.myquant.cn/docs/python_strategyies/110</a><br>12    行业轮动(股票) 量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/111">https://www.myquant.cn/docs/python_strategyies/111</a><br>13    机器学习(股票) 量化策略源码    <a href="https://www.myquant.cn/docs/python_strategyies/112">https://www.myquant.cn/docs/python_strategyies/112</a><br>14    仓位管理（1）： 鞅与反鞅策略，凯利公司及其局限    <a href="https://www.myquant.cn/community/topic/673/2">https://www.myquant.cn/community/topic/673/2</a><br>15    仓位管理（2）： 凯利公式指导投资与多种资金管理方式    <a href="https://www.myquant.cn/community/topic/679">https://www.myquant.cn/community/topic/679</a><br>16    多因子选股之有效因子    <a href="https://www.myquant.cn/community/topic/690">https://www.myquant.cn/community/topic/690</a><br>17    多因子策略之冗余因子    <a href="https://www.myquant.cn/community/topic/695">https://www.myquant.cn/community/topic/695</a><br>18    多因子选股之策略的实现    <a href="https://www.myquant.cn/community/topic/708/2">https://www.myquant.cn/community/topic/708/2</a><br>19    大师系列之彼得•林奇基层调查选股法    <a href="https://www.myquant.cn/community/topic/719/2">https://www.myquant.cn/community/topic/719/2</a><br>20    从量化角度告诉你常见的技术指标到底能不能赚钱？    <a href="https://www.myquant.cn/community/topic/649/2">https://www.myquant.cn/community/topic/649/2</a><br>21    从回测到实盘（2）：如何让回测更贴近实盘结果     <a href="https://www.myquant.cn/community/topic/665">https://www.myquant.cn/community/topic/665</a><br>22    程序化交易（3）：从回测到实盘，还需要注意些什么？    <a href="https://www.myquant.cn/community/topic/668">https://www.myquant.cn/community/topic/668</a><br>23    股市暴跌深套 | 如何利用日内回转交易策略降低持仓成本    <a href="https://www.myquant.cn/community/topic/704">https://www.myquant.cn/community/topic/704</a><br>24    算法交易策略的成功回测之一    <a href="https://www.myquant.cn/community/topic/721">https://www.myquant.cn/community/topic/721</a><br>25    股票中的情侣——配对交易    <a href="https://www.myquant.cn/community/topic/735">https://www.myquant.cn/community/topic/735</a><br>26    量化交易入门    <a href="https://www.myquant.cn/community/topic/28/2">https://www.myquant.cn/community/topic/28/2</a><br>27    分享一个python均线策略    <a href="https://www.myquant.cn/community/topic/78/2">https://www.myquant.cn/community/topic/78/2</a><br>28    一个量化交易策略师的自白    <a href="https://www.myquant.cn/community/topic/652/2">https://www.myquant.cn/community/topic/652/2</a><br>29    《利用Python进行数据分析》PDF电子书下载    <a href="https://www.myquant.cn/community/topic/618">https://www.myquant.cn/community/topic/618</a><br>30    高频交易：为了0.07毫秒的比拼，竟然花费了1400万美金    <a href="https://www.myquant.cn/community/topic/634/2">https://www.myquant.cn/community/topic/634/2</a><br>31    分享几本量化和python方面的书，可以直接下载    <a href="https://www.myquant.cn/community/topic/89/2">https://www.myquant.cn/community/topic/89/2</a><br>32    2018：数据科学20个最好的Python库    <a href="https://www.myquant.cn/community/topic/664">https://www.myquant.cn/community/topic/664</a><br>33    《投资中最简单的事》读书笔记    <a href="https://www.myquant.cn/community/topic/575/2">https://www.myquant.cn/community/topic/575/2</a><br>34    史上最全的量化交易资源合集    <a href="https://www.myquant.cn/community/topic/624/2">https://www.myquant.cn/community/topic/624/2</a><br>35    七种量化选股模型    <a href="https://www.myquant.cn/community/topic/663">https://www.myquant.cn/community/topic/663</a><br>36    谈资金管理    <a href="https://www.myquant.cn/community/topic/579/2">https://www.myquant.cn/community/topic/579/2</a><br>37    网格交易策略（附策略源码与收益图）    <a href="https://www.myquant.cn/community/topic/548/2">https://www.myquant.cn/community/topic/548/2</a><br>38    指数增强策略    <a href="https://www.myquant.cn/community/topic/527">https://www.myquant.cn/community/topic/527</a><br>39    日内回转交易策略    <a href="https://www.myquant.cn/community/topic/526">https://www.myquant.cn/community/topic/526</a><br>40    跨期套利策略    <a href="https://www.myquant.cn/community/topic/525">https://www.myquant.cn/community/topic/525</a><br>41    跨品种价差套利策略    <a href="https://www.myquant.cn/community/topic/524">https://www.myquant.cn/community/topic/524</a><br>42    集合竞价选股    <a href="https://www.myquant.cn/community/topic/523">https://www.myquant.cn/community/topic/523</a><br>43    基于EV/EBITDA倍数估值法的Alpha对冲策略    <a href="https://www.myquant.cn/community/topic/522">https://www.myquant.cn/community/topic/522</a><br>44    行业轮动策略    <a href="https://www.myquant.cn/community/topic/521">https://www.myquant.cn/community/topic/521</a><br>45    海龟交易法则    <a href="https://www.myquant.cn/community/topic/520">https://www.myquant.cn/community/topic/520</a></p>
]]></content>
      <categories>
        <category>quant</category>
      </categories>
      <tags>
        <tag>quant</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始学习iftop流量监控（找出服务器耗费流量最多的ip和端口）</title>
    <url>/2020/07/27/61259/</url>
    <content><![CDATA[<h2 id="一、iftop是什么"><a href="#一、iftop是什么" class="headerlink" title="一、iftop是什么"></a>一、iftop是什么</h2><p>iftop是类似于top的实时流量监控工具。</p>
<p>作用：监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等</p>
<p>官网：<a href="http://www.ex-parrot.com/~pdw/iftop/">http://www.ex-parrot.com/~pdw/iftop/</a></p>
<h2 id="二、界面说明"><a href="#二、界面说明" class="headerlink" title="二、界面说明"></a>二、界面说明</h2><p>=&gt;代表发送数据，&lt;= 代表接收数据<br>TX：发送流量<br>RX：接收流量<br>TOTAL：总流量<br>Cumm：运行iftop到目前时间的总流量<br>peak：流量峰值<br>rates：分别表示过去 2s 10s 40s 的平均流量<br>##　三、常用参数<br>-i 指定需要检测的网卡， 如果有多个网络接口，则需要注意网络接口的选择，如：# iftop -i eth1<br>-B 将输出以byte为单位显示网卡流量，默认是bit<br>-n 将输出的主机信息都通过IP显示，不进行DNS解析<br>-N 只显示连接端口号，不显示端口对应的服务名称<br>-F 显示特定网段的网卡进出流量  如iftop -F 192.168.85.0/24<br>-h 帮助，显示参数信息<br>-p 以混杂模式运行iftop，此时iftop可以用作网络嗅探器 ;<br>-P 显示主机以及端口信息<br>-m 设置输出界面中最上面的流量刻度最大值，流量刻度分5个大段显示  如：# iftop -m 100M<br>-f 使用筛选码选择数据包来计数  如iftop -f filter code<br>-b 不显示流量图形条<br>-c 指定可选的配置文件   如iftop  -c config file<br>-t 使用不带ncurses的文本界面，<br>    以下两个是只和-t一起用的：<br>    -s num num秒后打印一次文本输出然后退出，-t -s 60组合使用，表示取60秒网络流量输出到终端<br>    -L num 打印的行数<br>-f 参数支持tcpdump的语法，可以使用各种过滤条件。</p>
<h2 id="四、进入界面后的操作"><a href="#四、进入界面后的操作" class="headerlink" title="四、进入界面后的操作"></a>四、进入界面后的操作</h2><p>一般参数<br>P      切换暂停/继续显示<br>h      在交互界面/状态输出界面之间切换<br>b      切换是否显示平均流量图形条<br>B      切换显示2s 10s和40s内的平均流量<br>T      切换是否显示每个连接的总流量<br>j/k    向上或向下滚动屏幕显示当前的连接信息<br>f      编辑筛选码<br>l      打开iftop输出过滤功能 ，如输入要显示的IP按回车键后屏幕就只显示与这个IP相关的流量信息<br>L      切换显示流量刻度范围，刻度不同，流量图形条也会不同<br>q      退出iftop<br>主机参数<br>n      使iftop输出结果以IP或主机名的方式显示<br>s      切换是否显示源主机信息<br>d      切换是否显示远端目标主机信息<br>t      切换输出模式,一行或多行<br>端口显示参数<br>N      切换显示端口号/端口号对应服务名称<br>S      切换是否显示本地源主机的端口信息<br>D      切换是否显示远端目标主机的端口信息<br>p      切换是否显示端口信息<br>输出排序参数<br>1/2/3  通过第一列/第二列/第三列排序<br>&lt;      根据左边的本地主机名或IP地址进行排序</p>
<blockquote>
<pre><code> 根据远端目标主机的主机名或IP地址进行排序</code></pre>
<p>o      切换是否固定显示当前的连接</p>
</blockquote>
<h2 id="五、使用示例"><a href="#五、使用示例" class="headerlink" title="五、使用示例"></a>五、使用示例</h2><p>1.显示网卡eth0的信息，主机通过ip显示<br>iftop -i eth0 -n<br>2.显示端口号（添加-P参数，进入界面可通过p参数关闭）<br>iftop -i eth0 -n -P<br>3.显示将输出以byte为单位显示网卡流量,默认是bit<br>iftop -i eth0 -n -B<br>4.显示流量进度条<br>iftop -i eth0 -n(进入界面后按下L)<br>5.显示每个连接的总流量<br>iftop -i eth0 -n(进入界面后按下T)<br>6.显示指定ip 172.17.1.158的流量<br>iftop -i eth0 -n(进入界面后按下l,输入172.17.1.158回车)</p>
<h2 id="六、实战-找出最费流量的ip和端口号"><a href="#六、实战-找出最费流量的ip和端口号" class="headerlink" title="六、实战-找出最费流量的ip和端口号"></a>六、实战-找出最费流量的ip和端口号</h2><p>网上找了一圈，全是粘贴复制的iftop命令使用，没说到点上</p>
<p>接下，请欣赏真正的表演</p>
<p>1.进入界面<br>iftop -i eth0 -nNB -m 10M<br>-i 指定网卡，<br>-n 代表主机通过ip显示不走DNS<br>-N 只显示连接端口号，不显示端口对应的服务名称(不加会显示如ssh这样的服务名称，不便于排查)<br>-B 指定显示单位为Kb，默认是bit，太小！<br>-m 设置输出界面中最上面的流量刻度最大值，流量刻度分5个大段显示<br>进入后界面如下</p>
<p>2.按下L显示流量刻度<br>L参数直接显示进度条，方便人类阅读，别说你能直接通过数字感知，小心被砍死</p>
<p>3.按下T显示总量<br>总得有个总数统计，看着方便！</p>
<p>4.按下3，根据最近40s统计排序<br>用平均值来统计最权威点</p>
<p>5.按下t，发送和接受合成一行<br>显示两行没什么意思，一行就够了！</p>
<p>6.多按几次B，查看最近2s、10s、40s的统计</p>
<p>没错，图中的172.17.1.158就是我们找到的流量用得最多的IP</p>
<p>7.筛选指定IP 172.17.1.158<br>按下l, 输入172.17.1.158，出现如下</p>
<p>回车，生效</p>
<p>这下就只看到这个ip的流量监控了</p>
<p>8.找到这个ip哪个端口流量用得最多<br>按下p,根据端口号显示</p>
<p>到这里，我们就学会了如何找出流量用得最多的ip和端口号，这么好干货你不high起来对不起哥这么用心的截图！</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Iftop</tag>
      </tags>
  </entry>
  <entry>
    <title>你真的会用索引么？-- Mongo</title>
    <url>/2020/07/24/8356/</url>
    <content><![CDATA[<p>一次奇怪的查询经历<br>如何奇怪了？</p>
<p>对同一张表，用同样的SQL，查询200万条数据耗时100ms，查询二十条数据却耗时30s。<br>数据量少了10万倍，完全不是一个数量级的数据，耗时却多了300倍。<br>明明加了索引为什么还是那么慢？<br>下图是在本地简化模拟出来的查询结果，虽然没有那么夸张但是同样可以复现问题。</p>
<p>95.6万条数据，用时0.08秒</p>
<p>106条数据，用时10秒<br>如上二图，通过相同查询条件以及相同的排序条件，进行查询，查询效率缺却天差地别，下面让我们来一起探索一下究竟是为什么？</p>
<h2 id="索引概述"><a href="#索引概述" class="headerlink" title="索引概述"></a>索引概述</h2><p>我们常常会看到一些乱七八糟的索引，所以我们用索引的真正目的是什么呢？</p>
<p>终极目的：借助索引快速搜索，有效减少了扫描的行数</p>
<p>精髓：不止要有索引，索引的过滤性还要好，区分度要足够高，这才是好的设计</p>
<h2 id="索引的类型和属性"><a href="#索引的类型和属性" class="headerlink" title="索引的类型和属性"></a>索引的类型和属性</h2><p>唯一索引<br>唯一索引是索引具有的一种属性，让索引具备唯一性，确保这张表中，该条索引数据不会重复出现。在每一次insert和update操作时，都会进行索引的唯一性校验，保证该索引的字段组合在表中唯一。</p>
<p>db.containers.createIndex({name: 1},{unique:true, background: true})<br>db.packages.createIndex({ appId: 1, version: 1 },{unique:true, background: true})</p>
<h1 id="知识点一："><a href="#知识点一：" class="headerlink" title="知识点一："></a>知识点一：</h1><p>创建索引时,1表示按升序存储,-1表示按降序存储。</p>
<h1 id="知识点二："><a href="#知识点二：" class="headerlink" title="知识点二："></a>知识点二：</h1><p>Mongo提供两种建索引的方式foreground和background。<br>前台操作，它会阻塞用户对数据的读写操作直到index构建完毕；<br>后台模式，不阻塞数据读写操作，独立的后台线程异步构建索引，此时仍然允许对数据的读写操作。</p>
<h3 id="创建索引时一定要写-background-true"><a href="#创建索引时一定要写-background-true" class="headerlink" title="创建索引时一定要写{background: true}"></a>创建索引时一定要写{background: true}</h3><h3 id="创建索引时一定要写-background-true-1"><a href="#创建索引时一定要写-background-true-1" class="headerlink" title="创建索引时一定要写{background: true}"></a>创建索引时一定要写{background: true}</h3><h3 id="创建索引时一定要写-background-true-2"><a href="#创建索引时一定要写-background-true-2" class="headerlink" title="创建索引时一定要写{background: true}"></a>创建索引时一定要写{background: true}</h3><h2 id="复合索引"><a href="#复合索引" class="headerlink" title="复合索引"></a>复合索引</h2><p>概念：指的是将多个键组合到一起创建索引，终极目的是加速匹配多个键的查询。</p>
<p>看例子来理解复合索引是最直接的方式：</p>
<p>图中模拟了简单的航班信息表的数据。</p>
<p>对表中指定航班进行查询，查询后按价格排序。</p>
<p>db.getCollection(‘flight’).find({flight: “CA12345”}).sort({price: 1})</p>
<p>在没有索引的情况下，那么他其实是会一条一条的扫描全部8条数据，找到CA12345航班，然后再在内存中按价钱进行排序。</p>
<p>如果这时我给航班添加一条索引db.flights.createIndex({ flight: 1 },{background: true})，那么索引会类似于下图一样，将数据按照索引规则进行排序，此时就只需要扫描4条CA12345航班的数据，然后再在内存中进行排序。如果数据量大了以后，在内存中进行排序的代价是非常大的。</p>
<p>所以我们可以建立复合索引 db.flights.createIndex({ flight: 1, price: 1 },{background: true})</p>
<p>让数据按照索引先将所有数据以航班号有序排列，再在航班号相同的数据集中按价格升序排列，这样在进行查询的时候，就可以准确的使用索引扫描4条数据，并且他们本身就是有序的，无需再进行额外的排序工作。以上实现了通过复合索引，让查询变得最优，这就是复合索引的作用。</p>
<h2 id="内嵌索引"><a href="#内嵌索引" class="headerlink" title="内嵌索引"></a>内嵌索引</h2><p>可以在嵌套的文档上建立索引，方式与建立正常索引完全一致。</p>
<p>个人信息表结构如下,包含了省市区三级的地址信息，如果想要给城市（city）添加索引，其实就和正常添索引一样</p>
<p>db.personInfos.createIndex({“address.city”:1})</p>
<p>const personInfo = new Schema({<br>  name: { type: String, required: true },<br>  address: {<br>    province: { type: String, required: true },<br>    city: { type: String, required: true },<br>    district: { type: String, required: true },<br>  }<br>}, {timestamps: true});</p>
<h1 id="知识点三："><a href="#知识点三：" class="headerlink" title="知识点三："></a>知识点三：</h1><p>对嵌套文档本身“address”建立索引，与对嵌套文档的某个字段（address.city）建立索引是完全不相同的。<br>对整个文档建立索引，只有在使用文档完整匹配时才会使用到这个索引，例如建立了这样一个索引db.personInfos.createIndex({“address”:1})，那么只有使用db.personInfos.find({“address”:{“province”:”xxx”,”city”:”xxx”,””district”:”xxx”}})这种完整匹配时才会使用到这个索引，使用db.personInfos.find({“address.city”:”xxx”})是不会使用到该索引的。<br>数组索引<br>MongoDB支持对数组建立索引，这样就可以高效的搜索数组中的特定元素。</p>
<h1 id="知识点四："><a href="#知识点四：" class="headerlink" title="知识点四："></a>知识点四：</h1><p>但是！对数组建立索引的代价是非常高的，他实际上是会对数组中的每一项都单独建立索引，就相当于假设数组中有十项，那么就会在原基础上，多出十倍的索引大小。如果有一百个一千个呢？<br>所以在mongo中是禁止对两个数组添加复合索引的，对两个数组添加索引那么索引大小将是爆炸增长，所以谨记在心。<br>过期索引（TTL）<br>可以针对某个时间字段，指定文档的过期时间（经过指定时间后过期 或 在某个时间点过期）</p>
<p>##　哈希索引（Hashed Index）<br>是指按照某个字段的hash值来建立索引，hash索引只能满足字段完全匹配的查询，不能满足范围查询等</p>
<h2 id="地理位置索引（Geospatial-Index）"><a href="#地理位置索引（Geospatial-Index）" class="headerlink" title="地理位置索引（Geospatial Index）"></a>地理位置索引（Geospatial Index）</h2><p>能很好的解决一些场景，比如『查找附近的美食』、『查找附近的加油站』等</p>
<h2 id="文本索引（Text-Index）"><a href="#文本索引（Text-Index）" class="headerlink" title="文本索引（Text Index）"></a>文本索引（Text Index）</h2><p>能解决快速文本查找的需求，比如，日志平台，相对日志关键词查找，如果通过正则来查找的话效率极低，这时就可以通过文本索引的形式来进行查找</p>
<h3 id="索引的优点"><a href="#索引的优点" class="headerlink" title="索引的优点"></a>索引的优点</h3><p>1.减少数据扫描：避免全表扫描代价</p>
<p>2.减少内存计算：避免分组排序计算</p>
<p>3.提供数据约束：唯一和时间约束性</p>
<h3 id="索引的缺点"><a href="#索引的缺点" class="headerlink" title="索引的缺点"></a>索引的缺点</h3><p>1.增加容量消耗：创建时需额外存储索引数据</p>
<p>2.增加修改代价：增删改都需要维护索引数据</p>
<p>3.索引依赖内存：会占用极其宝贵的内存资源</p>
<p>索引固然不全是优点，如果不能了解到索引可能带来的危害滥用索引，后果也是非常严重的。</p>
<p>索引虽然也是持久化在磁盘中的，但为了确保索引的速度，实际上需要将索引加载到内存中使用，使用过后还会进行缓存，内存资源相比磁盘空间那是非常的珍贵了。当内存不足以承载索引的时候，就会出现内存——磁盘交换的情况，这时会大大降低索引的性能。</p>
<p>有人说研究索引好累啊？我给我的每个字段都加一个索引不就完事了么？其实每个人都知道这样不好，但实战中好多人都是这样干的。无脑的给每个字段都加上索引就意味着每一次数据库操作，不仅需要更新文档，还需要有大量索引需要更新。mongo每次查询只会使用一个索引。想不到吧？不是你想的我先查航班，在用价格排序，会先走航班的索引，再走价格的索引，你做梦去吧，不可能的，他只会选定一条索引，并不会因为你给每个字端都加了索引就解决问题了。</p>
<h1 id="知识点五："><a href="#知识点五：" class="headerlink" title="知识点五："></a>知识点五：</h1><p>为了追求索引的速度，索引是加载在内存中使用的，不能合理使用索引后果严重。<br>mongo每次查询只会使用一次索引！！！只有$or或查询特殊，他会给每一个或分支使用索引然后再合并<br>何时不应该使用索引<br>也有一些查询不使用索引会更快。结果集在原集合中所占的比例越大，查询效率越慢。因为使用索引需要进行两次查找：一次查找索引条目，一次根据索引指针去查找相应的文档。而全表扫描只需要进行一次查询。在最坏的情况，使用索引进行查找次数会是全表扫描的两倍。效率会明显比全表扫描低。</p>
<p>而相反在提取较小的子数据集时，索引就非常有效，这就是我们为什么会使用分页。</p>
<h3 id="查询优化器"><a href="#查询优化器" class="headerlink" title="查询优化器"></a>查询优化器</h3><p>Mongo自带了一个查询优化器会为我们选择最合适的查询方案。</p>
<p>如果一个索引能够精确匹配一个查询，那么查询优化器就会使用这个索引。</p>
<p>如果不能精确匹配呢？可能会有几个索引都适合你的查询，那MongoDB是怎样选择的呢？</p>
<p>MongoDB的查询计划会将多个索引并行的去执行，最先返回第101个结果的就是胜者，其他查询计划都会被终止，执行优胜的查询计划；<br>这个查询计划会被缓存，接下来相同的查询条件都会使用它；<br>何时查询计划缓存才会变呢？<br>在计划评估之后表发生了比较大的数据波动，查询优化器就会重新挑选可行的查询计划<br>建立索引时<br>每执行1000次查询之后，查询优化器就会重新评估查询计划<br>联合索引的优化<br>当你查询条件的顺序和你索引的顺序不一致的话，mongo会自动的调整查询顺序，保证你可以使用上索引。</p>
<p>例如：你的查询条件是(a,c,b)但是你的索引是（a,b,c）mongo会自动将你的查询条件调整为abc，寻找最优解。</p>
<h2 id="聚合管道的优化"><a href="#聚合管道的优化" class="headerlink" title="聚合管道的优化"></a>聚合管道的优化</h2><p>如果管道中不需要使用一个完整的文档的全部字段的话，管道不会将多余字段进行传递<br>$sort 和 $limit 合并,在内存中只会维护limit个数量的文档，不需要将所有的文档维护在内存中，大大降低内存中sort的压力<br>然而管道中的索引使用情况是极其不佳的，在管道中，只有在管道最开始时的match sort可以使用到索引，一旦发生过project投射，group分组，lookup表关联，unwind打散等操作后，就完全无法使用索引。</p>
<p>希望通过本文能让你对Mongo的索引有更深的理解</p>
<h1 id="Explain查询计划"><a href="#Explain查询计划" class="headerlink" title="Explain查询计划"></a>Explain查询计划</h1><p>提到查的慢，二话不说直接看查询计划好么？具体每一个字段的含义我就不做赘述了很容易查到，我截取winningPlan的部分和大家一起看一下。WinningPlan就是在查询计划中胜出的方案，那肯定就有被淘汰的方案，是在rejectPlan里。</p>
<p>// 查询计划中的winningPlan部分<br>“winningPlan”: {<br>    “stage”: “FETCH”,<br>    “filter”: {<br>        “createdAt”: {<br>            “$gte”: ISODate(“2019-07-22T12:00:44.000Z”)<br>        }<br>    },<br>    “inputStage”: {<br>        “stage”: “IXSCAN”,<br>        “keyPattern”: {<br>            “load”: 1<br>        },<br>        “indexName”: “load_1”,<br>        “isMultiKey”: false,<br>        “multiKeyPaths”: {<br>            “load”: []<br>        },<br>        “isUnique”: false,<br>        “isSparse”: false,<br>        “isPartial”: false,<br>        “indexVersion”: 2,<br>        “direction”: “backward”,<br>        “indexBounds”: {<br>            “load”: [<br>                “[MaxKey, MinKey]”<br>            ]<br>        }<br>    }<br>},<br>看不懂？没关系，先学习了下面两个知识点，我带你读一遍。</p>
<h1 id="知识点六："><a href="#知识点六：" class="headerlink" title="知识点六："></a>知识点六：</h1><p>explain 结果将查询计划以阶段树的形式呈现。<br>每个阶段将其结果（文档或索引键）传递给父节点。<br>中间节点操纵由子节点产生的文档或索引键。<br>根节点是MongoDB从中派生结果集的最后阶段。<br>对于新人一定要特别注意：在看查询结果的阶段树的时候一定一定是从最里层一层一层往外看的，不是直接顺着读下来的。</p>
<h1 id="知识点七："><a href="#知识点七：" class="headerlink" title="知识点七："></a>知识点七：</h1><p>在查询计划中出现了很多stage，下面列举的经常出现的stage以及他的含义：<br>COLLSCAN：全表扫描<br>IXSCAN：索引扫描<br>FETCH：根据前面扫描到的位置抓取完整文档<br>SORT：进行内存排序，最终返回结果<br>SORT_KEY_GENERATOR：获取每一个文档排序所用的键值<br>LIMIT：使用limit限制返回数<br>SKIP：使用skip进行跳过<br>IDHACK：针对_id进行查询<br>COUNTSCAN：count不使用用Index进行count时的stage返回<br>COUNT_SCAN：count使用了Index进行count时的stage返回<br>TEXT：使用全文索引进行查询时候的stage返回<br>Explain解读：</p>
<p>将解读写在了注释中，按顺序阅读</p>
<p>// 查询计划中的winningPlan部分<br>“winningPlan”: {<br>    “stage”: “FETCH”,                                            // 5. 根据内层阶段树查到的索引去抓取完整的文档<br>    “filter”: {                                                  // 6. 再根据createdAt参数进行筛选<br>        “createdAt”: {<br>            “$gte”: ISODate(“2019-07-22T12:00:44.000Z”)<br>        }<br>    },<br>    “inputStage”: {                                               // 1. 每个阶段将自己的查询结果传递给父阶段树，所以从里往外读Explain<br>        “stage”: “IXSCAN”,                                    // 2. IXSCAN该阶段使用了索引进行扫描<br>        “keyPattern”: {<br>            “load”: 1                                     // 3. 使用了 load:1 这条索引<br>        },<br>        “indexName”: “load_1”,<br>        “isMultiKey”: false,<br>        “multiKeyPaths”: {<br>            “load”: []<br>        },<br>        “isUnique”: false,<br>        “isSparse”: false,<br>        “isPartial”: false,<br>        “indexVersion”: 2,<br>        “direction”: “backward”,<br>        “indexBounds”: {<br>            “load”: [<br>                “[MaxKey, MinKey]”                      // 4. 边界<br>            ]<br>        }<br>    }<br>},<br>最后在本文末尾，留下了前面查询航班按价钱排序的例子，在各种索引下的查询计划<br>最期望看到的查询组合<br>Fetch+IDHACK<br>Fetch+ixscan<br>Limit+（Fetch+ixscan）<br>PROJECTION+ixscan<br>最不期望看到的查询组合<br>COLLSCAN（全表扫）<br>SORT（使用sort但是无index）<br>COUNTSCAN（不使用索引进行count）<br>最左前缀原则<br>假定索引(a，b，c) 它可能满足的查询如下：</p>
<ol>
<li><p>a</p>
</li>
<li><p>a，b</p>
</li>
<li><p>a，b，c</p>
</li>
<li><p>a，c [该组合只能用a部分]</p>
</li>
<li><p>a, c, b [cb在查询时会被优化换位置]</p>
</li>
</ol>
<p>显然，最左前缀的核心是查询条件字段必须含有索引第一个字段</p>
<p>最左值尽可能用最精确过滤性最好的值，不要用那种可能会用于范围模糊查询，用于排序的字段</p>
<p>效率极低的操作符<br>$where和$exists：这两个操作符，完全不能使用索引。<br>$ne和$not:通常来说取反和不等于,可以使用索引，但是效率极低，不是很有效，往往也会退化成扫描全表。<br>$nin:不包含，这个操作符也总是会全表扫描<br>对于管道中的索引，也很容易出现意外，只有在管道最开始时的match sort可以使用到索引，一旦发生过project投射，group分组，lookup表关联，unwind打散等操作后，就完全无法使用索引。</p>
<h1 id="索引设计和优化原则"><a href="#索引设计和优化原则" class="headerlink" title="索引设计和优化原则"></a>索引设计和优化原则</h1><p>最后祭出李丹老师的索引设计和优化原则</p>
<h2 id="1-主键的设置"><a href="#1-主键的设置" class="headerlink" title="1.主键的设置"></a>1.主键的设置</h2><p>业务无关、显示指定、递增属性</p>
<h2 id="2-数据区分度"><a href="#2-数据区分度" class="headerlink" title="2.数据区分度"></a>2.数据区分度</h2><p>原则上区分度高的字段优先做索引字段，如果是组合索引优先放前面</p>
<h2 id="3-字段更新频率"><a href="#3-字段更新频率" class="headerlink" title="3.字段更新频率"></a>3.字段更新频率</h2><p>频繁更新的字段是否做索引字段需要综合考虑对业务的影响及查询的代价</p>
<h2 id="4-前缀索引问题"><a href="#4-前缀索引问题" class="headerlink" title="4.前缀索引问题"></a>4.前缀索引问题</h2><p>需要注意的是因前缀索引只包含部分值因此无法通过前缀索引优化排序</p>
<h2 id="5-适当冗余设计"><a href="#5-适当冗余设计" class="headerlink" title="5.适当冗余设计"></a>5.适当冗余设计</h2><p>对于存储较长字符串字段可额外增加字段存储原字段计算(如hash)后的值</p>
<p>创建索引时只需要对额外字段创建索引即可</p>
<h2 id="6-避免无效索引"><a href="#6-避免无效索引" class="headerlink" title="6.避免无效索引"></a>6.避免无效索引</h2><p>通常类似表已经含有主键ID就无需再创建额外唯一性的ID索引</p>
<h2 id="7-查询覆盖率"><a href="#7-查询覆盖率" class="headerlink" title="7.查询覆盖率"></a>7.查询覆盖率</h2><p>设计一个索引我们需要考虑尽量覆盖更多的查询场景</p>
<h2 id="8-控制字段数"><a href="#8-控制字段数" class="headerlink" title="8.控制字段数"></a>8.控制字段数</h2><p>如果你设计的索引例如含有7、8个字段通常需要考虑设计是否合理</p>
<h2 id="优化原则"><a href="#优化原则" class="headerlink" title="优化原则"></a>优化原则</h2><h3 id="1-减少网络带宽"><a href="#1-减少网络带宽" class="headerlink" title="1.减少网络带宽"></a>1.减少网络带宽</h3><p>按需返回所需字段、尽量避免返回大字段</p>
<h3 id="2-减少内存计算"><a href="#2-减少内存计算" class="headerlink" title="2.减少内存计算"></a>2.减少内存计算</h3><p>减少无必要中间结果存储、减少内存计算</p>
<h3 id="3-减少磁盘IO"><a href="#3-减少磁盘IO" class="headerlink" title="3.减少磁盘IO"></a>3.减少磁盘IO</h3><p>添加合适的索引、关注SQL改写</p>
<p>前文查询航班按价钱排序的例子，在各种索引下的查询计划</p>
<p><a href="https://zhuanlan.zhihu.com/p/77971681">https://zhuanlan.zhihu.com/p/77971681</a><br><a href="https://juejin.im/post/5ad1d2836fb9a028dd4eaae6">正确的使用mongo索引</a><br><a href="https://blog.souche.com/mysql-explain/">Explain分析查询语句</a></p>
]]></content>
      <categories>
        <category>Mongo</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Docker 搭建 MTProxy TG 专用代理</title>
    <url>/2016/09/16/47626/</url>
    <content><![CDATA[<p>Telegram 是一款开源且跨平台的 IM 工具（类似 Whatsapp、Messenger、微信），是我用过所有同类软件中用户体验最好的一个，同时我也是 Telegram 重度用户和开发者。当然，这么好用的工具在天朝是难以访问的。 —李钊同学</p>
<p>由于你知道的原因，Telegram 在天朝默认情况下是无法使用的，当然你可以先打开 Shadowsocks 或是 V2Ray 等代理软件正常访问国际互联网，然后才可以正常使用 Telegram 但是这样就让 IM软件失去了一部分使用体验。</p>
<p>前段时间 俄罗斯🇷🇺当局因 Telegram 公司不提供通讯加密密钥(为了信息审查)为由决定屏蔽 Telegram 服务，但最终没有获得成功为此 俄罗斯当局还屏蔽了 Google Microsoft 等公司的云服务器 IP段 可谓是用心良苦。Telegram 为了对抗封锁开发了 MTProxy Telegram 专用代理；对于处于同样情况的天朝来说也可以通过它正常使用 Telegram 服务</p>
<p>MTProxy</p>
<p>MTProxy 是在新版本 Telegram 中内置的代理程序</p>
<p>MTProxy的命名，大概和MTProto有关<br>Telegram 团队使用自己设计的加密协议 MTProto ，并以 30 万美金的高价奖赏漏洞的提交者。Telegram 使用基于 MTProto 的通讯协议。</p>
<p>在新版的 Telegram 中 Proxy 设置已经新增了 MTProxy 支持，我们只需要把相应的地址和密钥填入就能愉快的玩耍了</p>
<p>下面说一下如何使用 Docker 快速部署</p>
<p>安装 Docker<br>使用官方简化命令安装:</p>
<h2 id="适用于-Linux"><a href="#适用于-Linux" class="headerlink" title="适用于 Linux"></a>适用于 Linux</h2><p>$ curl -fsSL get.docker.com -o get-docker.sh<br>$ sudo sh get-docker.sh –mirror Aliyun //使用阿里云镜像源加速</p>
<h2 id="启动-Docker"><a href="#启动-Docker" class="headerlink" title="启动 Docker"></a>启动 Docker</h2><p>$ sudo systemctl enable docker<br>$ sudo systemctl start docker<br>部署 MTProxy 官方 Docker 镜像<br>$ docker pull telegrammessenger/proxy<br>$ docker run -d -p<port>:443 –name=mtproto-proxy –restart=always -v proxy-config:/data telegrammessenger/proxy:latest </port></p>
<h2 id="修改为你想要的端口"><a href="#修改为你想要的端口" class="headerlink" title=" 修改为你想要的端口"></a><port> 修改为你想要的端口</port></h2><p>$ docker logs mtproto-proxy</p>
<h2 id="查看你的链接信息"><a href="#查看你的链接信息" class="headerlink" title="查看你的链接信息"></a>查看你的链接信息</h2><h2 id="会输出如下信息"><a href="#会输出如下信息" class="headerlink" title="会输出如下信息"></a>会输出如下信息</h2><p>####</p>
<h4 id="Telegram-Proxy"><a href="#Telegram-Proxy" class="headerlink" title="Telegram Proxy"></a>Telegram Proxy</h4><p>####</p>
<p>[+] Using the secret in /data/secret: ‘xxxxxxxxxxxxxxxxxxxxxxxx’.<br>[<em>] Final configuration:<br>[</em>]   Secret 1: xxxxxxxxxxxxxxxxxxxxxxxx<br>[<em>]   tg:// link for secret 1 auto configuration: tg://proxy?server=你的服务器地址6&amp;port=443&amp;secret=xxxxxxxxxxxxxxxxxxxxxxxx<br>[</em>]   t.me link for secret 1: <a href="https://t.me/proxy?server=%E4%BD%A0%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9C%B0%E5%9D%806&amp;port=443&amp;secret=xxxxxxxxxxxxxxxxxxxxxxxx">https://t.me/proxy?server=你的服务器地址6&amp;port=443&amp;secret=xxxxxxxxxxxxxxxxxxxxxxxx</a><br>[<em>]   Tag: no tag<br>[</em>]   External IP: 你的服务器地址<br>[*]   Make sure to fix the links in case you run the proxy on a different port.<br>PS:<br>使用 docker logs mtproto-proxy 查询到的链接<br>其中的端口是默认的请根据你使用的端口酌情修改</p>
<p>使用 macOS Telegram 客户端作示例</p>
<p>参考：<br><a href="https://yeasy.gitbook.io/docker_practice/install/">Docker 从入门到实践 | 安装 Docker</a><br><a href="https://hub.docker.com/r/telegrammessenger/proxy/">telegrammessenger/proxy</a><br>本文链接： <a href="https://cloverkits.github.io/2018/08/18/%E4%BD%BF%E7%94%A8-Docker-%E6%90%AD%E5%BB%BA-MTProxy-TG-%E4%B8%93%E7%94%A8%E4%BB%A3%E7%90%86/">https://cloverkits.github.io/2018/08/18/使用-Docker-搭建-MTProxy-TG-专用代理/</a></p>
]]></content>
      <categories>
        <category>docker</category>
        <category>proxy</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>MTProxy</tag>
      </tags>
  </entry>
  <entry>
    <title>单机版——docker搭建MongoDB分片集群</title>
    <url>/2020/07/30/42383/</url>
    <content><![CDATA[<p>记录了在如何利用docker搭建MongoDB的分片集群。这里使用1个mongos、3个config server和2组分片副本集，每组分片副本集1主2从。</p>
<h2 id="1-搭建config-server"><a href="#1-搭建config-server" class="headerlink" title="1. 搭建config server"></a>1. 搭建config server</h2><p>这里启动了3个config server。docker命令如下：</p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker run  --restart: always --name cs0 -itd -v ~/data/db/mongo/cs0:/data/db -p <span class="number">27019</span>:<span class="number">27019</span> mongo --configsvr --replSet <span class="string">&quot;rs_configsvr&quot;</span>  --bind_ip_all</span><br><span class="line">docker run  -- restart: always --name cs1 -itd -v ~/data/db/mongo/cs1:/data/db -p <span class="number">27029</span>:<span class="number">27019</span>  mongo --configsvr --replSet <span class="string">&quot;rs_configsvr&quot;</span>  --bind_ip_all</span><br><span class="line">docker run -- restart: always --name cs2 -itd -v ~/data/db/mongo/cs2:/data/db -p <span class="number">27039</span>:<span class="number">27019</span>  mongo --configsvr --replSet <span class="string">&quot;rs_configsvr&quot;</span>  --bind_ip_all</span><br></pre></td></tr></table></figure>
<p>启动完后可以利用docker ps -a来看config server是否启动成功。我们通过命令docker inspect cs0 | grep IPAddress看下cs0的ip地址，发现地址是172.17.0.9。相同的方法看到cs1和cs2的ip分别为172.17.0.10和172.17.0.11。</p>
<p>docker exec -it cs0 bash进入cs0容器里，并连接MongoDB配置服，配置服的端口为27019。命令如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mongo --host <span class="number">172.17</span><span class="number">.0</span><span class="number">.9</span> --port <span class="number">27019</span></span><br></pre></td></tr></table></figure>
<p>登录进MongoDB后开始配置config server:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line">  &#123;</span><br><span class="line">    _id: <span class="string">&quot;rs_configsvr&quot;</span>,</span><br><span class="line">    configsvr: true,</span><br><span class="line">    members: [</span><br><span class="line">      &#123; _id : <span class="number">0</span>, host : <span class="string">&quot;172.17.0.9:27019&quot;</span> &#125;,</span><br><span class="line">      &#123; _id : <span class="number">1</span>, host : <span class="string">&quot;172.17.0.10:27019&quot;</span> &#125;,</span><br><span class="line">      &#123; _id : <span class="number">2</span>, host : <span class="string">&quot;172.17.0.11:27019&quot;</span> &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>返回的ok里的值为1就表示配置成功了。</p>
<h2 id="2-搭建分片副本集"><a href="#2-搭建分片副本集" class="headerlink" title="2. 搭建分片副本集"></a>2. 搭建分片副本集</h2><p>这里启动了2组分片副本集，命令如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker run -- restart: always --name shm00 -itd -v ~/data/db/mongo/db00:/data/db -p <span class="number">27018</span>:<span class="number">27018</span> mongo --shardsvr --replSet <span class="string">&quot;rs_shardsvr0&quot;</span>  --bind_ip_all</span><br><span class="line">docker run -- restart: always --name shm01 -itd -v ~/data/db/mongo/db01:/data/db -p <span class="number">27028</span>:<span class="number">27018</span> mongo --shardsvr --replSet <span class="string">&quot;rs_shardsvr0&quot;</span>  --bind_ip_all</span><br><span class="line">docker run -- restart: always --name shm02 -itd -v ~/data/db/mongo/db02:/data/db -p <span class="number">27038</span>:<span class="number">27018</span> mongo --shardsvr --replSet <span class="string">&quot;rs_shardsvr0&quot;</span>  --bind_ip_all</span><br><span class="line">docker run -- restart: always --name shm10 -itd -v ~/data/db/mongo/db10:/data/db -p <span class="number">27048</span>:<span class="number">27018</span> mongo --shardsvr --replSet <span class="string">&quot;rs_shardsvr1&quot;</span>  --bind_ip_all</span><br><span class="line">docker run -- restart: always --name shm11 -itd -v ~/data/db/mongo/db11:/data/db -p <span class="number">27058</span>:<span class="number">27018</span> mongo --shardsvr --replSet <span class="string">&quot;rs_shardsvr1&quot;</span>  --bind_ip_all</span><br><span class="line">docker run -- restart: always --name shm12 -itd -v ~/data/db/mongo/db12:/data/db -p <span class="number">27068</span>:<span class="number">27018</span> mongo --shardsvr --replSet <span class="string">&quot;rs_shardsvr1&quot;</span>  --bind_ip_all</span><br></pre></td></tr></table></figure>
<p>查看shm00和shm01的ip：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker inspect shm00 | grep IPAddress</span><br><span class="line">docker inspect shm10 | grep IPAddress</span><br></pre></td></tr></table></figure>
<p>发现shm00和shm10的ip尾号分别是12和15。</p>
<p>进入shm00容器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it shm00 bash</span><br><span class="line">mongo --host <span class="number">172.17</span><span class="number">.0</span><span class="number">.12</span> --port <span class="number">27018</span></span><br></pre></td></tr></table></figure>
<p>配置副本集rs_shardsvr0:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line">  &#123;</span><br><span class="line">    _id : <span class="string">&quot;rs_shardsvr0&quot;</span>,</span><br><span class="line">    members: [</span><br><span class="line">      &#123; _id : <span class="number">0</span>, host : <span class="string">&quot;172.17.0.12:27018&quot;</span> &#125;,</span><br><span class="line">      &#123; _id : <span class="number">1</span>, host : <span class="string">&quot;172.17.0.13:27018&quot;</span> &#125;,</span><br><span class="line">      &#123; _id : <span class="number">2</span>, host : <span class="string">&quot;172.17.0.14:27018&quot;</span> &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>同理配置副本集rs_shardsvr0：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mongo --host <span class="number">172.17</span><span class="number">.0</span><span class="number">.15</span> --port <span class="number">27018</span></span><br><span class="line"></span><br><span class="line">rs.initiate(</span><br><span class="line">  &#123;</span><br><span class="line">    _id : <span class="string">&quot;rs_shardsvr1&quot;</span>,</span><br><span class="line">    members: [</span><br><span class="line">      &#123; _id : <span class="number">0</span>, host : <span class="string">&quot;172.17.0.15:27018&quot;</span> &#125;,</span><br><span class="line">      &#123; _id : <span class="number">1</span>, host : <span class="string">&quot;172.17.0.16:27018&quot;</span> &#125;,</span><br><span class="line">      &#123; _id : <span class="number">2</span>, host : <span class="string">&quot;172.17.0.17:27018&quot;</span> &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="3-搭建mongos路由服"><a href="#3-搭建mongos路由服" class="headerlink" title="3. 搭建mongos路由服"></a>3. 搭建mongos路由服</h2><p>docker命令如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker run -- restart: always --name mongos0 -itd -p <span class="number">27017</span>:<span class="number">27017</span> --entrypoint <span class="string">&quot;mongos&quot;</span> mongo --configdb rs_configsvr/<span class="number">172.17</span><span class="number">.0</span><span class="number">.9</span>:<span class="number">27019</span>,<span class="number">172.17</span><span class="number">.10</span><span class="number">.3</span>:<span class="number">27019</span>,<span class="number">172.17</span><span class="number">.0</span><span class="number">.11</span>:<span class="number">27019</span> --bind_ip_all</span><br></pre></td></tr></table></figure>
<p>进入容器并连接MongoDB：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> -it mongos0 bash</span><br><span class="line"></span><br><span class="line">mongo --host <span class="number">172.17</span><span class="number">.0</span><span class="number">.18</span> --port <span class="number">27017</span></span><br></pre></td></tr></table></figure>
<p>配置分片信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sh.addShard(<span class="string">&quot;rs_shardsvr0/172.17.0.12:27018,172.17.0.13:27018,172.17.0.14:27018&quot;</span>)</span><br><span class="line"></span><br><span class="line">sh.addShard(<span class="string">&quot;rs_shardsvr1/172.17.0.15:27018,172.17.0.16:27018,172.17.0.17:27018&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>至此，我们的MongoDB分片集群就搭建好了。</p>
<h2 id="创建用户密码-增加认证"><a href="#创建用户密码-增加认证" class="headerlink" title="创建用户密码, 增加认证"></a>创建用户密码, 增加认证</h2><p>mongo4 以后的 解决方案：修改mechanisms加密方式为SCRAM-SHA-1</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">db.createUser(&#123; </span><br><span class="line">    user: <span class="string">&quot;admin&quot;</span>, </span><br><span class="line">    pwd: <span class="string">&quot;xxx&quot;</span>, </span><br><span class="line">    roles: [ &#123; role: <span class="string">&quot;userAdminAnyDatabase&quot;</span>, db: <span class="string">&quot;admin&quot;</span> &#125; ], </span><br><span class="line">    mechanisms : [<span class="string">&quot;SCRAM-SHA-1&quot;</span>] </span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.4以前的版本使用以下</span></span><br><span class="line">db.createUser(&#123; </span><br><span class="line">    user: <span class="string">&quot;admin&quot;</span>, </span><br><span class="line">    pwd: <span class="string">&quot;xxx&quot;</span>, </span><br><span class="line">    roles: [ &#123; role: <span class="string">&quot;userAdminAnyDatabase&quot;</span>, db: <span class="string">&quot;admin&quot;</span> &#125; ] </span><br><span class="line">&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="4-测试我们的集群"><a href="#4-测试我们的集群" class="headerlink" title="4. 测试我们的集群"></a>4. 测试我们的集群</h2><p>首先在mongos配置一个database并启动分片:sh.enableSharding(“mapp”)。</p>
<p>对order集合设置分片规则：sh.shardCollection(“mapp.order”, {“_id”: “hashed” })</p>
<p>好了，我们插入1000条数据看下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">use mapp</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= <span class="number">1000</span>; i=i+<span class="number">1</span>)&#123;</span><br><span class="line">    db.order.insert(&#123;<span class="string">&#x27;price&#x27;</span>: <span class="number">1</span>&#125;)</span><br><span class="line">&#125;</span><br><span class="line">db.order.find().count()查看数据确实是<span class="number">1000</span>条。我们再到<span class="number">2</span>个分片副本集看下吧：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> -it shm00 bash</span><br><span class="line">mongo --host <span class="number">172.17</span><span class="number">.0</span><span class="number">.12</span> --port <span class="number">27018</span></span><br><span class="line"></span><br><span class="line">use mapp</span><br><span class="line">db.order.find().count()</span><br></pre></td></tr></table></figure>
<p>我这里查看有505条数据。</p>
<p>另一个分片看下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> -it shm10 bash</span><br><span class="line">mongo --host <span class="number">172.17</span><span class="number">.0</span><span class="number">.15</span> --port <span class="number">27018</span></span><br><span class="line"></span><br><span class="line">use mapp</span><br><span class="line">db.order.find().count()</span><br></pre></td></tr></table></figure>
<p>我这里查看到右495条数据。看起来我们的数据是正常的。</p>
<p>刚才都是在主分片上看的，我们看下ip尾号为13的副本是怎么的情况：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it shm01 bash</span><br><span class="line">mongo --host <span class="number">172.17</span><span class="number">.0</span><span class="number">.13</span> --port <span class="number">27018</span></span><br><span class="line">rs.slaveOk()</span><br><span class="line">use mapp</span><br><span class="line">db.order.find().count()</span><br></pre></td></tr></table></figure>
<p>查看到数据是505条。确认ok。<br><a href="https://www.dazhuanlan.com/2019/08/21/5d5c524f315e1/">link</a></p>
]]></content>
  </entry>
  <entry>
    <title>可直接用浏览器打开的无头计算机docker images，包含 Chrome 与 Firefox，支持 VNC、RDP 协议</title>
    <url>/2018/03/09/59051/</url>
    <content><![CDATA[<p>可直接用浏览器打开的无头计算机，包含 Chrome 与 Firefox，支持 VNC、RDP 协议[Docker]</p>
<p>Docker 镜像：<a href="https://hub.docker.com/r/consol/centos-xfce-vnc/">consol/centos-xfce-vnc</a>，一个带有 Chrome 与 Firefox 浏览器的无头 VNC 服务器，可直接用浏览器打开</p>
<p>可直接用浏览器打开的无头计算机，包含 Chrome 与 Firefox，支持 VNC、RDP 协议[Docker] 1<br>这是个啥？</p>
<p>这是一个在 A 电脑的浏览器里打开 B 电脑上的浏览器的工具。</p>
<p>使用方法<br>原版：<br><a href="https://hub.docker.com/r/consol/centos-xfce-vnc/dockerfile">https://hub.docker.com/r/consol/centos-xfce-vnc/dockerfile</a></p>
<p>docker run -d -p 5901:5901 -p 6901:6901 consol/centos-xfce-vnc<br>浏览器，直接访问：<a href="http://ip:6901/">http://ip:6901</a><br>VNC：ip:5901<br>默认密码 vncpassword 即可。</p>
<p>新版：<br><a href="https://hub.docker.com/r/soff/ubuntu-xfce-vnc">https://hub.docker.com/r/soff/ubuntu-xfce-vnc</a></p>
<p>docker run -d -p 3389:3389 -p 5901:5901 -p 6901:6901 soff/ubuntu-xfce-vnc<br>浏览器，直接访问：<a href="http://ip:6901，密码">http://ip:6901，密码</a> vncpassword<br>VNC：ip:5901，密码 vncpassword<br>RDP：ip，用户名 user 密码 password<br>新版由 @imsoff 老师发布，精简掉了 Firefox。</p>
<p>也可以使用ubuntu版本<br><a href="https://hub.docker.com/r/consol/ubuntu-xfce-vnc/">ubuntu-xfce-vnc</a><br><a href="https://github.com/fcwu/docker-ubuntu-vnc-desktop">docker-ubuntu-vnc-dedktop</a><br>如何安装 Docker<br>青小蛙写过一篇教程，感兴趣的同学可以参考。以及，因为有了浏览器，建议选择配置高一点的机器，推荐 Vultr（👈有返利，感谢使用我们的推荐链接），支持支付宝、微信支付，十分方便。</p>
<p>如果你还想到其他玩法，欢迎留言告诉我们。</p>
<p>无头计算机<br>无头系统（headless system）是指已配置为无须显示器（即“头”）、键盘和鼠标操作的计算机系统或设备。无头系统通常通过网络连接控制，但也有部分无头系统的设备需要通过RS-232串行连接进行设备的管理。服务器通常采用无头模式以降低运作成本。</p>
]]></content>
      <categories>
        <category>docker</category>
        <category>centos-xfce-vnc</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>centos-xfce-vnc</tag>
      </tags>
  </entry>
  <entry>
    <title>唯有经历过交易四阶段，你才能彻底开悟</title>
    <url>/2018/04/12/54023/</url>
    <content><![CDATA[<p>交易之道，交易之术，有道无术术尚可求，有术无道止于术，何为道，何为术？</p>
<p>所谓大道至简的交易哲学，是需要经过很多年的实战才能领悟的。能够走向稳定成熟的股票交易者，往往需要3到5年经验的磨砺，这期间会经历多次爆仓和失败。</p>
<p>但是，如果在这个过程中能吸取来自其他优秀交易员的一些核心的交易理念，会加快你迈向稳定成熟的步伐。今天重点和大家谈一些你知道但不一定真的明白的朴素而且有效的交易理念，同时也指出多数交易者可能会经历的一些普遍阶段和感受。</p>
<h2 id="第一阶段：初遇，都会有一个好时光，股票也不例外"><a href="#第一阶段：初遇，都会有一个好时光，股票也不例外" class="headerlink" title="第一阶段：初遇，都会有一个好时光，股票也不例外"></a>第一阶段：初遇，都会有一个好时光，股票也不例外</h2><p>如同初恋一般，你初接触了股票，爱上它，开始变得如痴如醉。上班的时候，天天想着螺纹铁矿橡胶白糖；看新闻的时候，世界和平不再和你没关系；下班后，迫不及待地打开文华财经，开始交易起来。过了凌晨一点，才依依不舍强行平仓。</p>
<p>刚爱上一个事物的时候，是一个人的美好时光。你会主动去读很多关于交易的书籍，泡很多论坛，加很多群，可能还会拜几个资深交易的老师。</p>
<p>这个时候的你，对知识如饥似渴，疯狂的学习。随之而来的是你的知识面大增，国内局势、国际形势、政经环境、美联储、等等，都开始进入到你的日常生活。你觉得很high，比你身边的人多了更多的知识，时不时会在朋友圈发个行情分析显摆显摆。</p>
<p>这个时候的你，如同早上六七点钟的太阳，朝气蓬勃，势不可挡，不乏冷静和理性。你会不断的告诫自己，交易是有纪律的，进场是绝对要跟随趋势的，单子是必须要设置止损的。</p>
<p>这个时候的你，多少人是会主动去看股票作手回忆录，研究波浪和江恩。你会思考左侧和右侧交易的好与坏，结合理论每天复盘研究如何做的更好，还会去操基本面的心。</p>
<p>交易人生的美好，其实莫过如此。你会发现，你虽然有时候会小亏，但是赚的时候也不少。满打满算，可能还有不少的赚头。你的资金曲线，总体上是震荡向上。偶尔有点小挫折，但不影响大局。重要的是，你的账户不会发生重大的单笔亏损，因为你懂得及时止损退场。不会有精疲力尽的感觉，你同样懂得休息，不熬通宵。</p>
<p>于是你越来越投入其中，甚至觉得股票这片天，就是为你而造。这个幸福时光，可能会持续两年。</p>
<p>可是，人生好景不常有。就像爱情的新鲜度，不会超过18个月一样。度过了最初的两三年交易生涯，基本摸清了这个市场的来龙去脉，积累了一些交易经验，你开始进入交易高原期。这会是一段漫长而寂寞的时光。</p>
<h2 id="第二阶段：高原期，这是一个股票盘手奠定一生交易功底的时候"><a href="#第二阶段：高原期，这是一个股票盘手奠定一生交易功底的时候" class="headerlink" title="第二阶段：高原期，这是一个股票盘手奠定一生交易功底的时候"></a>第二阶段：高原期，这是一个股票盘手奠定一生交易功底的时候</h2><p>用多年的时间，才可能摸清这个市场的脉搏，积累交易技术、理念、资金管理，以及大量的实盘经验。这个阶段，你会发现你的交易进入了高原反应期，再也很难有突破，业绩时好时坏，有时候会经历一些单子的闪崩。你会让自己不断反省，有时候也会因为抓住一个大波浪而高兴。</p>
<p>这些漫长的时光里，你多次会以为自己经验已经相当丰富，交易系统成熟完善。你给自己制定的交易盈利目标里，收益率从最初的月收益20%降低到10%。你会告诉自己，一定可以每个月轻松赚到至少10%。（其实你的目标是半年至少翻一倍。）</p>
<p>这个阶段，你不会排斥用中型和重型仓位来做。你知道这不是最好的资金管理办法，但是你会安慰自己，你已经经历过三年或者六年的市场洗礼，什么大风大浪没经历过。你会觉得50%的仓位不会有什么大问题，而且，你时不时会经常越过这个界线。</p>
<p>你算不上成功，但也不算失败。一切都还在坚持，你把这定义为：苦难的长征。交易者，总是要有苦行僧的灵魂感召的！</p>
<h2 id="第三阶段：闪崩，是接下来大部分资深交易者的宿命，少有人能逃脱。要么退出，要么抑郁。坚持下来的，都成就了传奇。"><a href="#第三阶段：闪崩，是接下来大部分资深交易者的宿命，少有人能逃脱。要么退出，要么抑郁。坚持下来的，都成就了传奇。" class="headerlink" title="第三阶段：闪崩，是接下来大部分资深交易者的宿命，少有人能逃脱。要么退出，要么抑郁。坚持下来的，都成就了传奇。"></a>第三阶段：闪崩，是接下来大部分资深交易者的宿命，少有人能逃脱。要么退出，要么抑郁。坚持下来的，都成就了传奇。</h2><p>坚持了很多年，你以为自己要开始飞了。</p>
<p>看起来万事俱备只欠东风。经验，技术，知识，阅历，前面那么多年的修炼，让你觉得大干一场的时候终于到了！于是，你开始调集大批量的资金，借贷，抵押，筹集能弄到的钱，跑步入市。</p>
<p>春风吹，战鼓擂，百万资金进场急。</p>
<p>人生在此一战！你觉得在股票中赚回千万身家不多，亿万不少，荣华富贵、交易圣杯不再是梦。</p>
<p>交易的诱惑和人性的贪婪，不是以线性倍数在放大，而是以指数级别在放大！你第一次经历这样高逼格操盘的人生，你人性深处的劣势被指数级别打开。哪怕此前六年八年的漫长交易，都无法抹去这些弱点。</p>
<p>大资金的闪失，往往只出现在3%的概率里。我知道你会很小心去操作，告诫自己纪律和仓位都要严格控制。可是，一次致命的贪婪，就让你前面所有的努力付之东流。</p>
<p>没有领略人生极致的苦，你没有能力去控制你深处的欲念。</p>
<p>接下来的时光，会是你一生中最痛苦的回忆。失眠、抑郁、甚至想过要自杀。万念俱灰，对一切都提不起兴趣，后悔进入股票市场，后悔接触金融。大批量资金的压力，是你作为一个小散户此前从未经历过的。哪怕你无数次推演过同样的资金管理模式。</p>
<p>你倒下了。闪崩，是无数资深交易者都无法逃脱的宿命。</p>
<p>这个时候，你会无比怀念当年初遇股票时候的美好。你面临两个最重大的抉择，是继续坚持，还是退出市场。</p>
<p>很多人选择再坚持一年半载后，迫于各种压力，不可能突破自身固有的弱点，慢慢放手，退出外市股票，隐退江湖。</p>
<p>最终，只有极少数人始终继续坚持。这里面，少数幸运者等到了彻底开悟的那一天。</p>
<p>彻底开悟了，也就再次焕发交易青春。</p>
<h2 id="第四阶段：大道至简，彻底的开悟，无外乎轻仓、顺势、多睡觉。"><a href="#第四阶段：大道至简，彻底的开悟，无外乎轻仓、顺势、多睡觉。" class="headerlink" title="第四阶段：大道至简，彻底的开悟，无外乎轻仓、顺势、多睡觉。"></a>第四阶段：大道至简，彻底的开悟，无外乎轻仓、顺势、多睡觉。</h2><p>人生三重境界，看山是山，看山不是山，看山还是山。做完十年交易，历经无数市场磨难，最终你开始重回轻松赚钱的轨道，无外乎这么几点：轻仓，顺势，学会休息。山还是那年你刚入股票市场的山，人却是顿悟后的人，方法还是那些最淳朴的方法。</p>
<p>你不把股票交易太当回事，这就对了。你的欲望已经在无欲中提升到一个新的高度，精神的升华推动了你的自律，灵魂的洗礼涤荡了你的欲望。</p>
<p>成功的交易，我是领悟了，顺势交易乃第一要素，做好资金管理乃核心。最后，轻易不要出手，耐心等待真正的高胜率机会出现。减少交易机会，增加成功概率！</p>
<p>从上面这些人的结局中，我们自然容易悟出几个道理：</p>
<h2 id="第一，不能逆势操作，在火火的牛市中，或者在熊熊的熊市中，凭借着自认为的见顶或见底，那是寻死的，就像某年铁矿石、橡胶、螺纹等跌跌不休的品种，逆势就是寻死。必须等到弓箭之末，等到势消耗殆尽，出现转势，方可做。"><a href="#第一，不能逆势操作，在火火的牛市中，或者在熊熊的熊市中，凭借着自认为的见顶或见底，那是寻死的，就像某年铁矿石、橡胶、螺纹等跌跌不休的品种，逆势就是寻死。必须等到弓箭之末，等到势消耗殆尽，出现转势，方可做。" class="headerlink" title="第一，不能逆势操作，在火火的牛市中，或者在熊熊的熊市中，凭借着自认为的见顶或见底，那是寻死的，就像某年铁矿石、橡胶、螺纹等跌跌不休的品种，逆势就是寻死。必须等到弓箭之末，等到势消耗殆尽，出现转势，方可做。"></a>第一，不能逆势操作，在火火的牛市中，或者在熊熊的熊市中，凭借着自认为的见顶或见底，那是寻死的，就像某年铁矿石、橡胶、螺纹等跌跌不休的品种，逆势就是寻死。必须等到弓箭之末，等到势消耗殆尽，出现转势，方可做。</h2><h2 id="第二，不止损，逆势不可怕，可怕的是逆势不止损，在牛市或熊市中抄底摸高，死不认错，或者亏红了眼，干脆做起了鸵鸟，则就是等死。"><a href="#第二，不止损，逆势不可怕，可怕的是逆势不止损，在牛市或熊市中抄底摸高，死不认错，或者亏红了眼，干脆做起了鸵鸟，则就是等死。" class="headerlink" title="第二，不止损，逆势不可怕，可怕的是逆势不止损，在牛市或熊市中抄底摸高，死不认错，或者亏红了眼，干脆做起了鸵鸟，则就是等死。"></a>第二，不止损，逆势不可怕，可怕的是逆势不止损，在牛市或熊市中抄底摸高，死不认错，或者亏红了眼，干脆做起了鸵鸟，则就是等死。</h2><h2 id="第三，重仓。对于期货而言，由于杠杆效用，时机很重要，重仓的话，上下个10-，就基本上爆仓了，而上下10-是太正常不过了，所以等到市场按照你的预期行走的时候，你已经死掉了。所以对于选择时机能力不行的人而言，轻仓反而是一条路。"><a href="#第三，重仓。对于期货而言，由于杠杆效用，时机很重要，重仓的话，上下个10-，就基本上爆仓了，而上下10-是太正常不过了，所以等到市场按照你的预期行走的时候，你已经死掉了。所以对于选择时机能力不行的人而言，轻仓反而是一条路。" class="headerlink" title="第三，重仓。对于期货而言，由于杠杆效用，时机很重要，重仓的话，上下个10%，就基本上爆仓了，而上下10%是太正常不过了，所以等到市场按照你的预期行走的时候，你已经死掉了。所以对于选择时机能力不行的人而言，轻仓反而是一条路。"></a>第三，重仓。对于期货而言，由于杠杆效用，时机很重要，重仓的话，上下个10%，就基本上爆仓了，而上下10%是太正常不过了，所以等到市场按照你的预期行走的时候，你已经死掉了。所以对于选择时机能力不行的人而言，轻仓反而是一条路。</h2><h2 id="第四，我认为的，其实最重要的是谦虚，有敬畏之心，敬畏市场，保持低调、谦卑的心态，不可过于张扬。上面的这些人之所以死亡，无一不是高大、自负，赚了大钱，沾沾自喜，自以为已手握天下，顺我者昌、逆我者亡，结局就是他们自己亡。"><a href="#第四，我认为的，其实最重要的是谦虚，有敬畏之心，敬畏市场，保持低调、谦卑的心态，不可过于张扬。上面的这些人之所以死亡，无一不是高大、自负，赚了大钱，沾沾自喜，自以为已手握天下，顺我者昌、逆我者亡，结局就是他们自己亡。" class="headerlink" title="第四，我认为的，其实最重要的是谦虚，有敬畏之心，敬畏市场，保持低调、谦卑的心态，不可过于张扬。上面的这些人之所以死亡，无一不是高大、自负，赚了大钱，沾沾自喜，自以为已手握天下，顺我者昌、逆我者亡，结局就是他们自己亡。"></a>第四，我认为的，其实最重要的是谦虚，有敬畏之心，敬畏市场，保持低调、谦卑的心态，不可过于张扬。上面的这些人之所以死亡，无一不是高大、自负，赚了大钱，沾沾自喜，自以为已手握天下，顺我者昌、逆我者亡，结局就是他们自己亡。</h2><p>最后我要说：之所以能在期货中生存了十多年，当然除了努力之外，还有，就是一直保持着一颗敬畏之心，时刻如履薄冰，战战兢兢，无论是打了大胜仗，赚了多大的钱，心理面一直保持着敬畏。</p>
<p>当你有了这颗心态之后，你就会发现，你所遇到的许多交易问题，比如重仓、频繁交易、不止损，还有不努力、赌博，等等，都会自然消失。</p>
<p>道理，就是这些道理。看起来每个人都知道，但是从结果就能看得出谁是”混子“。</p>
<p>仅处于知道的地步，还远远不够。</p>
]]></content>
  </entry>
  <entry>
    <title>在Hexo博客中插入图片的各种方式</title>
    <url>/2020/12/07/23964/</url>
    <content><![CDATA[<p>在文章中插入图片<br><a href="https://yanyinhong.github.io/2017/05/02/How-to-insert-image-in-hexo-post/">Hexo博客搭建之在文章中插入图片</a></p>
<h2 id="绝对路径本地引用"><a href="#绝对路径本地引用" class="headerlink" title="绝对路径本地引用"></a>绝对路径本地引用</h2><p>当Hexo项目中只用到少量图片时，可以将图片统一放在source/images文件夹中，通过markdown语法访问它们。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">![](/images/image.jpg)</span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line">&lt;!--more--&gt;</span><br><span class="line">图片既可以在首页内容中访问到，也可以在文章正文中访问到。</span><br><span class="line"><span class="comment">## 相对路径本地引用</span></span><br><span class="line">图片除了可以放在统一的images文件夹中，还可以放在文章自己的目录中。文章的目录可以通过站点配置文件_config.yml来生成。</span><br><span class="line">``` bash</span><br><span class="line">post_asset_folder: <span class="literal">true</span></span><br><span class="line">``` </span><br><span class="line">将_config.yml文件中的配置项post_asset_folder设为<span class="literal">true</span>后，执行命令$ hexo new post_name，在<span class="built_in">source</span>/_posts中会生成文章post_name.md和同名文件夹post_name。将图片资源放在post_name中，文章就可以使用相对路径引用图片资源了。</span><br><span class="line">``` bash</span><br><span class="line">![](image.jpg)</span><br><span class="line">``` </span><br><span class="line">[vi-vim-cheat-sheet.gif](vi-vim-cheat-sheet.gif)</span><br><span class="line"><span class="comment">## 标签插件语法引用</span></span><br><span class="line">这种相对路径的图片显示方法在博文详情页面显示没有问题，但是在首页预览页面图片将显示不出来。如果希望图片在文章和首页中同时显示，可以使用标签插件语法。</span><br><span class="line">``` bash</span><br><span class="line"><span class="comment"># 本地图片资源，不限制图片尺寸</span></span><br><span class="line">&#123;% asset_img image.jpg This is an image %&#125;</span><br><span class="line"><span class="comment"># 网络图片资源，限制图片显示尺寸</span></span><br><span class="line">&#123;% img http://www.viemu.com/vi-vim-cheat-sheet.gif 200 400 vi-vim-cheat-sheet %&#125;</span><br><span class="line">HTML语法引用</span><br><span class="line">&lt;img src=<span class="string">&quot;SpellCheck.png&quot;</span> width=<span class="string">&quot;50%&quot;</span> height=<span class="string">&quot;50%&quot;</span> title=<span class="string">&quot;拼写检查工具Grammarly.&quot;</span> alt=<span class="string">&quot;拼写检查工具Grammarly.&quot;</span>/&gt;</span><br></pre></td></tr></table></figure>
<p>直接将<img src="/.com//image.jpg">替换上面的语法即可。</p>
<p>启用fancybox：点击查看图片大图<br>我这里使用的是Hexo的NexT主题，NexT主题中提供了fancybox的方便接口。</p>
<p>Usage：<a href="https://github.com/theme-next/theme-next-fancybox3">https://github.com/theme-next/theme-next-fancybox3</a><br>markdown用法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% img http://www.viemu.com/vi-vim-cheat-sheet.gif 600 600 <span class="string">&quot;点击查看大图:vi/vim-cheat-sheet&quot;</span> %&#125;</span><br></pre></td></tr></table></figure>
<p>Hexo部分图片禁用fancybox</p>
<p>hexo在使用fancybox插件时，图片的效果还是很可观的，但是我们往往是不需要所有的图片都用fancybox；<br>例如：hexo next主题下，添加某些图片的时候，有些事不需要可点击的<br>修改theme\next\source\js\src\utils.js 红色字体部分；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">diff --git a/<span class="built_in">source</span>/js/src/utils.js b/<span class="built_in">source</span>/js/src/utils.js</span><br><span class="line">index 0f3704e..8516665 100644</span><br><span class="line">--- a/<span class="built_in">source</span>/js/src/utils.js</span><br><span class="line">+++ b/<span class="built_in">source</span>/js/src/utils.js</span><br><span class="line">@@ -11,6 +11,7 @@ NexT.utils = NexT.<span class="variable">$u</span> = &#123;</span><br><span class="line">       .not(<span class="string">&#x27;.group-picture img, .post-gallery img&#x27;</span>)</span><br><span class="line">       .each(<span class="function"><span class="title">function</span></span>() &#123;</span><br><span class="line">         var <span class="variable">$image</span> = $(this);</span><br><span class="line">+        <span class="keyword">if</span> ($(this).hasClass(<span class="string">&#x27;nofancybox&#x27;</span>)) <span class="built_in">return</span>;</span><br><span class="line">         var imageTitle = <span class="variable">$image</span>.attr(<span class="string">&#x27;title&#x27;</span>);</span><br><span class="line">         var <span class="variable">$imageWrapLink</span> = <span class="variable">$image</span>.parent(<span class="string">&#x27;a&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>在img标签使用的时候加上class=”nofancybox”即可。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;img src=<span class="string">&quot;http://www.viemu.com/vi-vim-cheat-sheet.gif&quot;</span> class=<span class="string">&quot;nofancybox&quot;</span> /&gt;</span><br></pre></td></tr></table></figure>
<img src="http://www.viemu.com/vi-vim-cheat-sheet.gif" class width="600" height="600" title="点击查看大图:vi&#x2F;vim-cheat-sheet">]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>多机版———docker-compose搭建MongoDB 3.4 分片集群详细步骤</title>
    <url>/2020/07/30/35105/</url>
    <content><![CDATA[<h2 id="服务器三台-按顺序执行"><a href="#服务器三台-按顺序执行" class="headerlink" title="服务器三台  按顺序执行"></a>服务器三台  按顺序执行</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.125</span></span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.126</span></span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.127</span></span><br></pre></td></tr></table></figure>
<h2 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h2><p>在每台机器上操作此步骤</p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cd /home/seeyii</span><br><span class="line">mkdir mongoCluster</span><br><span class="line">cd mongoCluster</span><br></pre></td></tr></table></figure>
<h3 id="vi-mongod-conf"><a href="#vi-mongod-conf" class="headerlink" title="vi mongod.conf"></a>vi mongod.conf</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">storage:</span><br><span class="line">  dbPath: /data/db</span><br><span class="line">  journal:</span><br><span class="line">    enabled: true</span><br><span class="line">systemLog:</span><br><span class="line">  destination: file</span><br><span class="line">  logAppend: true</span><br><span class="line">  path: /var/log/mongodb/mongod.log</span><br><span class="line"></span><br><span class="line">net:</span><br><span class="line">  maxIncomingConnections: <span class="number">10000</span></span><br><span class="line">replication:</span><br><span class="line">  oplogSizeMB: <span class="number">10240</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># security:</span></span><br><span class="line">  <span class="comment"># keyFile: /data/mongodb/key.file</span></span><br><span class="line">  <span class="comment"># authorization: enabled</span></span><br></pre></td></tr></table></figure>
<h3 id="vi-mongos-conf"><a href="#vi-mongos-conf" class="headerlink" title="vi mongos.conf"></a>vi mongos.conf</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">storage:</span><br><span class="line">  dbPath: /data/db</span><br><span class="line">  journal:</span><br><span class="line">    enabled: true</span><br><span class="line">systemLog:</span><br><span class="line">  destination: file</span><br><span class="line">  logAppend: true</span><br><span class="line">  path: /var/log/mongodb/mongos.log</span><br><span class="line"></span><br><span class="line">net:</span><br><span class="line">  maxIncomingConnections: <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># security:</span></span><br><span class="line">  <span class="comment"># keyFile: /data/mongodb/key.file</span></span><br></pre></td></tr></table></figure>
<h2 id="创建目录-1"><a href="#创建目录-1" class="headerlink" title="创建目录"></a>创建目录</h2><h3 id="vi-first-mkdir-sh"><a href="#vi-first-mkdir-sh" class="headerlink" title="vi first_mkdir.sh"></a>vi first_mkdir.sh</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mkdir -p /database/vol/conf/config</span><br><span class="line">mkdir -p /database/vol/conf/db</span><br><span class="line">mkdir -p /database/vol/shard1/config</span><br><span class="line">mkdir -p /database/vol/shard1/db</span><br><span class="line">mkdir -p /database/vol/shard1/backup</span><br><span class="line">mkdir -p /database/vol/shard2/config</span><br><span class="line">mkdir -p /database/vol/shard2/db</span><br><span class="line">mkdir -p /database/vol/shard2/backup</span><br><span class="line">mkdir -p /database/vol/mongos/config</span><br><span class="line">mkdir -p /database/vol/mongos/db</span><br></pre></td></tr></table></figure>
<h3 id="生成认证文件-root-用户-三台共用一个"><a href="#生成认证文件-root-用户-三台共用一个" class="headerlink" title="生成认证文件 root 用户 三台共用一个"></a>生成认证文件 root 用户 三台共用一个</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">openssl rand -base64 <span class="number">741</span> &gt; key.file</span><br><span class="line">chmod <span class="number">600</span> key.file</span><br><span class="line">chown <span class="number">999</span> key.file</span><br><span class="line">mv key.file /database/vol</span><br></pre></td></tr></table></figure>


<h3 id="将配置文件放到指定位置"><a href="#将配置文件放到指定位置" class="headerlink" title="将配置文件放到指定位置"></a>将配置文件放到指定位置</h3><p>vi second_mv.sh</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> /database/vol/</span><br><span class="line"> do</span><br><span class="line">   <span class="keyword">for</span> item2 <span class="keyword">in</span> `ls $item`</span><br><span class="line">    do</span><br><span class="line">     <span class="keyword">if</span> [ $item2 = <span class="string">&#x27;mongos&#x27;</span> ]</span><br><span class="line">     then</span><br><span class="line">        echo $item2</span><br><span class="line">        cp mongos.conf $item$item2/config/mongos.conf</span><br><span class="line">     <span class="keyword">else</span></span><br><span class="line">        echo <span class="string">&quot;no&quot;</span></span><br><span class="line">        cp mongod.conf $item$item2/config/mongod.conf</span><br><span class="line">    fi</span><br><span class="line">    done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h2 id="docker-compose-yaml-容器编排"><a href="#docker-compose-yaml-容器编排" class="headerlink" title="docker-compose.yaml 容器编排"></a>docker-compose.yaml 容器编排</h2><p>将文件放在 mongoCluster目录中</p>
<h2 id="docker-compose-文件"><a href="#docker-compose-文件" class="headerlink" title="docker-compose 文件"></a>docker-compose 文件</h2><p>docker-compose.yaml</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">version: <span class="string">&#x27;2&#x27;</span></span><br><span class="line">services:</span><br><span class="line">  rs_config_server:</span><br><span class="line">    image: mongo:<span class="number">3.4</span>  <span class="comment">#  可以不用设置版本,注意参考方案二</span></span><br><span class="line">    command: mongod -f /etc/mongod/mongod.conf --configsvr --replSet <span class="string">&quot;rs-config-server&quot;</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /database/vol/key.file:/data/mongodb/key.file</span><br><span class="line">      - /database/vol/conf/config:/etc/mongod</span><br><span class="line">      - /database/vol/conf/db:/data/db</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;10021:27019&quot;</span></span><br><span class="line">    restart:</span><br><span class="line">      always</span><br><span class="line">    container_name:</span><br><span class="line">      rs_config_server</span><br><span class="line">    ulimits:</span><br><span class="line">      nofile:</span><br><span class="line">        soft: <span class="number">300000</span></span><br><span class="line">        hard: <span class="number">300000</span></span><br><span class="line"></span><br><span class="line">  rs_shard_server1:</span><br><span class="line">    image: mongo:<span class="number">3.4</span></span><br><span class="line">    command: mongod -f /etc/mongod/mongod.conf --directoryperdb --shardsvr --replSet <span class="string">&quot;rs-shard1-server&quot;</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /database/vol/key.file:/data/mongodb/key.file</span><br><span class="line">      - /database/vol/shard1/config:/etc/mongod</span><br><span class="line">      - /database/vol/shard1/db:/data/db</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;10031:27018&quot;</span></span><br><span class="line">    restart:</span><br><span class="line">      always</span><br><span class="line">    container_name:</span><br><span class="line">      rs_shard_server1</span><br><span class="line">    ulimits:</span><br><span class="line">      nofile:</span><br><span class="line">        soft: <span class="number">300000</span></span><br><span class="line">        hard: <span class="number">300000</span></span><br><span class="line"></span><br><span class="line">  rs_shard_server2:</span><br><span class="line">    image: mongo:<span class="number">3.4</span></span><br><span class="line">    command: mongod -f /etc/mongod/mongod.conf --directoryperdb --shardsvr --replSet <span class="string">&quot;rs-shard2-server&quot;</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /database/vol/key.file:/data/mongodb/key.file</span><br><span class="line">      - /database/vol/shard2/config:/etc/mongod</span><br><span class="line">      - /database/vol/shard2/db:/data/db</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;10041:27018&quot;</span></span><br><span class="line">    restart:</span><br><span class="line">      always</span><br><span class="line">    container_name:</span><br><span class="line">      rs_shard_server2</span><br><span class="line">    ulimits:</span><br><span class="line">      nofile:</span><br><span class="line">        soft: <span class="number">300000</span></span><br><span class="line">        hard: <span class="number">300000</span></span><br><span class="line"></span><br><span class="line">  rs_mongos_server:</span><br><span class="line">    image: mongo:<span class="number">3.4</span></span><br><span class="line">    command:   --configdb rs-config-server/<span class="number">192.168</span><span class="number">.1</span><span class="number">.125</span>:<span class="number">10021</span>,<span class="number">192.168</span><span class="number">.1</span><span class="number">.126</span>:<span class="number">10021</span>,<span class="number">192.168</span><span class="number">.1</span><span class="number">.127</span>:<span class="number">10021</span>  --bind_ip_all</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;10011:27017&quot;</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /database/vol/key.file:/data/mongodb/key.file</span><br><span class="line">      - /database/vol/mongos/config:/etc/mongod</span><br><span class="line">      - /database/vol/mongos/db:/data/db</span><br><span class="line">    entrypoint: mongos</span><br><span class="line">    restart:</span><br><span class="line">      always</span><br><span class="line">    container_name:</span><br><span class="line">      rs_mongos_server</span><br><span class="line">    ulimits:</span><br><span class="line">      nofile:</span><br><span class="line">        soft: <span class="number">300000</span></span><br><span class="line">        hard: <span class="number">300000</span></span><br></pre></td></tr></table></figure>
<h3 id="启动-docker-compose-up-d"><a href="#启动-docker-compose-up-d" class="headerlink" title="启动 docker-compose up -d"></a>启动 docker-compose up -d</h3><h1 id="添加副本集"><a href="#添加副本集" class="headerlink" title="添加副本集"></a>添加副本集</h1><h2 id="配置服务器"><a href="#配置服务器" class="headerlink" title="配置服务器"></a>配置服务器</h2><p>连接任意一个节点 mongo –host 192.168.1.125 –port 10021</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rs.initiate(&#123;</span><br><span class="line">		    _id: <span class="string">&quot;rs-config-server&quot;</span>,</span><br><span class="line">		    configsvr: true,</span><br><span class="line">		    members: [</span><br><span class="line">		    	&#123; _id : <span class="number">0</span>, host : <span class="string">&quot;192.168.1.125:10021&quot;</span> &#125;,</span><br><span class="line">		        &#123; _id : <span class="number">1</span>, host : <span class="string">&quot;192.168.1.126:10021&quot;</span> &#125;,</span><br><span class="line">		        &#123; _id : <span class="number">2</span>, host : <span class="string">&quot;192.168.1.127:10021&quot;</span> &#125;,</span><br><span class="line">		    ]</span><br><span class="line">		&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="分片1"><a href="#分片1" class="headerlink" title="分片1"></a>分片1</h2><p>连接任意一个节点 mongo –host 192.168.1.125 –port 10031</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rs.initiate(&#123;</span><br><span class="line">		    _id: <span class="string">&quot;rs-shard1-server&quot;</span>,</span><br><span class="line">		    members: [</span><br><span class="line">		    	&#123; _id : <span class="number">0</span>, host : <span class="string">&quot;192.168.1.125:10031&quot;</span> &#125;,</span><br><span class="line">		        &#123; _id : <span class="number">1</span>, host : <span class="string">&quot;192.168.1.126:10031&quot;</span> &#125;,</span><br><span class="line">		        &#123; _id : <span class="number">2</span>, host : <span class="string">&quot;192.168.1.127:10031&quot;</span> &#125;,</span><br><span class="line">		    ]</span><br><span class="line">		&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="分片2"><a href="#分片2" class="headerlink" title="分片2"></a>分片2</h2><p>连接任意一个节点 mongo –host 192.168.1.125 –port 10041</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rs.initiate(&#123;</span><br><span class="line">		    _id: <span class="string">&quot;rs-shard2-server&quot;</span>,</span><br><span class="line">		    members: [</span><br><span class="line">		    	&#123; _id : <span class="number">0</span>, host : <span class="string">&quot;192.168.1.125:10041&quot;</span> &#125;,</span><br><span class="line">		        &#123; _id : <span class="number">1</span>, host : <span class="string">&quot;192.168.1.126:10041&quot;</span> &#125;,</span><br><span class="line">		        &#123; _id : <span class="number">2</span>, host : <span class="string">&quot;192.168.1.127:10041&quot;</span> &#125;,</span><br><span class="line">		    ]</span><br><span class="line">		&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="配置mongos"><a href="#配置mongos" class="headerlink" title="配置mongos"></a>配置mongos</h2><p>确保mongos服务起来之后，连接到192.168.1.125:10011执行以下命令添加分片服务器信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sh.addShard(<span class="string">&quot;rs-shard1-server/192.168.1.125:10031,192.168.1.126:10031,192.168.1.127:10031&quot;</span>)</span><br><span class="line">sh.addShard(<span class="string">&quot;rs-shard2-server/192.168.1.125:10041,192.168.1.126:10041,192.168.1.127:10041&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="添加用户认证"><a href="#添加用户认证" class="headerlink" title="添加用户认证"></a>添加用户认证</h2><p>连接任意的mongos</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">use admin</span><br><span class="line"></span><br><span class="line">db.createUser(</span><br><span class="line">		    &#123;</span><br><span class="line">		        user:<span class="string">&quot;root&quot;</span>,</span><br><span class="line">		        pwd:<span class="string">&quot;shiye1805A&quot;</span>,</span><br><span class="line">		        roles:[&#123;role:<span class="string">&quot;root&quot;</span>,db:<span class="string">&quot;admin&quot;</span>&#125;]</span><br><span class="line">		    &#125;</span><br><span class="line">		)</span><br></pre></td></tr></table></figure>
<h2 id="验证是否创建成功"><a href="#验证是否创建成功" class="headerlink" title="验证是否创建成功"></a>验证是否创建成功</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">db.auth(<span class="string">&#x27;root&#x27;</span>,<span class="string">&#x27;shiye1805A&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>返回值 1 成功</p>
<p>将配置文件的用户认证全部打开 security:</p>
<p>重启容器 注意： 保证key.file 权限为 999</p>
<h2 id="容器-操作"><a href="#容器-操作" class="headerlink" title="容器 操作"></a>容器 操作</h2><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>docker rm -f rs_mongos_server rs_config_server rs_shard_server1 rs_shard_server2</p>
<h3 id="停止"><a href="#停止" class="headerlink" title="停止"></a>停止</h3><p>docker stop rs_mongos_server rs_config_server rs_shard_server1 rs_shard_server2</p>
<h3 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h3><p>docker restart rs_mongos_server rs_config_server rs_shard_server1 rs_shard_server2</p>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>docker start rs_mongos_server rs_config_server rs_shard_server1 rs_shard_server2</p>
<p><a href="https://blog.csdn.net/weixin_43886133/article/details/95332931">link</a><br><a href="https://blog.csdn.net/yufei_java/article/details/103704582">docker-compose搭建mongodb分片集群及安全身份认证（实战）</a></p>
<p> 最近由于项目中设计中有使用mongodb，具体mongodb的优点我就不多说。这篇文章主要是分享下我通过docker-compose搭建mongodb分片集群，并实现安全身份认证访问(mongodb安装后默认是不需要用户名和密码访问的)。</p>
<h2 id="下面是我配置的docker-compose-yml文件："><a href="#下面是我配置的docker-compose-yml文件：" class="headerlink" title="下面是我配置的docker-compose.yml文件："></a>下面是我配置的docker-compose.yml文件：</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">version: <span class="string">&#x27;2&#x27;</span></span><br><span class="line">services:</span><br><span class="line">  shard_server01:</span><br><span class="line">    container_name: shard_server01</span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.11</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27018</span>:<span class="number">27018</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/shard_server01/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/shard_server01/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/shard_server01/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    command: --shardsvr --bind_ip_all</span><br><span class="line">    restart: always</span><br><span class="line">    depends_on:</span><br><span class="line">      - rs_config_server01</span><br><span class="line">      - rs_config_server02</span><br><span class="line">    ulimits:</span><br><span class="line">      nofile:</span><br><span class="line">        soft: <span class="number">300000</span></span><br><span class="line">        hard: <span class="number">300000</span></span><br><span class="line">  shard_server02:</span><br><span class="line">    container_name: shard_server02</span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.12</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27028</span>:<span class="number">27018</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/shard_server02/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/shard_server02/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/shard_server02/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    command: --shardsvr --keyFile <span class="string">&quot;/etc/key.file&quot;</span> --bind_ip_all --auth</span><br><span class="line">    restart: always</span><br><span class="line">    depends_on:</span><br><span class="line">      - rs_config_server01</span><br><span class="line">      - rs_config_server02</span><br><span class="line"><span class="comment"># 配置服务器集群两个节点（mongodb3.4之后的版本需要两个config_server）</span></span><br><span class="line">  rs_config_server01:</span><br><span class="line">    container_name: rs_config_server01</span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.13</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27019</span>:<span class="number">27019</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server01/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server01/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server01/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    command: --configsvr --replSet <span class="string">&quot;rs_config_server&quot;</span> --bind_ip_all</span><br><span class="line">    restart: always</span><br><span class="line"> </span><br><span class="line">  rs_config_server02:</span><br><span class="line">    container_name: rs_config_server02</span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.14</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27029</span>:<span class="number">27019</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server02/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server02/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server02/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    command: --configsvr --replSet <span class="string">&quot;rs_config_server&quot;</span> --bind_ip_all</span><br><span class="line">    restart: always</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 路由节点mongos</span></span><br><span class="line">  mongos:</span><br><span class="line">    container_name: mongos</span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.15</span></span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27017</span>:<span class="number">27017</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    entrypoint: mongos</span><br><span class="line">    command: --configdb rs_config_server/<span class="number">192.168</span><span class="number">.1</span><span class="number">.13</span>:<span class="number">27019</span>,<span class="number">192.168</span><span class="number">.1</span><span class="number">.14</span>:<span class="number">27019</span> --bind_ip_all</span><br><span class="line">    depends_on:</span><br><span class="line">      - shard_server01</span><br><span class="line">      - shard_server02</span><br><span class="line"> </span><br><span class="line">networks:</span><br><span class="line">    mongo:</span><br><span class="line">        driver: bridge</span><br><span class="line">        ipam:</span><br><span class="line">            config:</span><br><span class="line">                - subnet: <span class="number">192.168</span><span class="number">.1</span><span class="number">.10</span>/<span class="number">24</span></span><br></pre></td></tr></table></figure>
<h3 id="注意：目前是没有增加安全身份认证的。"><a href="#注意：目前是没有增加安全身份认证的。" class="headerlink" title="注意：目前是没有增加安全身份认证的。"></a>注意：目前是没有增加安全身份认证的。</h3><h2 id="使用docker-compose启动mongo集群"><a href="#使用docker-compose启动mongo集群" class="headerlink" title="使用docker-compose启动mongo集群"></a>使用docker-compose启动mongo集群</h2><p>docker-compose up -d</p>
<h3 id="配置服务器设置（config-server）"><a href="#配置服务器设置（config-server）" class="headerlink" title="配置服务器设置（config_server）"></a>配置服务器设置（config_server）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it rs_config_server01 /<span class="built_in">bin</span>/bash</span><br><span class="line">mongo --host localhost --port <span class="number">27019</span></span><br><span class="line">rs.initiate(&#123;</span><br><span class="line">    _id: <span class="string">&quot;rs_config_server&quot;</span>,</span><br><span class="line">    configsvr: true,</span><br><span class="line">    members: [</span><br><span class="line">        &#123; _id : <span class="number">0</span>, host : <span class="string">&quot;192.168.1.13:27019&quot;</span> &#125;,</span><br><span class="line">        &#123; _id : <span class="number">1</span>, host : <span class="string">&quot;192.168.1.14:27019&quot;</span> &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>配置路由mongos服务</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it mongos /<span class="built_in">bin</span>/bash</span><br><span class="line">mongo --port <span class="number">27017</span></span><br></pre></td></tr></table></figure>
<p>将分片集群添加到mongos中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sh.addShard(<span class="string">&quot;192.168.1.11:27018&quot;</span>)</span><br><span class="line">sh.addShard(<span class="string">&quot;192.168.1.12:27018&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>到目前为止，mongodb分片集群已经搭建完毕。但是mongdb默认是无需账户即可直接访问。故，若是需要增加账号和密码，并强制需要输入正确的账户和密码才能登陆的话，看下文。</p>
<h2 id="1、创建mongdb的账户和密码"><a href="#1、创建mongdb的账户和密码" class="headerlink" title="1、创建mongdb的账户和密码"></a>1、创建mongdb的账户和密码</h2><p>进入mongos路由服务</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it mongos /<span class="built_in">bin</span>/bash</span><br><span class="line">mongo --port <span class="number">27017</span></span><br></pre></td></tr></table></figure>
<p> 切换到admin库，创建用户root</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">use admin</span><br><span class="line"> </span><br><span class="line">db.createUser(</span><br><span class="line">		    &#123;</span><br><span class="line">		        user:<span class="string">&quot;root&quot;</span>,</span><br><span class="line">		        pwd:<span class="string">&quot;123456&quot;</span>,</span><br><span class="line">		        roles:[&#123;role:<span class="string">&quot;root&quot;</span>,db:<span class="string">&quot;admin&quot;</span>&#125;]</span><br><span class="line">		    &#125;</span><br><span class="line">		)</span><br></pre></td></tr></table></figure>
<h2 id="2、生成mongo节点之前通讯认证文件（key-file）"><a href="#2、生成mongo节点之前通讯认证文件（key-file）" class="headerlink" title="2、生成mongo节点之前通讯认证文件（key.file）"></a>2、生成mongo节点之前通讯认证文件（key.file）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">openssl rand -base64 <span class="number">741</span> &gt; key.file</span><br><span class="line">chmod <span class="number">600</span> key.file</span><br><span class="line">chown <span class="number">999</span> key.file </span><br></pre></td></tr></table></figure>
<h2 id="3、将key-file挂载docker容器里面，启动命令指定key-file，并增加需要认证-–auth"><a href="#3、将key-file挂载docker容器里面，启动命令指定key-file，并增加需要认证-–auth" class="headerlink" title="3、将key.file挂载docker容器里面，启动命令指定key.file，并增加需要认证(–auth)"></a>3、将key.file挂载docker容器里面，启动命令指定key.file，并增加需要认证(–auth)</h2><p>  增加安全认证之后的docker-compose .yml文件如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">version: <span class="string">&#x27;2&#x27;</span></span><br><span class="line">services:</span><br><span class="line">  shard_server01:</span><br><span class="line">    container_name: shard_server01</span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.11</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27018</span>:<span class="number">27018</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/shard_server01/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/shard_server01/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/shard_server01/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    command: --shardsvr --keyFile <span class="string">&quot;/etc/key.file&quot;</span> --bind_ip_all --auth</span><br><span class="line">    restart: always</span><br><span class="line">    depends_on:</span><br><span class="line">      - rs_config_server01</span><br><span class="line">      - rs_config_server02</span><br><span class="line">    ulimits:</span><br><span class="line">      nofile:</span><br><span class="line">        soft: <span class="number">300000</span></span><br><span class="line">        hard: <span class="number">300000</span></span><br><span class="line">  shard_server02:</span><br><span class="line">    container_name: shard_server02</span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.12</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27028</span>:<span class="number">27018</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/shard_server02/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/shard_server02/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/shard_server02/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    command: --shardsvr --keyFile <span class="string">&quot;/etc/key.file&quot;</span> --bind_ip_all --auth</span><br><span class="line">    restart: always</span><br><span class="line">    depends_on:</span><br><span class="line">      - rs_config_server01</span><br><span class="line">      - rs_config_server02</span><br><span class="line"><span class="comment"># 配置服务器集群两个节点（mongodb3.4之后的版本需要两个config_server）</span></span><br><span class="line">  rs_config_server01:</span><br><span class="line">    container_name: rs_config_server01</span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.13</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27019</span>:<span class="number">27019</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server01/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server01/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server01/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    command: --configsvr --keyFile <span class="string">&quot;/etc/key.file&quot;</span> --replSet <span class="string">&quot;rs_config_server&quot;</span> --bind_ip_all --auth</span><br><span class="line">    restart: always</span><br><span class="line"> </span><br><span class="line">  rs_config_server02:</span><br><span class="line">    container_name: rs_config_server02</span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.14</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27029</span>:<span class="number">27019</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server02/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server02/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/rs_config_server02/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    command: --configsvr --keyFile <span class="string">&quot;/etc/key.file&quot;</span> --replSet <span class="string">&quot;rs_config_server&quot;</span> --bind_ip_all --auth</span><br><span class="line">    restart: always</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 路由节点mongos</span></span><br><span class="line">  mongos:</span><br><span class="line">    container_name: mongos</span><br><span class="line">    networks:</span><br><span class="line">      mongo:</span><br><span class="line">        ipv4_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.15</span></span><br><span class="line">    image: mongo:<span class="number">3.6</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="number">27017</span>:<span class="number">27017</span></span><br><span class="line">    volumes:</span><br><span class="line">      - /data/docker/mongos/data/data/db:/data/db</span><br><span class="line">      - /data/docker/mongos/data/data/configdb:/data/configdb</span><br><span class="line">      - /data/docker/mongos/data/data/backup:/data/backup</span><br><span class="line">      - /data/docker/mongos/data/mongod.conf:/etc/mongod.conf</span><br><span class="line">      - /data/docker/mongos/data/key.file:/etc/key.file</span><br><span class="line">    entrypoint: mongos</span><br><span class="line">    command: --configdb rs_config_server/<span class="number">192.168</span><span class="number">.1</span><span class="number">.13</span>:<span class="number">27019</span>,<span class="number">192.168</span><span class="number">.1</span><span class="number">.14</span>:<span class="number">27019</span> --keyFile <span class="string">&quot;/etc/key.file&quot;</span> --bind_ip_all --auth</span><br><span class="line">    depends_on:</span><br><span class="line">      - shard_server01</span><br><span class="line">      - shard_server02</span><br><span class="line"> </span><br><span class="line">networks:</span><br><span class="line">    mongo:</span><br><span class="line">        driver: bridge</span><br><span class="line">        ipam:</span><br><span class="line">            config:</span><br><span class="line">                - subnet: <span class="number">192.168</span><span class="number">.1</span><span class="number">.10</span>/<span class="number">24</span></span><br></pre></td></tr></table></figure>
<h2 id="4、重启docker-compose"><a href="#4、重启docker-compose" class="headerlink" title="4、重启docker-compose"></a>4、重启docker-compose</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker-compose down</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>
<p>到此，增加安全登录已经配置完毕。若不使用账号和密码访问结果如下：</p>
]]></content>
      <categories>
        <category>mongo</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>如何破解并访问Hexo Blog已加密的文章</title>
    <url>/2020/07/29/61636/</url>
    <content><![CDATA[<h1 id="How-to-crack-hexo-simple-encrypted-blog？"><a href="#How-to-crack-hexo-simple-encrypted-blog？" class="headerlink" title="How to crack hexo simple encrypted blog？"></a>How to crack hexo simple encrypted blog？</h1><h2 id="事发"><a href="#事发" class="headerlink" title="事发"></a>事发</h2><p>下午一起加班的小伙伴在折腾blog，然后问我的blog文章是怎么加密的，然后，就是惨案的开始（orz…）</p>
<p>我直接发了一个截图，并友情提示，这段代码大概不安全。然后成功激发小伙伴的兴趣，开始尝试越过密码。大概1-2分钟后，blog加密文章形同虚设。</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>我的blog现在是用额hexo的the next主题加各种自定义特效，因为搭建时间其实很早，所以当时使用了一种简单的js逻辑来加密blog。下面我们来看下这段有安全问题的代码：<br>代码位置： yourblog/themes/next/layout/custom/head.swig</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">    (function()&#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="string">&#x27;&#123;&#123; page.password &#125;&#125;&#x27;</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span> (prompt(<span class="string">&#x27;请输入密码&#x27;</span>) !== <span class="string">&#x27;&#123;&#123; page.password &#125;&#125;&#x27;</span>)&#123;</span><br><span class="line">                alert(<span class="string">&#x27;密码错误&#x27;</span>);</span><br><span class="line">                history.back();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)();</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>
<p>乍看是否觉得除了逻辑简单没什么问题，然而眼尖的小伙伴分析出了第一个隐患：history.back(); ，而我已知静态页面的安全隐患。接下来我们逐个分析。</p>
<h2 id="istory-back"><a href="#istory-back" class="headerlink" title="istory.back()"></a>istory.back()</h2><p>back() 方法可加载历史列表中的前一个 URL（如果存在）。如果你的前一个URL就是这个文章的URL，那么恭喜，第一种破解方法get。（不理解，看下一条）</p>
<h2 id="静态页面"><a href="#静态页面" class="headerlink" title="静态页面"></a>静态页面</h2><p>hexo g 会根据blog相关文件在public目录下生成blog的所有静态文件。既然是已经生成好的静态页面，实际上html中包含了那段js代码的。因为需要获得html了之后才会触发那个页面访问加密的js，而理论上当我们获取到html页面之后，就可以停止当前页的js操作了。<br>That is to say, 你的blog word就是直接写在页面中的，虽然直接url去访问会弹alert，但是用curl直接获取这个页面的html，可以直接搜索到文章的访问密码, 分分钟攻破此种博文加密方式。上面利用history.back()的访问破解方式，归根结底也是这个问题引起的。</p>
<p>另外补充一点：因为用hexo的blog的人大多喜欢直接部署到github上利用github.io来展示，这样就要求使用Github的公开仓库，所以代码基本没有保密性可言。坊间流传直接看md文件我持疑，因为hexo d只会把public目录里生成的静态文件上传到github的仓库，除非是直接上传了blog项目的所有代码到github的仓库中。</p>
<h2 id="修复"><a href="#修复" class="headerlink" title="修复"></a>修复</h2><p>其实修复问题很好解决，既然简单的js加密不够安全，那我们就换一个安全的加密方式。<br>不知道怎么写？不慌，早已有大佬开发了插件hexo-blog-encrypt</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">安装hexo-blog-encrypt(安装方式<span class="number">2</span>选<span class="number">1</span>)</span><br><span class="line"><span class="number">1.</span>npm维护安装包</span><br><span class="line"></span><br><span class="line">npm install --save hexo-blog-encrypt (需要安装 npm)</span><br><span class="line"><span class="number">2.</span>yarn维护</span><br><span class="line"></span><br><span class="line">yarn add hexo-blog-encrypt (需要安装 Yarn)</span><br><span class="line">站点设置修改</span><br><span class="line">在 站点配置文件 _config.yml 中启用该插件</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encrypt plugin</span></span><br><span class="line">encrypt:</span><br><span class="line">  enable: true</span><br><span class="line">  default_abstract: 这是一篇加密文章，内容可能是个人日常吐槽或者特殊技术分享。如果你确实想看，请与我联系。非亲友团勿扰。</span><br><span class="line">  default_message: 输入密码，查看文章。</span><br></pre></td></tr></table></figure>
<h2 id="使用hexo-blog-encrypt加密blog"><a href="#使用hexo-blog-encrypt加密blog" class="headerlink" title="使用hexo-blog-encrypt加密blog"></a>使用hexo-blog-encrypt加密blog</h2><h3 id="使用-hexo-new-“yourblog”-后在页面添加password字段即可"><a href="#使用-hexo-new-“yourblog”-后在页面添加password字段即可" class="headerlink" title="使用 hexo new  “yourblog”  后在页面添加password字段即可"></a>使用 hexo new  “yourblog”  后在页面添加password字段即可</h3><p>在你的博文头部添加上相应字段，如 password, abstract, message。因为 abstract, message 在站点配置中设置了默认值，如果这里不想自定义 abstract, message，不用专门设置。<br>password: 代表blog的访问密码<br>abstract: 这篇博文的摘要，会显示在博客的列表页<br>message: 当查看加密博文时，密码输入框上面的提示性文字。建议使用中文，英文提示默认字体不好看，可以看我下面的截图。</p>
<p>visit_password</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 测试新文章加密</span><br><span class="line">date: </span><br><span class="line">category: hexo</span><br><span class="line">keywords: 博客文章密码</span><br><span class="line">password: yourpassword</span><br><span class="line">abstract: hexo密码测试</span><br><span class="line">message:  输入密码，查看文章</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<h2 id="反省总结"><a href="#反省总结" class="headerlink" title="反省总结"></a>反省总结</h2><p>这个事件，其实属于网络安全中最常见的问题“人的安全意识”，比如这个blog加密方案有访问漏洞，我是知道的，但是拖延症导致我没有足够重视这个问题（因为自己总是想着加密过的东西其实被看到也无妨，毕竟正要保密也不会发出来了balabala），结果一直没去修复（即使实际修复这个问题只需要10分钟），直到被小伙伴测试到bug才动手修复。</p>
<p>延伸到实际生产环境的安全问题，0 day漏洞被利用姑且还能辩解说是吃了信息不对等的亏。但也不乏一些有年头的机构的网站依然存在N day漏洞可利用，即使修复方案网上10s可能就能找到（例如：简单的打个补丁或者改几个配置项），这就真的是维护人员安全意识的问题了。所以在网络安全中，人的安全意识尤为重要，对于安全从业者更是如此，绝对不能有一丝松懈。<br><a href="https://blog.fullstackpentest.com/how-to-crack-hexo-simple-encrypted-blog.html">link</a></p>
]]></content>
      <categories>
        <category>Hack</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Hack</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习量化多因子选股策略</title>
    <url>/2018/07/09/25110/</url>
    <content><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>多因子选股策略是一种应用十分广泛的选股策略，其基本思构想就是找到某些和收益率最相关的指标，找出股票收益率与各种指标之间的“关系”，借此“关系”建立股票组合，并期望该组合可以跑赢指数。</p>
<p>多因子回归是多因子选股策略最常用的方法，它用过去的股票的收益率对多因子进行回归，得到一个回归方程，然后把当下的因子数值代入回归方程得到未来股票的预期收益，最后以此为依据进行选股。</p>
<p>机器学习和多因子选股策略的结合，从实践的角度来看，机器学习所做的工作是在现有因子的数据集上建立模型，对股票收益率进行拟合，然后对模型进行评估和优化。</p>
<p>用机器学习做模型预测有一套基本流程：数据获取、数据预处理、模型训练、模型评估和模型预测。接下来本文沿着这套流程用python中的机器学习库sklearn完成一个简单的多因子回归的选股模型。</p>
<h2 id="二、获取数据"><a href="#二、获取数据" class="headerlink" title="二、获取数据"></a>二、获取数据</h2><p>机器学习所需数据主要有两个来源：网络爬虫和专业数据库，这里我们使用的数据为A股股票的历史数据，因此数据来源取自wind数据库。</p>
<p>原始数据包含了所有A股股票——以2018/06/30当日的股票为准，时间段选取1998/04/30至2018/06/30，每个月度每只股票取数十个不同的指标，以月末最后一日的数据作为截面数据保存。</p>
<p>由于数据过于冗杂，我们先对数据进行结构化降维，使用csv格式进行存储，每个月度的截面数据保存在一个csv文件中，文件名有序排列。每个csv文件中包含了该月份最后一日所有股票的部分基本信息、下一个月的收益率、和数十个指标因子的值。</p>
<h2 id="三、数据预处理"><a href="#三、数据预处理" class="headerlink" title="三、数据预处理"></a>三、数据预处理</h2><p>首先是特征提取，特征提取这一步主要基于人的经验，对于指导股票投资的模型，则选取作出投资决策中经常考虑的一些数据指标。这里，我们选取以下几类指标进行考量：</p>
<p>估值指标：营业收入、净利润、净资产等</p>
<p>成长指标：营收同比增速、净利润同比增速等</p>
<p>财务指标：毛利率、资产周转率、经营性现金流等</p>
<p>杠杆指标：流动比率、现金比率等</p>
<p>流动性指标：N日日均换手率等</p>
<p>其他绝对指标：市值、股价、股东数、beta 等</p>
<p>情绪指标：wind评级、wind一直目标价等</p>
<p>技术指标：MACD、RSI、动量反转……</p>
<p>特征因子的选取对于模型的拟合结果和预测准确度有很大影响，因此特征因子要精挑细选。以上指标都是市场中各类投资者经常考虑的指标的总结，有效性有待商议，现在先从wind中提取出这些指标。</p>
<p>接下来是数据清洗，数据清洗需要做的是缺失值填充、数据标准化、数据降维等等。</p>
<p>由于从wind中所取得的指标有限，而且原始数据因为未上市、停牌、涨跌停等多种原因产生了很多空值、不可使用的数据，这部分因子的数值需要进行缺失值填充；部分指标属于绝对值类指标，不同公司间差异性较大，类似营业收入、净利润、现金流等因子，换做与其市值的比值后横向可比性更强；其他有些数据也因为各种原因存在着去极值、标准化和降维等需要。</p>
<p>下表为自1998年4月起的第244个月的csv文件部分截图，文件的列结构如下：</p>
<p>第1列：当前文件所属月份</p>
<p>第2列：wind股票代码</p>
<p>第3列：交易状态，1为正常交易，0为ST/停牌/次新股</p>
<p>第4列：下一个月超额收益率（相对于沪深300）</p>
<p>5列后：已完成数据预处理的特征因子70个</p>
<h2 id="四、模型训练"><a href="#四、模型训练" class="headerlink" title="四、模型训练"></a>四、模型训练</h2><h3 id="1-、模块导入"><a href="#1-、模块导入" class="headerlink" title="1 、模块导入"></a>1 、模块导入</h3><p>该模型依赖的模块主要有：numpy，pandas和sklearn。</p>
<p>其中numpy是Python做数据处理常用的扩充程序库，主要用于支持高维数组与矩阵运算，同时针对数组运算提供大量的数学函数库；而pandas是基于numpy的高效数据模型库，由于为面板数据分析和时间序列分析提供了很好的支持，因此常备用作金融数据分析的基础工具包。</p>
<p>sklearn全称是scikit-learn，是谷歌开发的一个机器学习框架，是python重要的机器学习库。sklearn支持包括分类、回归、降维和聚类四大机器学习算法，还包含了特征提取、数据处理和模型评估三大模块。sklearn建立在NumPy和matplotlib库的基础上，利用这几大模块的优势，大大提高机器学习的效率，是机器学习领域最知名的python模块之一。</p>
<p>sklearn支持的机器学习方式：</p>
<p>1.Classification 监督学习-分类（预测未来变化方向）</p>
<p>2.Regression 监督学习-回归（预测未来变化幅度）</p>
<p>3.Clustering 非监督学习-聚类（选取相近的样本）</p>
<p>4.Dimensionality reduction 非监督学习-降维（选取有代表性的因子）</p>
<p>5.Model Selection 模型选择（选择更好的模型）</p>
<p>6.Preprocessing 数据预处理（如何选择特征，做预处理）</p>
<h3 id="2-、参数设置"><a href="#2-、参数设置" class="headerlink" title="2 、参数设置"></a>2 、参数设置</h3><p>模型中所有参数都在这一部分进行定义，其中包含样本内数据集、样本外数据集、正反数据比例、验证集比例、随机数种子点、置信度、特征因子序列等等。具体参数如下：</p>
<p>1.month_in_sample = range(1,141+1)    # 样本内数据月份范围</p>
<p>2.month_test = range(142,243+1)        # 样本外数据月份范围</p>
<p>3.percent_select = [0.2,0.2]            # 正例和反例数据的比例</p>
<p>4.percent_cv = 0.1                       # 验证集比例</p>
<p>5.seed = 45                             # 随机数种子点</p>
<p>6.logi_C = 0.0005                        # 置信度</p>
<p>7.n_stock = 3625                         # 现今股票数</p>
<p>8.n_stock_select = 10                   # 选出股票数</p>
<p>9.parameters = (‘EP’：’bias’)   # 模型所使用的特征因子</p>
<p>这里的参数后期都可以根据不同需要进行调整，以获得更有效的模型。</p>
<h3 id="3-、数据处理"><a href="#3-、数据处理" class="headerlink" title="3 、数据处理"></a>3 、数据处理</h3><p>对于数据，使用经典的内外划分方式，将整体数据集244个月的A股月数据分为两部分：</p>
<p>样本内数据，通过设定month_in_sample参数的值，选取1998年4月~2009年12月的数据，用于模型训练</p>
<p>样本外数据，通过设定month_test参数的值，选取2010年1月~2018年6月的数据，用于模型预测</p>
<p>对于样本内的数据，先进行数据的进一步清洗和整理，循环读取每一期的csv表：</p>
<p>1.根据parameters参数，从csv文件中读取相关因子数据，并保存在临时表</p>
<p>2.删除单元格有空值的股票</p>
<p>3.加入标签项，根据次月超额收益对个股打标签</p>
<p>4.根据percent_select的参数留下收益最高和最低的部分股票</p>
<p>5.将收益最好的股票打标签1，收益最差的股票打标签0</p>
<p>最终，得到的数据集data_in_sample为处理好的样本内数据集，可以用来进行模型训练，该数据集的部分截图展示如下。</p>
<h3 id="4-、模型训练"><a href="#4-、模型训练" class="headerlink" title="4 、模型训练"></a>4 、模型训练</h3><p>模型训练前，先将样本内数据集再一次进行拆分，拆分为训练集和验证集，验证集的比例根据percent_cv参数确定，集合的拆分由train_test_split完成，因此具有随机性。</p>
<p>根据拆分出的训练集，对模型进行训练，模型训练使用sklearn中的函数model.fit。这里可用的模型很多，包括线性回归模型、支持向量机模型、SGD模型等等。这里以线性回归模型为例，在置信度为logi_C的水平下进行线性回归，经过机器学习得到拟合后的model。</p>
<h2 id="五、模型评估"><a href="#五、模型评估" class="headerlink" title="五、模型评估"></a>五、模型评估</h2><p>用此model对样本内数据集的训练集和验证集进行预测，sklearn中有专门的函数predict和decision_function对模型进行预测。</p>
<p>这样可以得到预测的涨跌标签值以及涨跌的概率，通过将预测数据和真实数据进行比较，metrics中有专门的函数accuracy_score可以进行矩阵直接的比较，最终得到两矩阵的相似性，可以理解为模型预测的准确率。</p>
<p>因此，若参数按上文中进行设置，可以得到的模型训练集的预测准确率为59%，验证集的预测准确度为58%，系统输出结果如下：</p>
<p>training set: accuracy = 0.59</p>
<p>cv set: accuracy = 0.58</p>
<h2 id="六、策略构建"><a href="#六、策略构建" class="headerlink" title="六、策略构建"></a>六、策略构建</h2><p>使用该model构建多因子选股策略：对于所有A股股票，以月度为频率，取parameters中定义的特征因子进行拟合，给出预测涨跌的概率，对预测涨跌概率进行排序，选取前n_stock_select个股票构建等权组合，进行买入。</p>
<h2 id="七、策略预测"><a href="#七、策略预测" class="headerlink" title="七、策略预测"></a>七、策略预测</h2><p>有了通过对训练集机器学习后确定的model，就可以对样本外的数据进行回测。在回测之前同样需要对样本外数据进行清洗和整理，然后按月循环带入model，给出每个月每只个股的涨跌预测以及涨跌概率的预测，并根据策略构建投资组合进行轮动。</p>
<p>回测部分需要有以下输出内容：</p>
<p>1.将预测涨跌概率的矩阵输出到PredResult.csv，</p>
<p>2.将股票组合的月收益率序列记录到return_test表，该表的部分展示如下图，</p>
<p>3.计算出投资组合在样本外预测月份的净值序列，输出到Value.csv。</p>
<h2 id="八、策略评价"><a href="#八、策略评价" class="headerlink" title="八、策略评价"></a>八、策略评价</h2><p>根据回测中得到的组合月度超额收益率return_test表，以及组合净值Value.csv，可以计算出该策略的超额年化收益、波动率和信息比率。本策略中，按上文设定的参数给出的投资组合各项指标，输出如下：</p>
<p>annualized excess return = 0.28</p>
<p>annualized excess volatility = 0.19</p>
<p>information ratio = 1.44</p>
<p>该策略组合的平均超额年化收益率为28%，平均年化收益波动率为0.19，信息比率IR为1.44，每承担1单位波动风险获得1.44的超额收益。</p>
<p>最后，绘制出回测时间段内，2010年1月~2018年6月，该选股策略下的投资组合净值曲线，输出如：</p>
<h2 id="九、其他改进"><a href="#九、其他改进" class="headerlink" title="九、其他改进"></a>九、其他改进</h2><h3 id="1-、因子原因"><a href="#1-、因子原因" class="headerlink" title="1 、因子原因"></a>1 、因子原因</h3><p>特征因子的选择对于限行回归模型的有效性有着较大影响，本文的实例中将70个不同层面的特征因子一起放入了sklearn的线性模型中进行拟合，后续可以考虑有选择性的对模型进行带入，或许会有更好的拟合效果。</p>
<p>例如，在原模型的基础上，去掉技术指标类的特征因子，只保留基本面的特征因子，模型的预测能力和回测评价输出如下：</p>
<p>training set: accuracy = 0.57</p>
<p>cv set: accuracy = 0.57</p>
<p>annualized excess return = 0.25</p>
<p>annualized excess volatility = 0.17</p>
<p>information ratio = 1.46</p>
<p>反之，若只使用技术指标类的特征因子，完全不考虑基本面的指标，模型的预测能力和回测评价输出如下：</p>
<p>training set: accuracy = 0.58</p>
<p>cv set: accuracy = 0.57</p>
<p>annualized excess return = 0.10</p>
<p>annualized excess volatility = 0.29</p>
<p>information ratio = 0.33</p>
<h3 id="2-、变量调参"><a href="#2-、变量调参" class="headerlink" title="2 、变量调参"></a>2 、变量调参</h3><p>可以根据model拟合后的预测准确率指标进行适当的参数调整，将下述输出指标进行优化。</p>
<p>trainingset: accuracy = 0.59</p>
<p>cv set: accuracy = 0.58</p>
<p>例如，将percent_select参数调整为[0.3,0.3]，即选择前30%的股票作为正例，后30%的股票作为反例，对模型进行训练，模型的预测能力和回测评价输出如下：</p>
<p>training set: accuracy = 0.57</p>
<p>cv set: accuracy = 0.57</p>
<p>annualized excess return = 0.27</p>
<p>annualized excess volatility = 0.20</p>
<p>information ratio = 1.33</p>
<p>或者，将n_stock_select参数调整为50，即每一期使用model进行预测时选取前50只股票买入，模型的预测能力不会改变，但是回测评价输出如下：</p>
<p>annualized excess return = 0.24</p>
<p>annualized excess volatility = 0.18</p>
<p>information ratio = 1.34</p>
<p>再或者，将logi_C参数调整为0.005，即对拟合的置信度进行放宽，对模型进行训练，模型的预测能力和回测评价输出如下：</p>
<p>training set: accuracy = 0.59</p>
<p>cv set: accuracy = 0.57</p>
<p>annualized excess return = 0.29</p>
<p>annualized excess volatility = 0.21</p>
<p>information ratio = 1.41</p>
<h3 id="3-、模型改进"><a href="#3-、模型改进" class="headerlink" title="3 、模型改进"></a>3 、模型改进</h3><p>线性回归模型虽然简单、对特征因子选取的依赖性较强，但也是可解释性、可控性较强的模型。除此之外，我们也可以引入其他模型，sklearn中包含了很多机器学习模块可供使用：</p>
<p>1.逻辑回归（可解释性更强，训练速度更快）：</p>
<p>fromsklearn.linear_model import LogisticRegression</p>
<p>2.随机森林模型：from sklearn import tree</p>
<p>3.支持向量机模型（高维非线性拟合，训练速度慢）：</p>
<p>fromsklearn.svm import SVC</p>
<p>4.K近邻算法：from sklearn import neighbors</p>
<p>5.多层神经网络（高频海量数据的机器学习，小题大做）：</p>
<p>fromsklearn.neural_network import MLPClassifier</p>
<p>另一方面，模型的训练和检验方式，也有多种选择，除了交叉验证外，还有滚动训练回测、检验曲线等等。都可以作为后期模型改进可以尝试的方向。</p>
<p>来源：西藏信托</p>
<p>拓展阅读：</p>
<p>1.<a href="https://blog.csdn.net/u011078141/article/details/89453203">一个量化策略师的自白（好文强烈推荐）</a></p>
<p>2.<a href="https://www.myquant.cn/community/topic/1587">学习Python量化有哪些书籍？这里有一份书单送给你</a></p>
<p>3.<a href="https://www.myquant.cn/community/topic/649/2">学了那么多技术指标为什么还不赚钱?从量化角度告诉你</a></p>
<p>4.<a href="https://www.myquant.cn/community/topic/679">最科学的仓位管理利器-凯利公式，从方法上胜过99%散户</a></p>
<p>5.<a href="https://www.myquant.cn/community/topic/548/2">网格交易法，一个不容易亏钱的投资策略（附源码）</a><br><a href="https://blog.csdn.net/weixin_42219751/article/details/105813212">link</a></p>
]]></content>
      <categories>
        <category>quant</category>
      </categories>
      <tags>
        <tag>quant</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>用 Docker 快速部署 PPTP VPN 和 L2TP + IPSEC VPN</title>
    <url>/2016/10/11/38830/</url>
    <content><![CDATA[<p>虽然平时主要用 Shadowsocks，但是架不住有时候没法安装 Shadowsocks 的客户端，那么就还是需要 PPTP VPN 或者 L2TP VPN。</p>
<p>最早的时候，是使用的各种一键安装脚本，但是由于系统版本差异，每次需要安装的时候，都要现找可用的一键脚本，太费劲了。于是从网上找了别人封装好的 Docker 镜像，这篇文章总结下，基本上就是一条语句就搞定了。</p>
<p>PPTP VPN<br>使用的镜像是 mobtitude/vpn-pptp，首先需要把用户名和密码配置一下，打开 /etc/ppp/chap-secrets，</p>
<h1 id="Secrets-for-authentication-using-CHAP"><a href="#Secrets-for-authentication-using-CHAP" class="headerlink" title="Secrets for authentication using CHAP"></a>Secrets for authentication using CHAP</h1><h1 id="client-server-secret-IP-addresses"><a href="#client-server-secret-IP-addresses" class="headerlink" title="client        server  secret                  IP addresses"></a>client        server  secret                  IP addresses</h1><p>ety001         *          123456              *<br>上面的就是配置了一个用户名 ety001 和 密码 123456 的用户，然后执行下面的命令就可以了，</p>
<p>docker run -d –name pptp –restart always  –privileged -p 1723:1723 -v /etc/ppp/chap-secrets:/etc/ppp/chap-secrets mobtitude/vpn-pptp<br>最后检查下 tcp 1723 端口在防火墙上是否打开就可以了。</p>
<p>L2TP + IPSEC VPN<br>使用的镜像是 hwdsl2/ipsec-vpn-server，需要先配置下用户名、密码和PSK，新建一个环境变量的文件 /etc/l2tp-env，内容如下</p>
<p>VPN_IPSEC_PSK=abcdef<br>VPN_USER=ety001<br>VPN_PASSWORD=123456<br>上面的就是配置了一个用户名 ety001，密码 123456，PSK 为 abcdef 的用户，然后执行下面的命令就可以了，</p>
<p>docker run –name ipsec-vpn-server –env-file /etc/l2tp-env –restart=always -p 500:500/udp -p 4500:4500/udp -v /lib/modules:/lib/modules:ro -d –privileged hwdsl2/ipsec-vpn-server<br>最后检查下 udp 500 和 udp 4500 端口在防火墙上是否打开就可以了。</p>
<p>Shadowsocks<br>最后再附带上一个一句话部署 Shadowsocks 的命令，先创建个配置文件 /etc/shadowsocks.json，内容如下</p>
<p>{<br>    “server”:”0.0.0.0”,<br>    “server_port”: 10000,<br>    “local_address”:”127.0.0.1”,<br>    “local_port”:1080,<br>    “password”:”ety001”,<br>    “timeout”:60,<br>    “method”:”aes-256-cfb”<br>}<br>然后执行下面的命令部署</p>
<p>$ docker run -d -p 10000:10000 -v /etc/shadowsocks.json:/conf/shadowsocks.json –restart=always –name ss ety001/ss</p>
]]></content>
      <categories>
        <category>VPN</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>VPN</tag>
      </tags>
  </entry>
  <entry>
    <title>盘点国内外优秀公共DNS</title>
    <url>/2020/07/24/46810/</url>
    <content><![CDATA[<h2 id="分国外和国内两部分（可以各取所需）："><a href="#分国外和国内两部分（可以各取所需）：" class="headerlink" title="分国外和国内两部分（可以各取所需）："></a>分国外和国内两部分（可以各取所需）：</h2><h3 id="国外的9个优秀DNS服务器："><a href="#国外的9个优秀DNS服务器：" class="headerlink" title="国外的9个优秀DNS服务器："></a>国外的9个优秀DNS服务器：</h3><h2 id="1-谷歌的公共DNS服务器"><a href="#1-谷歌的公共DNS服务器" class="headerlink" title="1.谷歌的公共DNS服务器"></a>1.谷歌的公共DNS服务器</h2><p>主DNS：8.8.8.8<br>辅DNS：8.8.4.4<br>谷歌的免费DNS服务器通常被列为最好的，它们易于记忆，并且每个人都可以使用。它甚至可以提供令人印象深刻的速度。</p>
<p>谷歌DNS的主要优势来自他们作为一家公司的声誉。谷歌每年收入极多，有能力提供最稳定和更有弹性的DNS服务器。</p>
<p>这个DNS服务器的唯一问题是它们存储有关您的运营的信息，如果美国政府决定需要这些信息，它们可以与第三方共享。但是，对于不担心此问题的用户，Google通常被认为是最好的DNS服务器。</p>
<h2 id="2-Norton-ConnectSafe"><a href="#2-Norton-ConnectSafe" class="headerlink" title="2. Norton ConnectSafe"></a>2. Norton ConnectSafe</h2><p>主DNS： 199.85.126.10<br>辅DNS： 199.85.127.10<br>诺顿以其出色的防病毒，互联网安全服务和产品而闻名。但是，人们不知道他们的DNS服务器也不会令人失望。</p>
<p>该DNS地址可防止恶意软件和诈骗。这是他们可用的三个级别的互联网防护DNS中的第一个。</p>
<p>第2个是199.85.126.20和199.85.127.20，还限制了带有色情内容的网站，第3个是199.85.126.30和199.85.126.30，增加了阻止诺顿认为非家庭友好的内容，如果你很感兴趣，您可以在Norton ConnectSafe - DNS常见问题中找到非家庭友好内容列表。</p>
<p>这些选项使Norton ConnectSafe成为父母的父母可以轻松选择的，这些孩子希望保护他们免受在线不需要的资料的侵害。</p>
<p>##　3. OpenDNS<br>主DNS： 208.67.222.222<br>辅DNS： 208.67.220.220<br>OpenDNS是今天仍然存在的另一个老竞争对手，是搜索发现的几个最好的DNS服务器列表中另一个常见的候选者。它的质量与Google的DNS效率相当。</p>
<p>同样，对于关心孩子互联网安全的用户，OpenDNS提供了一项名为OpenDNS FamilyShield的服务，可以阻止成人内容（可在服务器208.67.222.123和208.67.220.123获得）。</p>
<h2 id="4-DNS-Watch"><a href="#4-DNS-Watch" class="headerlink" title="4. DNS Watch"></a>4. DNS Watch</h2><p>主DNS： 84.200.69.80<br>辅DNS： 84.200.70.40<br>DNS Watch专注于透明度和自由选择，提供最好的DNS服务器，不受任何形式的审查。他们还保证不会在他们的服务器上存储任何信息，并且他们的解析器不会设置为记录您的任何数据。</p>
<p>他们的形象是无私的服务和团队。他们唯一的目的是为每个人提供高效的互联网。他们还声称，他们不是一家大公司，这有助于避免政府监管。所以对于那里的自由爱好者来说，这是一个很好的选择。</p>
<p>此外，为了跟上他们的透明态度，他们甚至还提供免费DNS服务器的实时统计数据。这种透明性使它们成为最佳DNS服务器的良好候选者，至少在可信度和匿名DNS服务器方面。</p>
<h2 id="5-Comodo安全DNS"><a href="#5-Comodo安全DNS" class="headerlink" title="5. Comodo安全DNS"></a>5. Comodo安全DNS</h2><p>主DNS： 8.26.56.26<br>辅DNS： 8.20.247.20<br>另一个易于设置的服务器。</p>
<p>其中一个有利的一面的科摩多安全DNS是它跨越全球15个节点的事实。在每个大陆上，每个节点包含几个服务器，准备为本地用户提供服务。这使得Comodo Secure DNS成为用户的绝佳选择。</p>
<p>关于DNS服务器速度的许多问题之一是您与其服务器的距离。</p>
<p>无论您身在何处，Comodo的全球报道都能让它快速发展。众所周知，Comodo Secure DNS是最好的DNS服务器之一，因为它还可以让您远离恶意软件和骗局网站。他们会定期更新阻止列表。</p>
<p>以合理的速度进行全球覆盖，再加上它自动检测“未使用”或“重影”页面的事实，使其成为最佳DNS服务器标题的引人注目的选择。特别推荐那些渴望可公开访问且安全的DNS服务器的用户。</p>
<h2 id="6-威瑞信"><a href="#6-威瑞信" class="headerlink" title="6.威瑞信"></a>6.威瑞信</h2><p>主DNS： 64.6.64.6<br>辅DNS： 64.6.65.6<br>Verisign的服务基于两个主题：作为匿名DNS服务器，并提供恶意软件和恶意网站的保护。</p>
<p>他们特别指出，让客户知道他们不会向第三方出售他们的信息，也不会向用户提供任何广告。</p>
<h2 id="7-OpenNIC"><a href="#7-OpenNIC" class="headerlink" title="7. OpenNIC"></a>7. OpenNIC</h2><p>主DNS： 192.95.54.3<br>辅DNS： 192.95.54.1<br>OpenNIC是那些不想弄清楚最接近其位置的服务器的用户的绝佳选择。</p>
<p>此处列出的DNS服务器只是它们可用的大量服务器的一部分。如果您访问他们的网站，您不仅可以查找最接近您所在位置的DNS，还可以让该网站自动为您执行此操作。这样你就可以省去寻找最佳DNS的麻烦。</p>
<h2 id="8-GreenTeamDNS"><a href="#8-GreenTeamDNS" class="headerlink" title="8. GreenTeamDNS"></a>8. GreenTeamDNS</h2><p>主DNS： 81.218.119.11<br>辅DNS： 209.88.198.133<br>有关家庭友好型互联网的最佳DNS服务器的另一名亚军，它不仅会阻止带有色情内容的网站，还会阻止包含恶意软件，僵尸程序以及与暴力和毒品相关的网站。</p>
<p>如前所述，对于父母来说，这尤其有用。</p>
<h2 id="9-Cloudflare-DNS"><a href="#9-Cloudflare-DNS" class="headerlink" title="9. Cloudflare DNS"></a>9. Cloudflare DNS</h2><p>DNS： 1.1.1.1</p>
<p>由职业的网站安全加速服务提供商cloudflare提供，新发布不久，主打安全、隐私、迅速。自用过cloudflare家的cdn服务，感觉还不错</p>
<h1 id="国内优秀公共DNS服务："><a href="#国内优秀公共DNS服务：" class="headerlink" title="国内优秀公共DNS服务："></a>国内优秀公共DNS服务：</h1><h2 id="1、114DNS-（http-www-114dns-com-）"><a href="#1、114DNS-（http-www-114dns-com-）" class="headerlink" title="1、114DNS （http://www.114dns.com/）"></a>1、114DNS （<a href="http://www.114dns.com/%EF%BC%89">http://www.114dns.com/）</a></h2><p>114.114.114.114<br>114.114.115.115</p>
<h2 id="2、腾讯-（https-www-dnspod-cn-Products-Public-DNS）"><a href="#2、腾讯-（https-www-dnspod-cn-Products-Public-DNS）" class="headerlink" title="2、腾讯 （https://www.dnspod.cn/Products/Public.DNS）"></a>2、腾讯 （<a href="https://www.dnspod.cn/Products/Public.DNS%EF%BC%89">https://www.dnspod.cn/Products/Public.DNS）</a></h2><p>119.29.29.29<br>182.254.118.118</p>
<h2 id="3、阿里-（http-alidns-com-）"><a href="#3、阿里-（http-alidns-com-）" class="headerlink" title="3、阿里 （http://alidns.com/）"></a>3、阿里 （<a href="http://alidns.com/%EF%BC%89">http://alidns.com/）</a></h2><p>223.5.5.5<br>223.6.6.6</p>
<h2 id="4、百度-（http-dudns-baidu-com-intro-publicdns-）"><a href="#4、百度-（http-dudns-baidu-com-intro-publicdns-）" class="headerlink" title="4、百度 （http://dudns.baidu.com/intro/publicdns/）"></a>4、百度 （<a href="http://dudns.baidu.com/intro/publicdns/%EF%BC%89">http://dudns.baidu.com/intro/publicdns/）</a></h2><p>180.76.76.76</p>
<h2 id="5、CNNIC-（http-www-sdns-cn-）"><a href="#5、CNNIC-（http-www-sdns-cn-）" class="headerlink" title="5、CNNIC （http://www.sdns.cn/）"></a>5、CNNIC （<a href="http://www.sdns.cn/%EF%BC%89">http://www.sdns.cn/）</a></h2><p>1.2.4.8<br>210.2.4.8</p>
<p><a href="www.simongong.net">西蒙宫博客</a></p>
]]></content>
      <categories>
        <category>DNS</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title>股市神奇的“五个数字”</title>
    <url>/2018/10/11/13755/</url>
    <content><![CDATA[<h2 id="一、20-——最佳止盈点"><a href="#一、20-——最佳止盈点" class="headerlink" title="一、20%——最佳止盈点"></a>一、20%——最佳止盈点</h2><p>20%，股票交易的最佳止盈点。在股市中没有常胜的将军，被套、亏损总是难免的，同时也要意识到也并不可能所有的股票都会不断上涨。来自的一份统计数据显示目前70.8%股民都是一个“贪”字在作祟，由赚变亏，由小亏反倒变成了大亏。所以股票投资“贪”字要不得，建议投资者在买进股票时就要设定一个止盈点，股价上涨20%后坚决卖出股票，如今华尔街不少资深投资人还仍在坚持此比例。另外一个是止损点，低于买入价7%-8%坚决止损。</p>
<h2 id="二、50-——持仓黄金比例"><a href="#二、50-——持仓黄金比例" class="headerlink" title="二、50%——持仓黄金比例"></a>二、50%——持仓黄金比例</h2><p>50%，即股票留50%的仓位，资金留50%的仓位，便于投资者根据自己的操作风格制定不同的仓位控制策略。所谓持仓比例，是持仓品种的市值占整个资金总额的比例，不过此比例是动态的。打个比方，比如某投资者的初始资金为10万元，将5万元购买股票，此时持仓比例为50%;虽说随着股价上涨，总资产和股票市值会不断变动，比如，股价上涨20%，总资产就为11万元，股票市值增至6万元，此时的持仓比例就变成了54.5%，但是刚入市时50%的持仓黄金比例仍要记住。</p>
<p>##　三、60%——低价圈判断</p>
<p>60%，低价圈一个判断比例，是指股价相对前期高点，个股跌幅在60%以上的都可以视作为低价圈。当股价出现涨幅靠前、量比靠前情形，此时股价处于低价圈时，说明主力有意图拉高股价，此时股民参与的风险较小。相反，此时若购买那些高价圈个股，那么风险很大，陷阱较多。所以，股民可以参考此“60%，低价圈判断”的比例，基本能避免盲目追涨个股而被套的惨剧，从而也能提高资金的利用效率。</p>
<h2 id="四、721——股市“魔咒”"><a href="#四、721——股市“魔咒”" class="headerlink" title="四、721——股市“魔咒”"></a>四、721——股市“魔咒”</h2><p>721，就是常被投资者说起的股市魔咒“七亏二平一赢”，是股市盈利的概率，是说90%股民都是亏损的。股民要想打破此魔咒，理财师表示关键还是投资者要改变投资观念，改变一夜暴富的错误观念。股市不是赌场，而是一门大学问，关系到宏观经济学、政策敏感度、心理学、股市技术、综合素质等。不是只靠运气，却没有学习的态度。所以在入市之初要认识这点，注重合理配置资产，一方面可以参与一些年收益10%左右的宜盛月月盈等稳健类投资，能保障有稳定的收益来源;另一方面参与股票和期货等高风险投资，能来获得较高的回报，多元化投资，实现收益最大化。</p>
<h2 id="五、10——股票不超过10只"><a href="#五、10——股票不超过10只" class="headerlink" title="五、10——股票不超过10只"></a>五、10——股票不超过10只</h2><p>10，有风险承受的投资者购买股票最好不要超过10只。因为据专家统计，股票超过10只的组合，其最终收益并不可观，投资者根本忙不过来，还不如配置上述提到的宜盛月月盈了。普通投资者如果对于自身高风险投资比例究竟多少合适，可以参考“100-自身年龄”的公式。当然，都需要看每个人和每个家庭的实际财务情况和风险偏好来做投资。</p>
<p>当然，这也不是万能的，以上股市投资法则仍要因人而异，投资比例做出及时调整。另外，在平时的生活中，投资者还要多加注重相关专业投资理财知识的学习，努力提高自己的投资理财技能，利用各种投资理财渠道和工具，让自己的财富获得保值增值。</p>
]]></content>
      <categories>
        <category>stock</category>
      </categories>
      <tags>
        <tag>quant</tag>
        <tag>stock</tag>
      </tags>
  </entry>
  <entry>
    <title>个人资料-horysk</title>
    <url>/2015/09/10/15552/</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">Hey, password is required here.</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="78b15fbd1e4f3b6449da46b1fd39d5c1255218146a8d77eab1eb4d44944ae0a1">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</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>horysk</category>
      </categories>
      <tags>
        <tag>horysk</tag>
      </tags>
  </entry>
  <entry>
    <title>股票作手回忆录--杰西·利弗莫尔尔操盘术 笔记</title>
    <url>/2019/06/18/34677/</url>
    <content><![CDATA[<p>作者的建议，几乎就是投机交易要旨的全部，剩下的，唯有执行二字而已。</p>
<h2 id="1-【Chapter-5】不要失去你的头寸"><a href="#1-【Chapter-5】不要失去你的头寸" class="headerlink" title="1. 【Chapter 5】不要失去你的头寸"></a>1. 【Chapter 5】不要失去你的头寸</h2><p>行情总是沿着阻力最小的方向运动，不会永涨不跌，也不可能永跌不涨；<br>大多数时间内，多空力量在一个区间中不停地强弱变换，走出震荡行情；<br>当一段时间内多空双方中某一方力量明显强势时，会走出一波趋势行情；<br>行情处于趋势状态时，相较于震荡状态，方向更明确，更容易获取利润；<br>几乎所有人都能够轻易看出来，行情目前是处于趋势状态还是震荡状态；<br>但没人能够永远精确知晓多空双方力量何时会达到平衡并开始发生转换；<br>因此，在趋势行情中，比起努力做到高抛低吸回转交易获取额外利润，持仓直至趋势结束不失为一种好选择；<br>在行情中不应过分担忧趋势是否会立即反转，预测最高点的难度与抛在最高点并反向开空的难度一样高；</p>
<h2 id="2-【Chapter-8】在多头市场看多，在空头市场看空"><a href="#2-【Chapter-8】在多头市场看多，在空头市场看空" class="headerlink" title="2. 【Chapter 8】在多头市场看多，在空头市场看空"></a>2. 【Chapter 8】在多头市场看多，在空头市场看空</h2><p>当判断趋势即将出现时，比起在判断多空反转时进入，不如等待趋势确定启动后进入，虽然此时入场会错失多空反转后的一波运动，但也避免判断错误而可能造成的损失，总体而言，成功率更好，获利也更为客观；<br>同样的，当判断趋势即将结束时，比起在判断多空即将反转时离场，不如等行情盘整并开始反转后离场，虽然这样会错过一部分利润，但相比起错失之后可能的行情延续，这些代价是值得的；</p>
<h2 id="3-【Chapter-10】总有一个错误在你前边"><a href="#3-【Chapter-10】总有一个错误在你前边" class="headerlink" title="3. 【Chapter 10】总有一个错误在你前边"></a>3. 【Chapter 10】总有一个错误在你前边</h2><p>与其抄底，不如等待行情启动后再买入，虽然相对价格较高，但因确定性更强，因此风险更低；<br>即便如此，对行情启动与否的判断，依然有误判的可能，此时应坚决止损，并视之为使用该策略的正常成本，不必太过在意，因这些成本当行情出现时即可轻松挽回；<br>不应贪图行情启动前的局部波段，做确定性较小的交易，造成额外亏损；</p>
<h2 id="4-【Chapter-12】股市不会为你的皮大衣付钱"><a href="#4-【Chapter-12】股市不会为你的皮大衣付钱" class="headerlink" title="4. 【Chapter 12】股市不会为你的皮大衣付钱"></a>4. 【Chapter 12】股市不会为你的皮大衣付钱</h2><p>任何时候做交易都应当保持独立决策，完全为自己的交易负责，可以听取他人的意见及建议作为参考，但最终应当依据自己的交易系统而非依赖他人的指点或判断；</p>
<h2 id="5-【Chapter-13】身为投机客，我的事业是始终支持自己的判断"><a href="#5-【Chapter-13】身为投机客，我的事业是始终支持自己的判断" class="headerlink" title="5. 【Chapter 13】身为投机客，我的事业是始终支持自己的判断"></a>5. 【Chapter 13】身为投机客，我的事业是始终支持自己的判断</h2><p>交易的技术和技巧可以被交流和探讨，但在交易过程中，应始终坚持自己的操作，不可由他人代为操作，也不可仅凭他人指令进行操作；</p>
<h2 id="6-【Chapter-14】抓住空头回补的理想时机"><a href="#6-【Chapter-14】抓住空头回补的理想时机" class="headerlink" title="6. 【Chapter 14】抓住空头回补的理想时机"></a>6. 【Chapter 14】抓住空头回补的理想时机</h2><p>l 获取盈利不仅仅依靠个人的交易能力，更取决于行情的波动；<br>当市场没有行情时，即使连利弗莫尔也无法赚到钱，此时所能做的只有耐心等待机遇的出现，盲目交易只会导致更多的亏损；<br>当只剩下一次交易机会且必须盈利时（如：面临总额止损/最大回撤止损时），应当极其谨慎，避免绝大多数胜率不够高的交易，努力研究并耐心等待机遇的出现，当时机到来时牢牢把握住；<br>不应将自己的交易建立在对未来未知事件的猜测或其它方式的判断之上，这类交易与赌博无异；<br>相反地，依据未来事件发生的结果顺势进行交易，成功率更高，收益也会很不错；</p>
<h2 id="7-【Chapter-18】投机客的勇气就是有信心根据自己的决定行动"><a href="#7-【Chapter-18】投机客的勇气就是有信心根据自己的决定行动" class="headerlink" title="7. 【Chapter 18】投机客的勇气就是有信心根据自己的决定行动"></a>7. 【Chapter 18】投机客的勇气就是有信心根据自己的决定行动</h2><p>当发现自己判断发生错误时，应当果断平仓，乃至顺势反向开仓；<br>不可因为自己当前仓位方向而预期乃至于期待行情走势，而应以行情走势检验自己仓位的正确与否，一旦错误即应立即择机平仓；</p>
<h2 id="8-【Chapter-21】在景气热潮中，大众总是先赚到很多钱账面上的利润，而且始终是账面上的利润"><a href="#8-【Chapter-21】在景气热潮中，大众总是先赚到很多钱账面上的利润，而且始终是账面上的利润" class="headerlink" title="8. 【Chapter 21】在景气热潮中，大众总是先赚到很多钱账面上的利润，而且始终是账面上的利润"></a>8. 【Chapter 21】在景气热潮中，大众总是先赚到很多钱账面上的利润，而且始终是账面上的利润</h2><p>永远不要责备行情走势不同于自己预期，更不应为此抱怨或懊恼，而应当认识到自己判断错误，承认问题，吸取经验；</p>
<h2 id="9-【Chapter-24】大众应该始终记住股票交易的要素一支股票上涨时，不需要花精神去解释它为什么会上涨利润"><a href="#9-【Chapter-24】大众应该始终记住股票交易的要素一支股票上涨时，不需要花精神去解释它为什么会上涨利润" class="headerlink" title="9. 【Chapter 24】大众应该始终记住股票交易的要素一支股票上涨时，不需要花精神去解释它为什么会上涨利润"></a>9. 【Chapter 24】大众应该始终记住股票交易的要素一支股票上涨时，不需要花精神去解释它为什么会上涨利润</h2><p>市场永远领先于实际状况，在交易时，不必过于追究行情波动的原因与理由，而应及时作出相应应对；</p>
<h2 id="10-【其它】"><a href="#10-【其它】" class="headerlink" title="10.【其它】"></a>10.【其它】</h2><p>利弗莫尔的交易能力强于绝大多数人，也曾在交易中赚取极多的利润，但最终依然破产，一贫如洗；<br>在交易世界里，生存比盈利更重要，只有将良好的资金管理与风险控制永远放在第一位，才能避免类似利弗莫尔的结局；<br>永远不要让自己破产，更不可让自己因交易而负债；<br>如果因为资金不够而无法获得更多的利润，那只能说明这些可能获得的额外利润并不是目前所应当得到的，不可因过分贪婪而急于冒进，承担额外的风险；</p>
]]></content>
  </entry>
  <entry>
    <title>试用了5款BI分析工具</title>
    <url>/2020/07/27/27607/</url>
    <content><![CDATA[<p>前几天，领导甩给我一个任务，考察几个BI工具，下季度立项用。</p>
<p>潜心做ETL的我，对BI只是略懂。之前上的BO，由于开发模式不适应、人员用不惯，再加上负责这块的同事走的走，一直被搁置。所以这次目标很明确，急需上手简单，维护要少，能快速反应数据结果的BI。</p>
<p>于是我花了4天时间，全网百度、翻遍各大BI产品官网，也翻遍了知乎和科技网站的口碑推荐，列选了工具测评清单：Tableau、PowerBI、MicroStrategy、Qlikview、FineBI。</p>
<p>每个工具都亲自下载使用，也悉心问了报价。由于是企业选型，考虑的因素较多，除功能和使用感受，还会注重数据整合能力、数据处理性能以及安全性方面的因素，所以大家看着参考。</p>
<p>从以下几个角度考量：</p>
<p>部署安装<br>学习教程<br>使用体验（上手难度）和需求符合度<br>产品功能<br>报价和服务</p>
<h2 id="Tableau"><a href="#Tableau" class="headerlink" title="Tableau"></a><a href="http://www.tableau.com/">Tableau</a></h2><p>从网络上找到一个10.4的Desktop破解版，替换一个注册文件即可，或者淘宝上找…（咳咳）。Tableau还有一个Server版，Server版需要请求tableau的服务器进行交互，网上找到一个代理，给发了一点资料后就没理，主要看desktop版。</p>
<h3 id="1、-下载安装"><a href="#1、-下载安装" class="headerlink" title="1、 下载安装"></a>1、 下载安装</h3><p>百度或者官网上直接下载，类似装office一样，试用版有15天的试用期，过后会提示输入密钥，安装就和一般软件安装一样，解压压缩包，按照提示一步步做。</p>
<h3 id="2、-学习教程"><a href="#2、-学习教程" class="headerlink" title="2、 学习教程"></a>2、 学习教程</h3><p>官网有教学视频，貌似没翻译完，学到一半发现后面的还都是英文的，脑壳疼。不过视频能基本带你熟悉这个工具并入门。</p>
<p>官方貌似还出了一本书叫《人人都是数据分析师：Tableau应用实战》，就是软件教程，还提供数据源供练习，学习Tableau的必备工具书吧。</p>
<p>Tableau有个在线的可视化实例库，都是学员们的作品，这个挺好，可视化作品大家可以互相参考，可以学习人家的分析思路。</p>
<h3 id="3、-产品使用体验和需求符合度"><a href="#3、-产品使用体验和需求符合度" class="headerlink" title="3、 产品使用体验和需求符合度"></a>3、 产品使用体验和需求符合度</h3><p>Tableau可以连接数据库，或者导入excel文件数据。</p>
<p>通过拖拽数据的维度和度量到工作区，来形成可视化图表，可以改变颜色，图表类型，以及其他各种细节。很多功能都是可以拖放到工作区，通过鼠标的几下点击和拖放来实现，很简单，基本不需要代码，还会自动推荐合适的图表。</p>
<p>可视化方面个人认为Tableau还是很强大的，操作也很简单。分析这块，分组、筛选、下钻、新建数据字段需要写公式…这些还是有点难度，一般软件深入的功能都比较难，需要研究一番。</p>
<h3 id="4、-产品功能"><a href="#4、-产品功能" class="headerlink" title="4、 产品功能"></a>4、 产品功能</h3><p>此次选型重点。</p>
<p>Tableau是直接连接数据库（相当于ROLAP），以关系数据库为核心，以关系型结构进行多维数据的表示和存储，维表和事实表通过主关键字和外关键字联系在一起，形成”星型模式”。</p>
<p>好处是小数据量非常快，大数据量影响性能。取数性能依赖于机器，且Tableau在构建多张有数据关联关系的表时，需要将多张数据表拼接成一张大的宽表，复杂统计时容易产生冗余数据，直接造成性能下降。</p>
<p>数据更新</p>
<p>BI很重要的一个功能是数据更新，它是报表自动化的基础。Tableau支持增量更新，不支持定时更新。Tableau抽取的数据均保存到制作的仪表板中，增量更新不能精确到某张表，必须是对全部数据的更新，报表多了，就很麻烦。</p>
<p>银行业十分注重数据安全。感叹Tableau美中不足缺少流程和数据管理功能。</p>
<p>Tableau Desktop（桌面版） 是用来创建分析，进行数据分析的，是分析工具。tableau 的server 是用来发布分析的，发布给企业有相关权限的人，是服务器。将工作簿发布到 Tableau Server。Tableau Server 会提供基于浏览器的分析。将工作簿发布到 Tableau Server 后，其他拥有帐户的人就可以登录查看发布的工作簿。</p>
<h3 id="5、-关于选型价格"><a href="#5、-关于选型价格" class="headerlink" title="5、 关于选型价格"></a>5、 关于选型价格</h3><p>官网报价：</p>
<p>代理商也给了我一个大致的价格：</p>
<p>光产品，Desktop+Sever，一套一人加税后是11万多，每增加一人多买一个桌面版，就是15000左右，我们公司估计是3、40套，预计得7、80万，不含定制实施和维护服务。</p>
<h2 id="PowerBI"><a href="#PowerBI" class="headerlink" title="PowerBI"></a><a href="http://powerbi.microsoft.com/">PowerBI</a></h2><p>Power BI是微软家的。如果大家熟悉Excel，应该会知道微软推出的Power Query、Power Pivot、Power View和Power Map，是Excel上非常强大的四个插件。Power BI则是微软将它们作为集合推出。如果大家熟练掌握以上四个插件，那么在Excel上也能实现部分BI，毕竟Excel是企业中人手一款的工具。</p>
<h3 id="1、下载安装"><a href="#1、下载安装" class="headerlink" title="1、下载安装"></a>1、下载安装</h3><p>Power BI的工作流是在Power BI Desktop中创建报表，将其发布到Power BI 服务，然后与其他人进行共享，让他们可以在服务中或在移动应用上查看到。</p>
<p>Desktop很简单，免费的，官网下载即可，过程同tableau。Power BI报表服务器需要另外安装。需要先安装SQL Server，然后安装报表服务器。报表服务器免费版有180天是试用期，正式版需要购买密钥。</p>
<h3 id="2、-学习教程-1"><a href="#2、-学习教程-1" class="headerlink" title="2、 学习教程"></a>2、 学习教程</h3><p>官网上只找到了学习文档，没有手把手教授的视频。</p>
<p>微信上倒是搜到很多Excel牛人组织的学习课程，可惜要钱呐~</p>
<h3 id="3、产品使用体验和需求符合度"><a href="#3、产品使用体验和需求符合度" class="headerlink" title="3、产品使用体验和需求符合度"></a>3、产品使用体验和需求符合度</h3><p>Power BI的界面很office，上面是操作工具项，左侧栏是导航栏。神似Access，所以寻找功能的时候轻车熟路。侧导航栏对应三个模块：仪表板、报表和数据集。整体流程实用流程就是读取数据集—数据清洗—数据关联—表制作—Dashboard整合仪表板。</p>
<p>可视化方面，相比Tableau，Power BI给人的感觉像是IT出身，没有特别惊艳的感觉，做出来的图表中规中矩、实用性也不错。其实真正好的数据分析，可视化只需要实用就够了。</p>
<h3 id="4、-产品功能-1"><a href="#4、-产品功能-1" class="headerlink" title="4、 产品功能"></a>4、 产品功能</h3><p>数据源</p>
<p>Power BI支持各类数据源（市面上绝大部分BI都支持，只是读取方式略有差异），除了Excel和CSV 文件，它还支持Acess、SQL数据库、Hadoop／HDFS、Spark、第三方API等。</p>
<p>数据清洗</p>
<p>Power BI有一个高级功能叫DAX（Data Analysis Expressions），是整个 Power BI 使用的公式语言。DAX近似Excel函数（大多数第三方BI，函数均接近Excel），故它针对新手非常友好。如果大家已经熟悉Excel函数，上手速度会很快，基本上函数名字都一样。</p>
<p>数据关联</p>
<p>建立表间联系这个很重要，在Excel中，大家一般用写Vlookup函数实现，Power BI则用拖拽关联数据，确实更加方便。</p>
<p>数据更新</p>
<p>BI很重要的一个功能是数据更新，它是报表自动化的基础，它通常和SQL关联。我们使用CSV，只能往里面黏贴数据更新，还是繁琐了些，只属于半自动化。</p>
<h3 id="5、-关于选型价格-1"><a href="#5、-关于选型价格-1" class="headerlink" title="5、 关于选型价格"></a>5、 关于选型价格</h3><p>官网价格（个人参考）：</p>
<p>企业部署：</p>
<p>它是按设计用户和节点卖的，按年/按月收费。估计了一下，假设200个用户的企业，40个设计用户，1年收费是45万左右，也就是每年要付出这么多，还是比较贵的。</p>
<h2 id="FineBI"><a href="#FineBI" class="headerlink" title="FineBI"></a><a href="http://www.finebi.com/">FineBI</a></h2><p>国产BI里口碑好的就挑了这么一家，是帆软的。他家还有一个报表工具finereport，貌似做得更成熟更好，毕竟报表BI也不分家。</p>
<h3 id="1、下载安装-1"><a href="#1、下载安装-1" class="headerlink" title="1、下载安装"></a>1、下载安装</h3><p>下载和安装很简单，官网上直接下载。启动软件时会加载数据日志，但是所有操作都在web端。最初用的4.1版，后来对方工作人员给我发来了最新的5.0，说这几天会上线。</p>
<h3 id="2、学习教程"><a href="#2、学习教程" class="headerlink" title="2、学习教程"></a>2、学习教程</h3><p>激活时会发送一个学习资料包，上面有大概10多节功能教学视频。</p>
<p>还有学习帮助文档，下载激活时大家留心，记得收藏。</p>
<p>除此之外，还有个学习交流的论坛，水了几天，加了学习交流群，怪怪好多人，提问回答好积极，对像我这样的技术宅来讲是极好的。</p>
<h3 id="3、产品使用体验和需求符合度-1"><a href="#3、产品使用体验和需求符合度-1" class="headerlink" title="3、产品使用体验和需求符合度"></a>3、产品使用体验和需求符合度</h3><p>使用的过程是先配置数据源，然后建立一个所谓的业务包，应该就是数据表暂存到业务包内管理，可以按照业务分类。后面就是数据清洗、数据表关联，然后可视化分析了。</p>
<p>界面风格是清爽商务的，比较符合中国人使用门户软件、使用互联网产品的感觉，看了一遍教程基本上就可以上手了。</p>
<p>分析过程，交互啊操作思路，类似Tableau，都是维度和度量的拖拽，自动推荐合适的图表，可以更改颜色、图表类型，以及其他各种细节。</p>
<p>数据配置时有个业务包，这个和其他BI工具大不同，暂时不太了解其用处，能把数据分门别类分好。</p>
<h3 id="4、产品功能"><a href="#4、产品功能" class="headerlink" title="4、产品功能"></a>4、产品功能</h3><p>说其特有的吧。有权限管理有权限管理，有点像OA。tableau、PowerBI这个功能都要装sever版，但貌似功能也局限于分享，没有部门、人员、数据权限的设置。所以相对来讲，finebi更适合企业级使用。</p>
<p>可视化和分析功能基本同tableau，虽然我没有使用太深入，但是整体的分析操作，拖拽数据字段——生成图表——编辑dashboard，这个过程都是很像的。</p>
<p>支持进行数据抽取和数据索引建模，可显著提高数据的计算速度，可实现离线查询；支持用户进行所有数据表的数据更新；支持对数据表进行增量增加、增量删除、增量修改更新。</p>
<p>数据挖掘</p>
<p>支持对数据进行时序预测、数据聚类、数据分类（神经网络、决策树算法）三类挖掘模型算法。</p>
<p>最后，还有一个移动端，手机可查看分析。</p>
<p>###　关于选型价格</p>
<p>个人使用免费，不限功能，限并发。</p>
<p>企业部署是按照功能来售卖，一次买断。问了对方销售，报价没说太明白，需要依据功能和项目来定，产品价格在小几十万不等。送一年技术服务，一年内免费升级。</p>
<p>还有两个工具MicroStrategy和PowerBI，简单试了下，网上内容不多，且篇幅有限，就大致评价一下。</p>
<h2 id="MicroStrategy"><a href="#MicroStrategy" class="headerlink" title="MicroStrategy"></a><a href="http://www.microstrategy.cn/cn">MicroStrategy</a></h2><p>网上下的10.11版。也是一个偏向于企业级的BI分析产品。</p>
<p>国外产品，很多资料都还是英文版，看着很吃力。使用上是先配置数据，然后选择图表，可视化展现，数据字段可以ctrl多选拖拽。</p>
<p>可视化风格和Tableau差不多，该支持的数据都能支持，就是对国内一些ERP等业务系统的数据连接并不支持。功能的话，性能我没有那么多数据也跑不起来，这块打算到现场POC再说。移动端、平板的适应做的挺好的，看他们也在大肆宣传，应该是优势之一。</p>
<p>产品拥有行业型及业务模块的方案，不过案例多是国外的，在国外用的不错。</p>
<p>报价包含产品licence费用以及服务费。产品费用按功能和用户来算，一个设计用户在16W，分析用户3~4W，web报表用户2.3W……总之价格还是蛮高的。</p>
<h2 id="Qlikview"><a href="#Qlikview" class="headerlink" title="Qlikview"></a><a href="http://www.qlik.com/zh-cn">Qlikview</a></h2><p>不得不吐槽，国外产品在国内的网站真的是…费了老大劲找到并下载了。</p>
<p>Qlikview个人是没觉得好用，也没看出优势来，更像是一个可视化工具。像tableau、finebi可以做探索性的数据分析。qlikview比如你想拖一些数据看看结论与猜想是否正确，有时候可能要做20多个仪表盘才能验证自己的猜想，它比较适合一开始就知道怎么分析展现。</p>
<p>Qlikview也是内存型的BI，同Tableau，通病是数据处理速度很大程度上依赖内存大小，对硬件要求较高，一般企业的配置，数据处理起来较慢。</p>
<p>关于报价，国内的报价不清楚，官网也没有展示，填了表单，代理商也没有回应。</p>
<p>最后<br>个人青睐于前三个，上手都比较简单，tableau可视化最佳，powerbi可以和excel结合，finebi最符合选型需求，上手也最简单。具体的还涉及数据读取性能、集群等等，还有乙方项目这块的时间和经济成本。</p>
]]></content>
      <categories>
        <category>BI</category>
      </categories>
      <tags>
        <tag>BI</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>读写CSV数据</title>
    <url>/2020/07/22/28259/</url>
    <content><![CDATA[<h2 id="6-1-读写CSV数据"><a href="#6-1-读写CSV数据" class="headerlink" title="6.1 读写CSV数据"></a>6.1 读写CSV数据</h2><p>More info: <a href="https://python3-cookbook.readthedocs.io/zh_CN/latest/c06/p01_read_write_csv_data.html">python3-cookbook</a><br>问题<br>你想读写一个CSV格式的文件。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>对于大多数的CSV格式的数据读写问题，都可以使用 csv 库。 例如：假设你在一个名叫stocks.csv文件中有一些股票市场数据，就像这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Symbol,Price,Date,Time,Change,Volume</span><br><span class="line"><span class="string">&quot;AA&quot;</span>,39.48,<span class="string">&quot;6/11/2007&quot;</span>,<span class="string">&quot;9:36am&quot;</span>,-0.18,181800</span><br><span class="line"><span class="string">&quot;AIG&quot;</span>,71.38,<span class="string">&quot;6/11/2007&quot;</span>,<span class="string">&quot;9:36am&quot;</span>,-0.15,195500</span><br><span class="line"><span class="string">&quot;AXP&quot;</span>,62.58,<span class="string">&quot;6/11/2007&quot;</span>,<span class="string">&quot;9:36am&quot;</span>,-0.46,935000</span><br><span class="line"><span class="string">&quot;BA&quot;</span>,98.31,<span class="string">&quot;6/11/2007&quot;</span>,<span class="string">&quot;9:36am&quot;</span>,+0.12,104800</span><br><span class="line"><span class="string">&quot;C&quot;</span>,53.08,<span class="string">&quot;6/11/2007&quot;</span>,<span class="string">&quot;9:36am&quot;</span>,-0.25,360900</span><br><span class="line"><span class="string">&quot;CAT&quot;</span>,78.29,<span class="string">&quot;6/11/2007&quot;</span>,<span class="string">&quot;9:36am&quot;</span>,-0.23,225400</span><br></pre></td></tr></table></figure>
<p>下面向你展示如何将这些数据读取为一个元组的序列：</p>
<pre><code class="bash">import csv
with open(&#39;stocks.csv&#39;) as f:
    f_csv = csv.reader(f)
    headers = next(f_csv)
    for row in f_csv:
        # Process row
        ...</code></pre>
<p>在上面的代码中， row 会是一个列表。因此，为了访问某个字段，你需要使用下标，如 row[0] 访问Symbol， row[4] 访问Change。</p>
<p>由于这种下标访问通常会引起混淆，你可以考虑使用命名元组。例如：</p>
<pre><code class="bash">from collections import namedtuple
with open(&#39;stock.csv&#39;) as f:
    f_csv = csv.reader(f)
    headings = next(f_csv)
    Row = namedtuple(&#39;Row&#39;, headings)
    for r in f_csv:
        row = Row(*r)
        # Process row
        ...</code></pre>
<p>它允许你使用列名如 row.Symbol 和 row.Change 代替下标访问。 需要注意的是这个只有在列名是合法的Python标识符的时候才生效。如果不是的话， 你可能需要修改下原始的列名(如将非标识符字符替换成下划线之类的)。</p>
<p>另外一个选择就是将数据读取到一个字典序列中去。可以这样做：</p>
<pre><code class="bash">import csv
with open(&#39;stocks.csv&#39;) as f:
    f_csv = csv.DictReader(f)
    for row in f_csv:
        # process row
        ...</code></pre>
<p>在这个版本中，你可以使用列名去访问每一行的数据了。比如，row[‘Symbol’] 或者 row[‘Change’]</p>
<p>为了写入CSV数据，你仍然可以使用csv模块，不过这时候先创建一个 writer 对象。例如:</p>
<pre><code class="bash">headers = [&#39;Symbol&#39;,&#39;Price&#39;,&#39;Date&#39;,&#39;Time&#39;,&#39;Change&#39;,&#39;Volume&#39;]
rows = [(&#39;AA&#39;, 39.48, &#39;6/11/2007&#39;, &#39;9:36am&#39;, -0.18, 181800),
         (&#39;AIG&#39;, 71.38, &#39;6/11/2007&#39;, &#39;9:36am&#39;, -0.15, 195500),
         (&#39;AXP&#39;, 62.58, &#39;6/11/2007&#39;, &#39;9:36am&#39;, -0.46, 935000),
       ]

with open(&#39;stocks.csv&#39;,&#39;w&#39;) as f:
    f_csv = csv.writer(f)
    f_csv.writerow(headers)
    f_csv.writerows(rows)</code></pre>
<p>如果你有一个字典序列的数据，可以像这样做：</p>
<pre><code class="bash">headers = [&#39;Symbol&#39;, &#39;Price&#39;, &#39;Date&#39;, &#39;Time&#39;, &#39;Change&#39;, &#39;Volume&#39;]
rows = [&#123;&#39;Symbol&#39;:&#39;AA&#39;, &#39;Price&#39;:39.48, &#39;Date&#39;:&#39;6/11/2007&#39;,
        &#39;Time&#39;:&#39;9:36am&#39;, &#39;Change&#39;:-0.18, &#39;Volume&#39;:181800&#125;,
        &#123;&#39;Symbol&#39;:&#39;AIG&#39;, &#39;Price&#39;: 71.38, &#39;Date&#39;:&#39;6/11/2007&#39;,
        &#39;Time&#39;:&#39;9:36am&#39;, &#39;Change&#39;:-0.15, &#39;Volume&#39;: 195500&#125;,
        &#123;&#39;Symbol&#39;:&#39;AXP&#39;, &#39;Price&#39;: 62.58, &#39;Date&#39;:&#39;6/11/2007&#39;,
        &#39;Time&#39;:&#39;9:36am&#39;, &#39;Change&#39;:-0.46, &#39;Volume&#39;: 935000&#125;,
        ]

with open(&#39;stocks.csv&#39;,&#39;w&#39;) as f:
    f_csv = csv.DictWriter(f, headers)
    f_csv.writeheader()
    f_csv.writerows(rows)</code></pre>
<p>讨论<br>你应该总是优先选择csv模块分割或解析CSV数据。例如，你可能会像编写类似下面这样的代码：</p>
<pre><code class="bash">with open(&#39;stocks.csv&#39;) as f:
for line in f:
    row = line.split(&#39;,&#39;)
    # process row
    ...</code></pre>
<p>使用这种方式的一个缺点就是你仍然需要去处理一些棘手的细节问题。 比如，如果某些字段值被引号包围，你不得不去除这些引号。 另外，如果一个被引号包围的字段碰巧含有一个逗号，那么程序就会因为产生一个错误大小的行而出错。</p>
<p>默认情况下，csv 库可识别Microsoft Excel所使用的CSV编码规则。 这或许也是最常见的形式，并且也会给你带来最好的兼容性。 然而，如果你查看csv的文档，就会发现有很多种方法将它应用到其他编码格式上(如修改分割字符等)。 例如，如果你想读取以tab分割的数据，可以这样做：</p>
<pre><code class="bash"># Example of reading tab-separated values
with open(&#39;stock.tsv&#39;) as f:
    f_tsv = csv.reader(f, delimiter=&#39;\t&#39;)
    for row in f_tsv:
        # Process row
        ...</code></pre>
<p>如果你正在读取CSV数据并将它们转换为命名元组，需要注意对列名进行合法性认证。 例如，一个CSV格式文件有一个包含非法标识符的列头行，类似下面这样：</p>
<p>Street Address,Num-Premises,Latitude,Longitude 5412 N CLARK,10,41.980262,-87.668452<br>这样最终会导致在创建一个命名元组时产生一个 ValueError 异常而失败。 为了解决这问题，你可能不得不先去修正列标题。 例如，可以像下面这样在非法标识符上使用一个正则表达式替换：</p>
<pre><code class="bash">import re
with open(&#39;stock.csv&#39;) as f:
    f_csv = csv.reader(f)
    headers = [ re.sub(&#39;[^a-zA-Z_]&#39;, &#39;_&#39;, h) for h in next(f_csv) ]
    Row = namedtuple(&#39;Row&#39;, headers)
    for r in f_csv:
        row = Row(*r)
        # Process row
        ...</code></pre>
<p>还有重要的一点需要强调的是，csv产生的数据都是字符串类型的，它不会做任何其他类型的转换。 如果你需要做这样的类型转换，你必须自己手动去实现。 下面是一个在CSV数据上执行其他类型转换的例子：</p>
<pre><code class="bash">col_types = [str, float, str, str, float, int]
with open(&#39;stocks.csv&#39;) as f:
    f_csv = csv.reader(f)
    headers = next(f_csv)
    for row in f_csv:
        # Apply conversions to the row items
        row = tuple(convert(value) for convert, value in zip(col_types, row))
        ...</code></pre>
<p>另外，下面是一个转换字典中特定字段的例子：</p>
<pre><code class="bash">print(&#39;Reading as dicts with type conversion&#39;)
field_types = [ (&#39;Price&#39;, float),
                (&#39;Change&#39;, float),
                (&#39;Volume&#39;, int) ]

with open(&#39;stocks.csv&#39;) as f:
    for row in csv.DictReader(f):
        row.update((key, conversion(row[key]))
                for key, conversion in field_types)
        print(row)</code></pre>
<p>通常来讲，你可能并不想过多去考虑这些转换问题。 在实际情况中，CSV文件都或多或少有些缺失的数据，被破坏的数据以及其它一些让转换失败的问题。 因此，除非你的数据确实有保障是准确无误的，否则你必须考虑这些问题(你可能需要增加合适的错误处理机制)。</p>
<p>最后，如果你读取CSV数据的目的是做数据分析和统计的话， 你可能需要看一看 Pandas 包。Pandas 包含了一个非常方便的函数叫 pandas.read_csv() ， 它可以加载CSV数据到一个 DataFrame 对象中去。 然后利用这个对象你就可以生成各种形式的统计、过滤数据以及执行其他高级操作了。 在6.13小节中会有这样一个例子。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>量化交易领域最重要的10本参考书推荐！</title>
    <url>/2018/08/20/33568/</url>
    <content><![CDATA[<ol start="0">
<li>《期权、期货及其他衍生产品》</li>
</ol>
<ol>
<li>《打开量化投资的黑箱》</li>
</ol>
<p>这本书的作者里什·纳兰（Rishi K. Narang）是华尔街顶级数量金融专家，资深对冲基金经理，自1996年开始，他就开始从事对冲基金事业，专注于量化交易策略。目前是特勒西斯资本有限责任公司（Telesis Capital LLC）的主要合伙人。在书中他站在一个非纯粹技术的视角介绍了量化交易策略，用生动的文笔带领读者游历整个“黑箱”。</p>
<p>《打开量化投资的黑箱》的写作涉及很多金融界丰富的真实案例和市场趣闻，富于智慧地描绘了华尔街的数量金融奇才们是如何工作的。可是说阅读《打开量化投资的黑箱》的过程，就是一个慢慢理解数量金融大师及其投资策略的过程，从而揭开量化交易的神秘面纱。</p>
<ol start="2">
<li>《量化投资策略：如何实现超额收益Alpha》</li>
</ol>
<p>本书作者Richard Tortoriello是任职于S&amp;P 标准普尔公司的证券分析师，他的日常工作就是建立一系列的数量选股模型。书中的模型类型覆盖面广，可以说作者是在对所有能够获得超额收益的策略进行了地毯式的搜索，并且提供了超过20种常胜投资idea的详细回测情况，充分展示了经验丰富的Quant是如何通过自己的想法来改进模型的。顺便提一句，本书的译者们也都是浸淫证券市场多年的大咖，其中陈工孟更是深圳国泰君安的董事长和上海交通大学金融工程研究中心的执行主任。值得一看。</p>
<ol start="3">
<li>《解读量化投资：西蒙斯用公式打败市场的故事》</li>
</ol>
<p>这本书的作者是以为在伦敦卖身瑞银十年，曾就任瑞银投资银行的外汇部和资本市场部，负责金融工程并且现任法国巴黎银行资产管理部外汇重置业务亚太区主管、董事总经理的传奇华人忻海，现居香港。</p>
<p>本书的人物主角詹姆斯·西蒙斯，拓扑学大腕，陈省身论文的合作者，虽然不是一个家喻户晓的名字，但他在投资界却因量化型投资的独门套路掀起层层热浪。大“数”底下好乘凉，西蒙斯的布阵和诸葛亮的布阵有所不同。西蒙斯靠的是概率：大量的统计套利操作，外加华尔街之外的数学教授来助阵，西蒙斯的“黑箱投资’’方法靠电脑编程和自动交易，在和市场的较量中稳操胜券。</p>
<ol start="4">
<li>《利用Python进行数据分析》</li>
</ol>
<p>如何利用各种Python库（包括NumPy、pandas、matplotlib以及IPython等）高效地解决各式各样的数据分析问题。由于作者Wes McKinney是Python pandas库的主要作者，所以本书也可以作为利用Python实现数据密集型应用的科学计算实践指南。本书适合刚刚接触Python的分析人员以及刚刚接触科学计算的Python程序员。</p>
<ol start="5">
<li>《集体智慧编程》</li>
</ol>
<p>这本书选择的是Python语言，以机器学习和统计学方法为背景，专门讲述如何挖掘、分析数据，适合做决策树、支持向量机（SVM）、神经网络的初学者 quant们使用。可以说它成功地将机器学习算法这一复杂议题拆分成实用易懂的例子，能够让初学者少走弯路。可以作为上一本书《利用Python进行数据分析》的高阶版进行阅读。</p>
<ol start="6">
<li>《量化投资: 以matlab为工具》</li>
</ol>
<p>这本书分为基础篇和高级篇两大部分。基础篇部分通过Q&amp;A的方式介绍了MATLAB的主要功能、基本命令、数据处理等内容，使读者对MATLAB有基本的了解。高级篇部分分为14章，包括MATLAB处理优化问题和数据交互、绘制交易图形、构建行情软件和交易模型等内容，通过丰富实例和图形帮助读者理解和运用MATLAB作为量化投资的工具。这本书的特色在于不仅仅满足理论学习的需要，更帮助读者边学边练，将理论和实践并重。</p>
<ol start="7">
<li>《宽客 Quants》</li>
</ol>
<p>《宽客》是一本讲述华尔街顶级数量金融大师的另类人生的书。2007年金融危机爆发以来，作者采访了大量加州抵押贷款违约业主、对冲基金经理和顶尖经济学及金融学学者，在《华尔街日报》上对危机做了全方位、多角度的报道。本书对华尔街新兴的主宰者“宽客”进行了前所未有的深入描述，其中既有宽客新锐中的佼佼者：穆勒、格里芬、阿斯内斯和魏因斯坦，又有隐士般的詹姆斯·西蒙斯，史上最成功对冲基金的创始人艾伦·布朗，以及多位宽客中的异类。这群数学天才就像闯进华尔街糖果店的小孩——他们从华尔街的最底层开始一步步登上最高峰，又造成了一次又一次的市场崩溃。书的第一章“从赌博开始”，更是揭示了众多概率论中复杂体系形成的起点，引人入胜。更推荐把这本书和 《对冲基金风云录二》、《高盛帝国下》一起比较起来看，可能收获更多。</p>
<ol start="8">
<li>《宽客人生》</li>
</ol>
<p>本书作者Emanuel Derman 是华尔街的顶级宽客，至今仍享盛名。目前是哥伦比亚大学金融工程教学项目的负责人。</p>
<p>自资本资产定价模型和Black-Scholes模型被发明之后，宽客成为华尔街的新宠，因为投资银行和基金公司必须采用日益复杂的数量交易策略和衍生产品。本书作者是首批转战华尔街的高能实验物理学家之一，在十几年中创建了对今天影响深远的众多金融交易模型。本书精彩纷呈，分析了物理学与金融学之间的关联和不同，讲述了许多物理学巨匠和金融学大师的故事。与上一本《宽客》不同的是，本书更适合理工科专业背景的金融从业人员阅读。</p>
<ol start="9">
<li>《对冲基金风云录 三部曲》</li>
</ol>
<p>本书主要描述了美国对冲基金行业里的众生相，生动细致真切，中间夹杂了作者自己的思考，还有一些行业常识的介绍内容。基本功效：开阔眼界，增长见识，引发同感。但是对于集中精力做国内产品量化交易的研究人员，这本书可能就是茶余饭后的消遣读物了。但是众多书友都极力推荐这个系列的第二本《对冲基金风云录2》，可见还是有它的可取之处。</p>
<p>本书作者巴顿·比格斯在摩根士丹利工作了30年，曾任该公司的首席战略官。在此期间，他创立了摩根士丹利的研究部，并使之成为世界上最优秀的投行研究部门。他还曾一手创办公司的投资管理业务部，并担任其主席达30年之久。到20世纪90年代中期，摩根士丹利投资管理部每年赢得的新客户超过任何竞争对手。</p>
<ol start="10">
<li>《证券混沌操作法》</li>
</ol>
<p>比尔·威廉姆于90年代出版的一本投资理念性质的书，全书讲述的就是如何用混沌的理念解释股价，但还是运用了一系列股票传统的技术指标，所以也适合初步接触股票的人翻看。不过也正如豆瓣上一位资深股民所说，“如果只是把它当成交易方法来看，有点可惜。 如果只是把他当成人生哲学，似乎不够通透。 这是一本需要一读再读的书。 想起了这句话：上士闻道，勤而行之；中士闻道，若隐若无；下士闻道，大笑之。不笑不足以为道。” 作者在2002年左右出版了第二版，目前大陆地区未发行，台湾地区翻译并出版了。</p>
]]></content>
      <categories>
        <category>quant</category>
      </categories>
      <tags>
        <tag>quant</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>高频交易四大派系大揭秘</title>
    <url>/2019/03/08/3936/</url>
    <content><![CDATA[<p>所谓高频交易，简单说就是指利用计算机技术在短时间内快速进行多次买入卖出的交易行为，一般指利用微妙（1秒等于1百万微秒）为时间单位制定策略，高频交易公司利用强大的电脑程序进行快速交易，交易时间经常不到十毫秒。</p>
<p>与技术上相对落后的投资者相比，此类公司利用靠技术优势获得的时间优势先行下单。高频交易的速度如此之快，以至于有些交易机构将自己的“服务器群组”（server farms）安置到了离交易所的计算机很近的地方，以缩短交易指令通过光缆以光速旅行的距离。</p>
<p>高频交易虽具有“高频”的共同特征，但是其交易机制则千差万别，由此导致其对市场的影响也会不同。根据现有策略，高频交易大体可以分为以下四类。</p>
<h2 id="订单拆分策略"><a href="#订单拆分策略" class="headerlink" title="订单拆分策略"></a>订单拆分策略</h2><p>在美国机构投资者的大笔交易往往造成价格急剧变化，从而增加交易成本。订单拆分策略为了解决这个问题，使用多种算法把大订单分割成若干个小订单，从而减小大订单对市场的影响并降低执行成本。</p>
<p>这类算法可以分为三代。第一代主要考虑如何减小对市场的影响，以TWAP(time weighted average price)、VWAP(volume weightedaverage price)和POV(percent of volume)为代表。其中，TWAP将大订单在规定的时间内按照一定的交易频率分割成小订单，VWAP按照交易量的历史分布分割订单，POV则将小订单以固定比例混入订单流以降低对市场的影响。但是，这种有规律的订单分割方式容易被其他交易者发觉并跟风，从而提高交易成本。</p>
<p>第二代拆分策略则加入了一些反侦测的技术手段。例如冰山策略(iceberg)采取了随机分割的方法，最低影响(minimal impact)策略则是利用备选交易系统2作为主要的交易通道，而只把小部分交易放在公开的交易系统中完成，以避免交易意图的泄露。</p>
<p>第三代拆分策略认为，如果片面地强调订单分割和避免被侦测，就存在无法按时完成交易计划的风险，这样反而会导致交易成本的上升，因此强调利用交易量较大的交易时间完成仓位计划。而且，为了使执行差额策略可以适应快速变化的市场条件，Kissell,Freyre-Sanders and Carrie提出了适应性差额策略(adaptiveshortfall)，以根据当前价格的变动情况决定如何执行仓位计划。</p>
<p>此外，由于收盘价对于投资结算等具有重要影响，还有经纪商提出了MC(market close)策略，在全天交易时间的后半部分完成交易指令。目前国内对此类策略的研究和应用都还很少。但是随着做市商制度的引进和机构投资者的发展壮大，大笔买入卖出的需求也会随之变大，可以预见对大笔交易的订单拆分需求也会越来越大。</p>
<h2 id="做市交易策略"><a href="#做市交易策略" class="headerlink" title="做市交易策略"></a>做市交易策略</h2><p>国际金融市场普遍实行做市商制度。与竞价交易制度不同，做市商制度是借助做市商(由大的银行机构来担任)的中介作用实现买卖双方的交易，做市商从证券的买卖差价中获取收益，并为市场提供流动性。</p>
<p>近年来，一种被称为“被动做市策略”的高频交易模式逐渐发展起来。这种策略产生于美国特殊的交易机制。在美国，所有的证券交易所都为那些创造流动性的券商提供一定的交易费用回扣以争取更多的交易订单。当这些交易者使用双向挂单等待成交时，便为市场提供了流动性，使得其他有交易需求的交易者以更低的成本交易，相应的也提高了交易所的竞争力。</p>
<p>因此各电子化交易所对这类流动性提供者提供返还回扣，鼓励其通过报单参与交易。在这种情况下，很多小机构甚至个人投资者也可以为市场提供流动性，并在众多电子化交易所中担当起了实质性的做市商的责任。</p>
<p>做市商在交易过程中也会面临各种风险，一方面，资产价格的波动会造成了存货风险；另一方面，买卖指令的泊松分布又造成了交易风险。这种风险对传统的做市商影响更大，因为它们普遍具有巨大的资金量和交易量，也对市场有着更大的影响。</p>
<p>它们主要采用两种方法来规避这种风险。一种方法是通过完善定价机制，将风险融入资产价格从而转移风险。学术界发展了一系列模型解决这一定价问题，例如存货模型和信息模型等等。</p>
<p>另一方法是风险对冲。以Delta中性策略最为典型。Delta被定义为该衍生证券的价格变化对其标的资产价格变化的比率，Delta为零的状态被称为Delta中性。如果进行高频对冲，Delta中性策略就成为一种高频交易模式。它必须在标的资产价格刚开始下降时将其出售，在其刚开始上涨时将其购入，因此它在本质上是一种趋势交易方法。从国外经验看，做市交易是高频交易策略的主流。我国目前已经在国债、利率掉期等若干市场引入做市商制度，如果在更多市场实施该制度，高频交易还会有进一步发展。</p>
<h2 id="定量化交易策略"><a href="#定量化交易策略" class="headerlink" title="定量化交易策略"></a>定量化交易策略</h2><p>订单拆分策略与做市交易策略更多是作为一种金融服务存在，而定量化交易策略强调使用定量分析进行投资决策。定量化交易策略种类非常繁多，有的针对单一资产，有的则针对投资组合。针对单一资产的分析方法包括事件套利(event arbitrage)、盘口交易(ticker tape trading)和技术分析(technicaltrading)等。</p>
<p>事件套利是指针对某特定事件的发生(如重组、拆分、兼并、收购等等)预先判定其对市场影响，进而利用市场的短期新闻效应进行交易。盘口交易是指根据订单流、交易量等信息进行交易的策略。</p>
<p>有研究认为，价格序列和交易量中包含了尚未公布的信息，通过对其进行分析，就可以根据这些信息进行交易。技术分析利用历史价格的走势和图形预测价格波动。Park and Irwin发现新兴股票市场、期货以及外汇市场是最适合技术分析的市场。Lukac,Brorsen and Irwin认为所有技术分析手段中趋势追随型交易策略最为有效Murphy指出，实现趋势追随的主要方法是移动均线法和通道突破法。针对投资组合的交易策略包括套利交易(arbitrage)和配对交易(pairtrading)等。</p>
<p>套利交易通过捕捉标的物完全相同的两种金融资产的差价获取利润。美国市场金融产品品种较多，针对同一标的物可能同时有期权期货等多种金融产品；同时，每种资产又可以同时在几个交易所挂牌交易。这样的市场生态为套利交易提供了较大的生存空间。</p>
<p>配对交易也称收敛交易(convergence trading)，它假设相关联的标的物的价格具有相关性，因此在一种资产价格上涨而另一种下跌时，就可以做多下跌的资产，而卖空上涨的资产。由配对交易发展而来的统计套利(statistical arbitrage)与配对交易的不同之处在于，统计套利判断资产的相关性并不依据基本面或其市场特征，而且它所关注的往往是包括上百个资产的资产组合之间统计上的相关性。</p>
<h2 id="其他策略"><a href="#其他策略" class="headerlink" title="其他策略"></a>其他策略</h2><p>除了上述正常的交易策略，还有一些高频交易策略可以使交易者获取信息优势而损害交易的公平性，甚至操纵价格走势，主要包括结构性(structural)策略和方向性(directional)策略。</p>
<p>结构性策略是指交易者利用不公平的交易制度获利。例如，某些交易者可能利用托管服务(co-location)先于其他交易者获取价格和订单数据，并据此下单而获利。</p>
<p>方向性策略主要包括指令占先(order anticipation)策略和趋势引发(momentum ignition)策略。指令占先策略在某些文献中又被称为“掠夺性算法交易”，它是指通过技术手段识别潜在大买(卖)方并抢先发出指令，待其大笔交易引发价格上升(下降)后平仓获利。</p>
<p>趋势引发策略是指事先建立头寸，然后诱骗其他交易者进行交易引发价格快速变动，进而从中牟利。其具体操作方法主要包括：通过大量挂单诱导其他交易者跟风；通过大笔成交触发市场中存在的止损指令；等等。在进行交易操纵的同时，还可能伴随着发布虚假信息等行为。</p>
<h2 id="高频交易“托拉斯”诞生"><a href="#高频交易“托拉斯”诞生" class="headerlink" title="高频交易“托拉斯”诞生"></a>高频交易“托拉斯”诞生</h2><p>在不少投资者眼中，高频交易是“市场里的嗜血鬼”，利用程序频繁挂单撤单严重影响市场。也有人说，高频交易不仅平抑了市场波动，还给市场提供流动性，因此程序化交易作为一种交易方式具有存在的价值和意义。但其对市场的影响，则要看是什么人，怎么来使用。可以说，程序化交易是把“双刃剑”。</p>
<p>在高度曝光下，高频交易商战无不胜的神话开始褪色。踏进2017年后，有关高频交易商的不利报道陆续涌现。</p>
<p>其中令人触目的三宗包括︰全球最大高频交易公司Virtu 14亿美元收购竞争对手KCG；量化交易公司Quantlabsa和专于高频交易的Teza进行合并；及Interactive Broker退出期权市场。</p>
<p>Virtu收购KCG</p>
<p>Virtu Financial 4月20日宣布：已达成最终收购协议，并获得骑士资本（KCG）董事会一致通过。Virtu以每股20.00美元的价格，总计约14亿美元，现金收购竞争对手骑士资本（KCG）</p>
<p>该笔交易为Virtu开辟了新的收入来源。Virtu可以将技术和服务拓展到KCG的众多机构客户。Virtu将整合Virtu和KCG的优秀算法和分析工具，向客户提供更优质的服务。</p>
<p>更大的规模和成本效益将使Virtu更有效地应对复杂的市场和同业竞争。Virtu预计在合并后两年可以节省大约2.08亿美元的成本节省，并通过协同效应增加4亿美元的收入。</p>
<p>该交易将通过向私募股权公司北岛和淡马锡发行价值7.5亿美元的股票进行融资，并从摩根大通证券有限责任公司借款16.5亿美元。</p>
<p>Virtu在收购KCG后也成为全球高频交易公司中的巨头。</p>
<p>Virtu Financial</p>
<p>Virtu曾是闷声发大财的代表，在1485个交易日中仅有一天出现亏损。但自2016年，Virtu的利润开始出现了下滑。</p>
<p>Virtu是全球最大的高频做市商之一。关注私募工场ID：simugongchang，加私募工场老板娘微信guo5_guoguo交易领域横跨股市、商品、外汇、期权和债市等固定收益市场，为全球34个国家的225余家交易所提供流动性。业务总部坐落在纽约，在北美、欧洲、亚洲均设有交易中心以专注于各洲市场。</p>
<p>Virtu于2014年提交招股说明书，并于2015年成功进行IPO。</p>
<p>在招股说明书中显示，Virtu的盈利能力令人难以置信。从2009年到2014年的1485个交易日中，Virtu平均每天执行530万次交易，其中49%的操作是盈利的，然而仅仅一天出现亏损。</p>
<p>2014年， Virtu每天都有盈利，共录得收入7.231亿美元和利润1.901亿美元。</p>
<p>Virtu避免可能带来巨额亏损的大交易，而是专注于赚取一笔笔微薄的利润——比如10美元——每天上百万次。</p>
<p>5月的那个周五，公司在黄金交易所和期货市场做市。在芝加哥和纽约的23笔交易中，总共获得了36美元的利润。</p>
<p>Virtu作为电子做市商，虽用高频交易的技术手段，但与高频趋势行情推手不同，而是流动性提供者，是各市场所依赖的”合作伙伴”，高频做市商Virtu是的策略是”市场中性”的。在Virtu的招股说明书中，Virtu戏称他的策略遵循”三板斧”。1”single instrument market making strategy” 场内寻找对手盘 2 “one to one market making strategy” 在双边市场寻找对手盘3 “one to many market making strategy” 在一揽子市场组合寻找对手盘。</p>
<p>与卖家和买家同时做对手盘，而不是自己持仓，并且要么在最后把风险对冲掉，要么不承担任何风险。Virtu的做市交易总共涉及1.2万种金融资产。最能体现该公司严苛高效的是：它从事交易的市场（全世界34个国家的225个交易所）比员工的人数还多（截至2015年有148人）。</p>
<p>骑士资本</p>
<p>成立于1995年的骑士资本是华尔街上名声显赫的重量级证券公司。</p>
<p>被行业称之为市场的支柱公司之一，并以其稳健的行业风格和专业的服务领域而著名。不但规模庞大，吸引了许多重量级的客户，而且业务范围遍及美国、欧洲和亚洲。</p>
<p>其市场的交易份额占到纽交所交易总量的17.3%，纳斯达克证券市场的16.9%，自2011年到2012年间的日交易总量达到全美金融证券市场的10%。</p>
<p>服务的客户对象既包括了买方客户，也包括了卖方客户，同时还有大量的零售客户。涉及的金融产品涵盖了全球金融市场的股票、固定收益产品、外汇，期货和期权等。</p>
<p>除了为客户提供全方位的经纪业务服务之外，还通过公司的交易平台为客户提供高频交易服务。骑士资本主要的业务涉及三大块，即做市商业务、电子交易执行服务业务、以及机构销售和交易业务。</p>
<p>但这家华尔街著名的做市商却在2012年遭受了灭顶之灾。不到45分钟的时间亏损高达4.6亿美元。</p>
<p>2012年8月1日，本应该是一个非常普通的交易日。</p>
<p>刚刚开市，市场中就出现了大量异常订单，数量不但巨大，而且涉及的股票也很广。开市20分钟后异常的订单如同发怒的海潮涌向纽交所，直接触发了市场熔断，并暂停了多只股票的交易。</p>
<p>直到9:50分时纽交所才确定这些非正常的交易订单来自于骑士资本公司。</p>
<p>而此时骑士资本公司也陷入了混乱。当得知交易系统向纽交所发出了大量异常订单之后，公司的高层管理人员立即赶到公司的交易厅。</p>
<p>直到10:00点钟，在骑士资本和纽交所的共同努力之下，才停止了骑士资本的交易系统向纽交所发送交易订单。</p>
<p>当天收市后纽交所宣布，在查验140只非正常交易的股票后，决定取消6只股票的交易。这意味着这6只股票当天的所有成交撮合全部无效。</p>
<p>骑士资本在交易事件之后向美国证监会提出申述，要求取消更多的错误交易，最终没能获得成功。</p>
<p>根据事后的报道，骑士资本集团交易系统的错误是由一个新安装的软件模块所引发，这是一个已经被废弃不用了的软件模块，但始终存在于交易系统之中。通常，这样的废弃模块被称为“死”模块。</p>
<p>但骑士资本的技术人员在为系统升级时，没有更换“死”模块。8月1日早上交易系统开始运行时，在某一特定条件下触发计算机执行了这个 “死”模块，导致了事件的发生。</p>
<p>很显然，这是一起由计算机引发的差错，但是根源却在于编写软件和维护计算机系统的人，是一起人为的严重交易事故。</p>
<p>根据美国证监会公布的调查表明，骑士资本的系统共收到212笔交易订单，交易系统应该执行这212笔交易订单的撮合。</p>
<p>然而，骑士资本的交易系统却在不到45分钟的时间里发送了几百万笔交易订单，致使纽交所在这段时间里成交了超过400万笔交易订单，平均每秒钟的成交超过了1500笔。</p>
<p>短短45分钟时间，骑士资本系统的总交易量就达到了66.5亿美元。骑士资本最终的损失高达$4.6亿美元。</p>
<p>最终美国高频交易商getco以14亿美元的价格收购了骑士资本。</p>
]]></content>
      <categories>
        <category>quant</category>
      </categories>
      <tags>
        <tag>quant</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>Hyperledger Fabric 搭建第一個 Blockchain” </title>
    <url>/2020/07/29/55187/</url>
    <content><![CDATA[<p>前言<br>只需单击即可启动功能完善的区块链网络<br>新的 IBM Blockchain Starter Membership Plan 为您提供了一种经济的方式来启动区块链网络。然后，您可以轻松部署区块链应用，比如这里描述的投票应用。</p>
<p>区块链（Blockchain）技术正在迅速发展，各行各业都正以极大的热情拥抱它。作者相信区块链将成为对信息科技领域产生革命性影响的一项新技术。目前，Hyperledger Fabric 正是此领域一个重要的技术框架与平台。</p>
<p>本文既是 Hyperledger Fabric（以下简称 Fabric）的实用教程，也是其学习、研究笔记。读者可以与作者一起，一步一步地学习 Fabric 基础知识，利用 Hyperledger Composer（以下简称 Composer）搭建 Fabric 本地开发环境，运行示例应用；并进一步分析、深入了解其技术结构与特点。</p>
<p>本文尽量不去简单复述其他相关文档，着重从实用角度与读者一起迅速建立对 Fabric 的直观认识，并在实践中逐渐理解区块链技术。本系列文章有三个部分，此为第一部分。</p>
<p>在本文示例中，Fabric 的版本为 1.1.0，Composer 的版本为 0.19.1。在以后的学习过程，它们可能随时有版本更新，而 micro 版本的改动应该对示例操作不会有影响。但仍请注意版本更新可能带来的变化。</p>
<p>基本概念与知识<br>基本概念与重要平台、技术、工具<br>用一句话来描述区块链：区块链是一个共享的不可修改的账本，可用来记录一个网络上所有交易的历史。这里所说的”交易”翻译自 “Transaction”。也可以将之称为”事务”，本文将之统一称为”交易”。</p>
<p>Hyperledger 是 Linux 基金会主持的一个开源项目，启动于 2015 年，其核心目标是建立开放的、标准化的、企业级的、能支持商业交易的分布式账本的框架与基础代码。</p>
<p>Hyperledger Fabric 是 Hyperledger 项目的一个组成部分，是一个区块链框架的实现。它将成为区块链应用开发、解决方案的基础。Fabric 框架支持组件化、可插拔的共识服务（Consensus Service）、成员服务（Membership Service）；”许可（Permissioned）”特性使之为”私有性”、”保密性”提供了可靠的解决方案；智能合约（Smart Contracts）在 Fabric 中通过”Chaincode”得以实现。Fabric 最初是由 Digital Asset、IBM 贡献给 Hyperledger 项目的。</p>
<p>Hyperledger Composer 也是 Hyperledger 项目的一个组成部分。通过它，人们可以更快速、容易地建立区块链业务模型，进行区块链网络及应用的开发、部署，并与现有系统、数据进行集成。</p>
<p>本文中，对于 Fabric 的学习，正是以 Composer 作为入口与基础工具，这样学习的效率更高。在学习初期，Fabric 与 Composer 的知识是紧密结合的，在后期，我们会对这两项技术分别深入学习、研究。</p>
<p>知识准备<br>区块链技术涉及到的技术比较多，本文希望能帮助读者将焦点一直放在区块链本身上，即使对某项技术学习得不是非常深入，也不会影响对于 Fabric 的学习。一般来说，希望读者还是能对以下知识预先有所了解：Ubuntu，Docker，Node.js，Javascript，npm，CA。</p>
<p>安装 Fabric 之前的环境准备<br>Ubuntu 16.04 LTS 64-bit<br>Fabric 支持 MacOSX、*nix 或者 Windows 10 操作系统；Composer 支持 Ubuntu Linux 14.04 / 16.04 LTS (64-bit)或者 MacOS 10.12 操作系统。</p>
<p>现在，我们使用 Ubuntu 16.04 LTS 64-bit ，作为我们的区块链部署系统。对于 Ubuntu 系统的安装与管理，这里不再详述，但可以通过以下命令确认版本信息：</p>
<p>确认 Ubuntu Linux 版本</p>
<h1 id="cat-etc-issue"><a href="#cat-etc-issue" class="headerlink" title="cat /etc/issue"></a>cat /etc/issue</h1><p>Ubuntu 16.04.4 LTS \n \l</p>
<h1 id="uname-a"><a href="#uname-a" class="headerlink" title="uname -a"></a>uname -a</h1><p>显示更多<br>系统用户<br>我们在学习过程中，几乎所有操作都通过一个专门的用户来完成（在本文示例中，使用的用户名为：fabric；读者可以根据需要使用自己的用户名，但请注意在后续示例中要相应修改）。请不要使用 root 用户。</p>
<p>添加一个新用户</p>
<h1 id="adduser-fabric"><a href="#adduser-fabric" class="headerlink" title="adduser fabric"></a>adduser fabric</h1><p>显示更多<br>将此用户加入 sudo 用户组</p>
<h1 id="usermod-aG-sudo-fabric"><a href="#usermod-aG-sudo-fabric" class="headerlink" title="usermod -aG sudo fabric"></a>usermod -aG sudo fabric</h1><p>显示更多<br>切换为 fabric 用户，并进入用户目录</p>
<h1 id="su-fabric"><a href="#su-fabric" class="headerlink" title="su fabric"></a>su fabric</h1><p>$ cd ~</p>
<p>显示更多<br>安装 Node.js, npm, Docker, Docker Compose, Python<br>现在需要安装 Node.js, Docker 等软件，Hyperledger 提供了一个脚本，可以用来自动安装。</p>
<p>下载并执行自动安装脚本<br>$ curl -O <a href="https://hyperledger.github.io/composer/latest/prereqs-ubuntu.sh">https://hyperledger.github.io/composer/latest/prereqs-ubuntu.sh</a><br>$ chmod u+x prereqs-ubuntu.sh<br>$ ./prereqs-ubuntu.sh</p>
<p>显示较少<br>安装成功后，会显示以下内容，包括安装的软件名称及版本号。（后续版本可能会有变化。）</p>
<p>Installation completed, versions installed are:<br>Node:             v8.11.1<br>npm:              5.8.0<br>Docker:           Docker version 18.03.0-ce, build 0520e24<br>Docker Compose:   docker-compose version 1.13.0, build 1719ceb<br>Python:           Python 2.7.12<br>Please logout then login before continuing.</p>
<p>显示更多<br>退出并重新登录<br>请 退出 当前用户会话， 关闭客户端工具与 Ubuntu 的连接； 并 重新 以用户 fabric 登录 U b untu ， 以 使系统设置生效。</p>
<p>如果是自行手动安装这几项软件但版本号并不完全一致，可能会给后续过程带来一些障碍。所以，为节约时间，请尽量使用这个自动安装脚本；或手动安装这些版本的软件。</p>
<p>使用 Hyperledger Composer 安装 Fabric Runtime<br>现在，终于要正式开始安装 Composer 和 Fabric 了。</p>
<p>安装 Composer<br>Hyperledger Composer 是一个开放的开发框架、工具集，可以帮助人们更容易地开发、部署区块链应用。它支持 Fabric，并提供 Javascript SDK。我们可以通过 npm 来安装它的一系列组件。</p>
<p>安装 Composer 命令行工具 CLI<br>$ npm install -g composer-cli<br>$ npm view composer-cli version<br>0.19.1</p>
<p>显示更多<br>当前，其版本为：0.19.1。</p>
<p>我们之后许多操作（安装、部署、管理）都将通过 Composer CLI 完成。</p>
<p>因为之前的 Node.js 是通过 nvm 安装的（请参考：prereqs-ubuntu.sh），并在这里使用了”-g”选项，所以默认设置下安装的 node modules 文件可以在这里找到：</p>
<p>~/.nvm/versions/node/v8.11.1/lib/node_modules</p>
<p>安装 Composer REST Server<br>$ npm install -g composer-rest-server<br>$ npm view composer-rest-server version<br>0.19.1</p>
<p>显示更多<br>Composer REST server 可以根据我们开发、部署的区块链应用自动生成一些 RESTful API 接口，以方便通过浏览器、curl 等工具对之进行访问。</p>
<p>安装 generator-hyperledger-composer<br>$ npm install -g generator-hyperledger-composer<br>$ npm view generator-hyperledger-composer version<br>0.19.1</p>
<p>显示更多<br>它包含了一组 Yeoman generator，可以在 Yeoman 中执行，以根据模板生成我们将要部署的区块链网络文件。</p>
<p>安装 Yeoman<br>$ npm install -g yo<br>$ npm view yo version<br>2.0.2</p>
<p>显示更多<br>Yeoman 能根据定义好的 generator 迅速生成我们所需要的项目、应用的框架。</p>
<p>安装 Hyperledger Fabric Runtime<br>新建一个 Fabric Tools 目录<br>$ cd ~<br>$ mkdir fabric-tools<br>$ cd fabric-tools/</p>
<p>显示更多<br>fabric-tools 目录是我们以后的工作目录，读者可以按需要改成自己期望的目录名。</p>
<p>下载 Fabric Dev Server<br>$ curl -O <a href="https://raw.githubusercontent.com/hyperledger/composer-">https://raw.githubusercontent.com/hyperledger/composer-</a><br>tools/master/packages/fabric-dev-servers/fabric-dev-servers.tar.gz</p>
<p>显示更多<br>目前，fabric-dev-servers.zip 包含了 Fabric1.0 与 Fabric1.1 的两套安装脚本，及用于初始化的 Fabric 相关配置。解压后文件位于 fabric-tools/fabric-scripts 目录下。</p>
<p>解压 Fabric Dev Server<br>$ tar -xvf fabric-dev-servers.tar.gz</p>
<p>显示更多<br>下载 Fabric Image 文件<br>$ ./downloadFabric.sh</p>
<p>显示更多<br>默认情况下这个脚本最终会执行 fabric-scripts/hlfv11/downloadFabric.sh，hlfv11 表示 Hyperledger Fabric V1.1。这个过程会下载 5 个 docker image 文件，共约 3.6G，视网络情况，可能需要比较长的时间。下载完成后可以通过 docker images 命令查看。</p>
<p>$ docker images<br>REPOSITORY                   TAG             IMAGE ID          CREATED             SIZE<br>hyperledger/fabric-ca        x86_64-1.1.0    72617b4fa9b4      2 weeks ago         299MB<br>hyperledger/fabric-orderer   x86_64-1.1.0    ce0c810df36a      2 weeks ago         180MB<br>hyperledger/fabric-peer      x86_64-1.1.0    b023f9be0771      2 weeks ago         187MB<br>hyperledger/fabric-ccenv     x86_64-1.1.0    c8b4909d8d46      2 weeks ago         1.39GB<br>hyperledger/fabric-couchdb   x86_64-0.4.6    7e73c828fc5b      6 weeks ago         1.56GB</p>
<p>显示更多<br>到这里，我们就非常迅速、方便的完成了 Fabric 的下载，及部署环境的安装，得益于 Docker Container 技术，并不需要我们做复杂的配置。接下来将要开始部署一个示例应用。在之前，我们要先启动 Fabric，并生成 PeerAdmin card。</p>
<p>启动 Fabric<br>$ ./startFabric.sh</p>
<p>显示更多<br>startFabric.sh 最终会执行 ~/fabric-tools/fabric-scripts/hlfv11/startFabric.sh，里面有如下一行内容：</p>
<p>ARCH=$ARCH docker-compose -f “${DOCKER_FILE}” up -d</p>
<p>显示更多<br>打开~/fabric-tools/fabric-scripts/hlfv11/composer/docker-compose.yml 我们可以看到有如下四个 Docker 应用的配置：ca.org1.example.com(CA Node)，orderer.example.com(Orderer Node)，peer0.org1.example.com(Peer Node)，couchdb(Database)。它们启动成功后即意味着 Fabric 区块链网络的核心部分已经处于运行状态了。</p>
<p>在 startFabric.sh 中，还有以下内容：</p>
<p>docker exec peer0.org1.example.com peer channel create……<br>docker exec -e…… peer0.org1.example.com peer channel join……</p>
<p>显示更多<br>它们的作用是建立一个通道（Channel）并将刚启动的节点 peer0.org1.example.com 加入到这个通道。</p>
<p>通道（Channel）是 Fabric 中的重要概念与设计，它是网络成员间通讯的私有的子网络；网络中会有多个通道同时存在；每个交易都在认证、授权后在某个通道里执行；所有数据、交易、成员、通道信息都只对此通道的授权成员可见。</p>
<p>生成并导入 PeerAdmin Card<br>$ ./createPeerAdminCard.sh</p>
<p>显示更多<br>这个脚本会生成一个 Card 文件，它包含了 Fabric 网络的信息以及管理员 PeerAdmin 与之连接所必须的信息；即管理员的身份证明文件；生成后这个文件会被导入到 Composer，你可以在~/.composer/cards/PeerAdmin@hlfv1 目录下找到被导入的 PeerAdmin Card 的文件内容。之后，Composer 会利用这个 Card 文件建立起到 Fabric 网络的连接。</p>
<p>在以后的学习中，我们会介绍如何建立一个自定义的 Card 文件。</p>
<p>部署第一个 Fabric 区块链业务网络<br>Fabric runtime 已经被成功安装、启动了，现在我们要部署第一个 Fabric 区块链业务网络。</p>
<p>准备业务网络<br>为使学习过程更容易，我们直接利用 Yeoman 及已经下载的 Generator 生成区块链网络框架。</p>
<p>在以后的章节中，我们会介绍如何按步骤手工完成定义、部署过程。</p>
<p>生成业务网络定义（Business Network Definition – BND）<br>$ yo hyperledger-composer:businessnetwork</p>
<p>显示更多<br>参数 businessnetwork 来自于之前安装的 generator-hyperledger-composer，表示了一组对应的模板文件。可以在 ~/.nvm/versions/node/v8.11.1/lib/node_modules/generator-hyperledger-composer/generators/businessnetwork/templates/ 下找到即将生成的内容的模板。</p>
<p>运行会提示输入相关信息，为方便学习，建议 Business network name 定义为：tutorial-network；Namespace 定义为：org.example.biznet，其他信息可以自行决定内容。将定义的内容如下：</p>
<p>Business network name: tutorial-network<br>Description: The first blockchain network<br>Author name: Alice<br>Author email: <a href="mailto:&#x61;&#108;&#105;&#99;&#x65;&#x40;&#x6f;&#x72;&#103;&#x2e;&#101;&#x78;&#x61;&#109;&#x70;&#x6c;&#x65;&#46;&#x62;&#105;&#x7a;&#110;&#x65;&#x74;">&#x61;&#108;&#105;&#99;&#x65;&#x40;&#x6f;&#x72;&#103;&#x2e;&#101;&#x78;&#x61;&#109;&#x70;&#x6c;&#x65;&#46;&#x62;&#105;&#x7a;&#110;&#x65;&#x74;</a><br>License: Apache-2.0<br>Namespace: org.example.biznet</p>
<p>显示更多<br>执行成功后，在当前 ~/fabric-tools/ 目录下，新增了一个目录 tutorial-network, 里面有 index.js, package.json 等文件，以及 lib, models 两个目录，这就是将要部署的区块链业务网络定义。</p>
<p>进入 tutorial-network 目录<br>$ cd ~/fabric-tools/tutorial-network</p>
<p>显示更多<br>后续的操作基本都在此目录下完成。</p>
<p>生成 .bna 文件<br>$ composer archive create -t dir -n .</p>
<p>显示更多<br>执行成功后，在当前目录下会产生一个新文件 <a href="mailto:&#x74;&#117;&#x74;&#x6f;&#114;&#x69;&#97;&#x6c;&#x2d;&#x6e;&#x65;&#116;&#x77;&#x6f;&#114;&#x6b;&#64;&#x30;&#x2e;&#x30;&#x2e;&#x31;&#x2e;&#x62;&#110;&#x61;">&#x74;&#117;&#x74;&#x6f;&#114;&#x69;&#97;&#x6c;&#x2d;&#x6e;&#x65;&#116;&#x77;&#x6f;&#114;&#x6b;&#64;&#x30;&#x2e;&#x30;&#x2e;&#x31;&#x2e;&#x62;&#110;&#x61;</a>，即是 tutorial-network 目录下文件的压缩包。解压后发现其中主要有文件及目录：lib/，models/，package.json，permissions.acl。我们会在以后详细解释、操作这些文件。</p>
<p>部署及启动业务网络<br>这是第一个示例区块链网络安装部署的最后一部分内容了。</p>
<p>部署示例业务网络 tutorial-network<br>$ composer network install –card PeerAdmin@hlfv1 –archiveFile <a href="mailto:&#x74;&#117;&#116;&#111;&#x72;&#x69;&#x61;&#108;&#x2d;&#110;&#101;&#116;&#x77;&#x6f;&#x72;&#x6b;&#64;&#48;&#46;&#48;&#x2e;&#49;&#46;&#98;&#110;&#x61;">&#x74;&#117;&#116;&#111;&#x72;&#x69;&#x61;&#108;&#x2d;&#110;&#101;&#116;&#x77;&#x6f;&#x72;&#x6b;&#64;&#48;&#46;&#48;&#x2e;&#49;&#46;&#98;&#110;&#x61;</a></p>
<p>显示更多<br>或者</p>
<p>$ composer network install –c PeerAdmin@hlfv1 –a <a href="mailto:&#116;&#x75;&#x74;&#x6f;&#114;&#x69;&#97;&#x6c;&#45;&#110;&#101;&#116;&#x77;&#x6f;&#114;&#107;&#x40;&#48;&#x2e;&#48;&#46;&#x31;&#x2e;&#98;&#x6e;&#97;">&#116;&#x75;&#x74;&#x6f;&#114;&#x69;&#97;&#x6c;&#45;&#110;&#101;&#116;&#x77;&#x6f;&#114;&#107;&#x40;&#48;&#x2e;&#48;&#46;&#x31;&#x2e;&#98;&#x6e;&#97;</a></p>
<p>显示更多<br>“composer network install” 命令会部署指定的 .bna 文件到 Fabric 网络。.bna 文件包括了这个业务网络的 Assets 模型、交易事务逻辑、访问控制规则等定义，但它并不能直接在 Fabric 上运行。.bna 文件是由 Composer 生成的，它是用 Composer 提供支持的一系列建模语言、规范定义的业务网络定义，我们必须将它先安装在 Fabric Peer 节点上。然后才可以在这个节点上启动运行这个业务网络。</p>
<p>参数 -c (–card) 应指定为在上一步骤中生成 PeerAdmin Card 文件。</p>
<p>参数 -a (–archiveFile) 应指定为将要部署的业务网络文件包。</p>
<p>启动业务网络<br>$ composer network start –networkName tutorial-network –networkVersion 0.0.1 –<br>networkAdmin admin –networkAdminEnrollSecret adminpw –card PeerAdmin@hlfv1 –file<br>networkadmin.card</p>
<p>显示更多<br>“composer network start” 用指定的 Card 启动这个网络；同时会生成一个当前业务网络的管理员 Card 文件，即此示例中的 networkadmin.card。</p>
<p>这个文件是 zip 格式的压缩文件，解压缩后，可以发现包含两个文件：connection.json, metadata.json。其中，metadata.json 内容如下：</p>
<p>{“version”:1,<br>“userName”:”admin”,<br>“businessNetwork”:”tutorial-network”,<br>“enrollmentSecret”:”adminpw”}</p>
<p>显示更多<br>“admin”, “tutorial-network” 正是我们此前的定义的管理员用户名，及业务网络名。我们在以后可以通过类似 -c admin@tutorial-network 使用这个管理员身份。</p>
<p>导入 tutorial-network 管理员 Card<br>$ composer card import –file networkadmin.card</p>
<p>显示更多<br>此时再查看 ~/.composer/cards 会发现新导入的 Card 文件。也可以直接通过命令查看。</p>
<p>查看导入的 Card 文件<br>$ composer card list<br>┌────────────────────────┬───────────┬──────────────────┐<br>│ Card Name              │ UserId    │ Business Network │<br>├────────────────────────┼───────────┼──────────────────┤<br>│ admin@tutorial-network │ admin     │ tutorial-network │<br>├────────────────────────┼───────────┼──────────────────┤<br>│ PeerAdmin@hlfv1        │ PeerAdmin │                  │<br>└────────────────────────┴───────────┴──────────────────┘</p>
<p>显示更多<br>确认 tutorial-network 安装成功<br>$ composer network ping –card admin@tutorial-network</p>
<p>显示更多<br>如果部署成功，会显示类似如下内容：</p>
<p>The connection to the network was successfully tested: tutorial-network<br>Business network version: 0.0.1<br>Composer runtime version: 0.19.1<br>participant: org.hyperledger.composer.system.NetworkAdmin#admin<br>identity: org.hyperledger.composer.system.Identity#…<br>Command succeeded</p>
<p>显示更多<br>启动 REST Server<br>$ composer-rest-server</p>
<p>显示更多<br>并在之后提示的选项中输入内容如下：</p>
<p>Card Name: admin@tutorial-network<br>Never use namespace<br>Enable authentication (default): No<br>Enable event publication over WebSockets (default): Yes<br>Enable TSL (default): No</p>
<p>显示更多<br>也可以直接带参数运行命令行：</p>
<p>$ composer-rest-server -c admin@tutorial-network -n never</p>
<p>显示更多<br>composer-rest-server 会根据部署的业务网络生成一系列 REST API,以方便用户通过浏览器或其他类似 curl 的应用程序访问这个区块链业务网络。如果在本机，我们可以通过这样的地址访问：</p>
<p><a href="http://localhost:3000/explorer%E3%80%82">http://localhost:3000/explorer。</a></p>
<p>部署成功<br>到这里，我们就成功地通过 Hyperledger Composer 安装了 Hyperledger Fabric，并部署、启动了第一个区块链业务网络 tutorial-network。</p>
<p>访问区块链网络<br>现在我们可以开始访问部署成功的第一个 Fabric 区块链业务网络。</p>
<p>本文主要介绍通过浏览器和 curl 命令访问 REST Service。</p>
<p>通过浏览器访问 REST Service<br>在浏览器中输入 <a href="http://fabric11dev1:3000/explorer%E3%80%82">http://fabric11dev1:3000/explorer。</a></p>
<p>fabric11dev1 是当前部署运行 Composer REST Server 的机器名。如果从本机访问，可以使用 localhost， 或者 直接使用 IP 地址访问。后文不再对此特别说明。</p>
<p>图 1. 入口界面<br>入口界面</p>
<p>SampleAsset 是这个区块链业务网络中定义的资产模型 (Asset)。表示一种有形或无形的可改变、转移的商品。</p>
<p>SampleParticipant 是这个业务网络的成员 (Participant)，可以拥有 Asset，提交 Transaction。</p>
<p>SampleTransaction 是一种交易或事务 (Transaction)，由成员提交到业务网络，用以改变、转移商品，或触发其他操作。</p>
<p>这些内容都可点击展开，显示 REST API 中对于此项内容的所有操作。</p>
<p>图 2. Participant 操作<br>Participant 操作</p>
<p>点击 GET ， POST 等按钮，可以进行展开并进行各种操作。</p>
<p>点击 POST 按钮，可添加一个新的 SampleParticipant。</p>
<p>图 3. 添加 SampleParticipant<br>添加 SampleParticipant</p>
<p>在 data 输入框中，输入如下内容：</p>
<p>{<br>“$class”: “org.example.biznet.SampleParticipant”,<br>“participantId”: “SP_1”,<br>“firstName”: “Alice”,<br>“lastName”: “Fabric”<br>}</p>
<p>显示更多<br>“org.example.biznet.SampleParticipant” 是将要添加 Participant 的模型名称；”SP_1″ 是当前业务网络中这种实例的唯一 ID。</p>
<p>我们会在以后详细分析这个模型的定义方法。</p>
<p>点击 Try it out! 按钮，REST Service 会向这个区块链业务网络添加新的 SampleParticipant。如果添加成功，会在界面下方显示 “Response Code 200” 类似的输出内容。</p>
<p>添加成功后，再点击第一个操作 GET ，展开后点击 Try it out! 按钮，即可列出所有 SampleParticipant。</p>
<p>图 4. 列出所有 SampleParticipant<br>列出所有 SampleParticipant</p>
<p>图 5. Asset 操作<br>Asset 操作</p>
<p>点击 GET ， POST 等按钮，可以进行 SampleAsset 各种操作。</p>
<p>点击 POST 按钮，可添加一个新的 SampleAsset。</p>
<p>图 6. 添加一个新的 SampleAsset<br>添加一个新的 SampleAsset</p>
<p>在 data 输入框中，输入如下内容：</p>
<p>{<br>“$class”: “org.example.biznet.SampleAsset”,<br>“assetId”: “SA_1”,<br>“owner”: “org.example.biznet.SampleParticipant#SP_1”,<br>“value”: “$100”<br>}</p>
<p>显示更多<br>“org.example.biznet.SampleAsset” 是将要添加实例的模型名；”SA_1″ 是当前业务网络中这种实例的唯一 ID。”org.example.biznet.SampleParticipant#SP_1″ 是对于之前建立的 ID 为 SP_1 的 SampleParticipant 的引用。</p>
<p>我们会在以后详细分析这个模型的定义方法。</p>
<p>点击 Try it out! 按钮，REST Service 会向这个区块链业务网络添加新的 SampleAsset。如果添加成功，会在界面下方显示 “Response Code 200” 类似的输出内容。</p>
<p>按此方法，我们可以再添加另一个 SampleAsset，其 ID 为 SA_2。</p>
<p>添加成功后，再点击第一个操作 GET ，展开后点击 Try it out! 按钮，即可列出所有 SampleAsset。</p>
<p>图 7. 列出所有 SampleAsset<br>列出所有 SampleAsset</p>
<p>在 Response Body 中，可以发现以 JSON 格式列出的所有 SampleAsset 实例。</p>
<p>图 8. 交易（Transaction）操作<br>交易（Transaction）操作</p>
<p>点击 GET ， POST 等按钮，可以进行交易的各种操作。</p>
<p>点击 POST 按钮，可提交一个新的交易。</p>
<p>图 9. 提交交易（Transaction）<br>提交交易（Transaction）</p>
<p>在 data 输入框中输入以下内容：</p>
<p>{<br>“$class”: “org.example.biznet.SampleTransaction”,<br>“asset”: “org.example.biznet.SampleAsset#SA_1”,<br>“newValue”: “$105”<br>}</p>
<p>显示更多<br>“org.example.biznet.SampleTransaction” 是将要提交的交易模型名称；”org.example.biznet. SampleTransaction#SA_1″ 是之前添加的 SampleAsset 实例的引用；newValue”$105″ 是指将这个 SampleAsset 实例中的 value 改成新的值 “$105″。</p>
<p>点击 Try it out! 按钮，REST Service 会向这个区块链业务网络提交这个交易。如果提交成功，会在界面下方显示 “Response Code 200” 类似的输出内容。</p>
<p>提交成功后，我们再次操作 SampleAsset – GET， 即可发现 SampleAsset#SA_1 的 value 已经被改为 “$105″。</p>
<p>“newValue” 这个操作的具体逻辑是在 ~/fabric-tools/tutorial-network/lib/logic.js 中定义的。其中所使用的 API，如 getAssetRegistry、getFactory 正是 Composer 提供的 Javascript API，这段 JS 会由被先前安装部署在 Peer 上的 Composer 业务网络执行。</p>
<p>在 SampleTransaction – GET 中，点击 Try it out! ，即可列出所有提交成功的交易。</p>
<p>图 10. 列出所有交易<br>列出所有交易</p>
<p>这里，每个交易比之前提交的内容，多了 transactionId, timestamp 两个内容，这是 tutorial-network 在处理交易时自动添加的。</p>
<p>图 11. System 操作<br>System 操作</p>
<p>通过 System – GET /system/historian 操作，可以列出这个业务网络的历史操作记录。部分内容如下：</p>
<p>[<br>{<br>“$class”: “org.hyperledger.composer.system.HistorianRecord”,<br>“transactionId”: “0d5eaeb63fe045505b1ff6d45083f6f7703a8ad7e6f2dd3b86190fab212ca0aa”,<br>“transactionType”: “org.hyperledger.composer.system.AddAsset”,<br>“transactionInvoked”:<br>“resource:org.hyperledger.composer.system.AddAsset#0d5eaeb63fe045505b1ff6d45083f6f7703a8ad7e6f2dd3b86190fab212ca0aa”,<br>“participantInvoking”: “resource:org.hyperledger.composer.system.NetworkAdmin#admin”,<br>“identityUsed”:<br>“resource:org.hyperledger.composer.system.Identity#0b0c50ab485d4b849a3050fcf630211ea4c9edb26c9e2b3308a1df4dc3dc77d6”,<br>“eventsEmitted”: [],<br>“transactionTimestamp”: “2018-03-31T10:09:24.709Z”<br>},<br>{<br>“$class”: “org.hyperledger.composer.system.HistorianRecord”,<br>“transactionId”: “6dcb8eb6-34aa-4b6e-95f6-08dc0b7285fb”,<br>“transactionType”: “org.hyperledger.composer.system.StartBusinessNetwork”,<br>“transactionInvoked”:<br>“resource:org.hyperledger.composer.system.StartBusinessNetwork#6dcb8eb6-34aa-4b6e-95f6-08dc0b7285fb”,<br>“eventsEmitted”: [],<br>“transactionTimestamp”: “2018-03-31T06:04:06.500Z”<br>},<br>{<br>“$class”: “org.hyperledger.composer.system.HistorianRecord”,<br>“transactionId”: “57b5004a3f865c84a2d298ec2d37bf3d1113ed61efad62055d11f1da0e3d2c1f”,<br>“transactionType”: “org.example.biznet.SampleTransaction”,<br>“transactionInvoked”:<br>“resource:org.example.biznet.SampleTransaction#57b5004a3f865c84a2d298ec2d37bf3d1113ed61efad62055d11f1da0e3d2c1f”,<br>“participantInvoking”: “resource:org.hyperledger.composer.system.NetworkAdmin#admin”,<br>“identityUsed”:<br>“resource:org.hyperledger.composer.system.Identity#0b0c50ab485d4b849a3050fcf630211ea4c9edb26c9e2b3308a1df4dc3dc77d6”,<br>“eventsEmitted”: [<br>{<br>“$class”: “org.example.biznet.SampleEvent”,<br>“asset”: “resource:org.example.biznet.SampleAsset#SA_1”,<br>“oldValue”: “$100”,<br>“newValue”: “$105”,<br>“eventId”: “57b5004a3f865c84a2d298ec2d37bf3d1113ed61efad62055d11f1da0e3d2c1f#0”,<br>“timestamp”: “2018-03-31T10:14:31.353Z”<br>}<br>],<br>“transactionTimestamp”: “2018-03-31T10:14:31.353Z”<br>},<br>{<br>“$class”: “org.hyperledger.composer.system.HistorianRecord”,<br>“transactionId”: “cd87d7c3940a2bc96d640cbf53a35f6a4fbcf3be5c953667428084ef5b02dabf”,<br>“transactionType”: “org.hyperledger.composer.system.AddParticipant”,<br>“transactionInvoked”:<br>“resource:org.hyperledger.composer.system.AddParticipant#cd87d7c3940a2bc96d640cbf53a35f6a4fbcf3be5c953667428084ef5b02dabf”,<br>“participantInvoking”: “resource:org.hyperledger.composer.system.NetworkAdmin#admin”,<br>“identityUsed”:<br>“resource:org.hyperledger.composer.system.Identity#0b0c50ab485d4b849a3050fcf630211ea4c9edb26c9e2b3308a1df4dc3dc77d6”,<br>“eventsEmitted”: [],<br>“transactionTimestamp”: “2018-03-31T10:00:32.858Z”<br>}<br>]</p>
<p>显示更多<br>示例中有 3 个操作：AddAsset, AddParticipant, SampleTransaction, StartBusinessNetwork。</p>
<p>其中 SampleTransaction 是我们之前手工提交的 Transaction；而 AddAsset, AddParticipant, StartBusinessNetwork 则是业务网络自己产生的事务操作历史记录。由此我们可以知道，当前 tutorial-network 中的一些操作（如：添加 SampleAsset）其实是通过一系列 Composer 模型语言定义了一个操作，由 Composer 提交到 Fabric Peer Node，最终由业务网络执行完成的，即智能合约（Smart Contract）在 Fabric 中的实现：Chaincode。我们会在后续学习中深入理解这种机制。</p>
<p>按上述方法，我们们可以浏览这个简单的区块链网络所提供服务的所有 REST API。</p>
<p>使用 curl 访问 REST Service<br>以上介绍的在浏览器中对 REST Service 及区块链网络的访问，都可以通过 curl 及其他类似应用程序，通过控制台进行。</p>
<p>使用 curl 程序调用 REST API – GET SampleAsset<br>$ curl -X GET –header ‘Accept: application/json’<br>‘<a href="http://fabric11dev1:3000/api/SampleAsset&#39;">http://fabric11dev1:3000/api/SampleAsset&#39;</a></p>
<p>显示更多<br>为方便起见，这里并没有指定任何用户信息，因为目前没有加入安全验证机制，我们会在以后的学习中专门讨论用户安全、权限控制问题。</p>
<p>执行成功后，会返回 JSON 格式的文本。</p>
<p>使用 curl 程序调用 REST API – POST SampleTransaction<br>$ curl -X POST –header ‘Content-Type: application/json’ –header ‘Accept:<br>application/json’ -d ‘{<br>“$class”: “org.example.biznet.SampleTransaction”,<br>“asset”: “org.example.biznet.SampleAsset#SA_1”,<br>“newValue”: “$110”<br>}’ ‘<a href="http://fabric11dev1:3000/api/SampleTransaction&#39;">http://fabric11dev1:3000/api/SampleTransaction&#39;</a></p>
<p>显示更多<br>结语<br>我们一起学习了 Hyperledger Fabric，Composer 的基本概念，并使用 Composer 部署了一个 Fabric 开发环境，安装并运行了第一个区块链业务网络与应用。最后通过 REST Service 访问了这个区块链应用。</p>
<p>本文对于 Fabric 的的学习内容还是初步的，旨在帮助大家迅速建立对 Fabric 的直观映像，以便为下一步深入研究打好基础。</p>
<p>参考资源<br>参考 IBM Blockchain Dev Center ，查看 IBM 在区块链领域的最新信息。<br>参考 Hyperledger Projects ，了解开源项目 Hyperledger 的主要内容。<br>参考 Hyperledger Fabric Documentation ，了解开源项目 Fabric 的主要内容。<br>阅读相关 Code Pattern: 使用 Hyperledger Composer 处理事务事件<br><a href="https://developer.ibm.com/zh/tutorials/cl-lo-hyperledger-fabric-study-notes1/">link</a></p>
]]></content>
      <categories>
        <category>block chain</category>
      </categories>
      <tags>
        <tag>block chain</tag>
      </tags>
  </entry>
  <entry>
    <title>Mongodb 笔记07 分片、配置分片、选择片键、分片管理</title>
    <url>/2020/08/03/45008/</url>
    <content><![CDATA[<h2 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h2><ol>
<li><p>分片(sharding)是指将数据拆分，将其分散存放在不同的机器上的过程。有时也用分区(partitioning)来表示这个概念。将数据分散到不同的机器上，不需要功能强大的大型计算机就可以</p>
<p> 存储更多的数据，处理更大的负载。</p>
</li>
<li><p>MongoDB支持自动分片(autosharding)，可以使数据库架构对应用程序不可见，也可以简化系统管理。对应用程序而言，好像始终在使用一个单机的MongoDB服务器一样。另一方面，</p>
<p> mongoDB自动处理数据在分片上的分布，也更容易添加和删除分片技术。</p>
<a id="more"></a></li>
<li><p>复制与分片的区别：复制时让多台服务器都拥有同样的数据副本，每一台服务器都是其他服务器的镜像，而每一个分片都和其他分片拥有不同的数据子集。</p>
</li>
<li><p>路由服务器：为了对应用程序隐藏数据库架构的细节，在分片之前要先执行mongos进行一次路由过程。这个路由服务器维护这一个”内容列表”，指明了每个分片包含什么数据内容。应用</p>
<p> 程序只需要连接路由服务器，就可以像使用单机一样进行正常的请求了。</p>
</li>
<li><p>运行sh.status()可以看到集群的状态：分片摘要信心、数据库摘要信息、集合摘要信息。</p>
</li>
<li><p>要对一个集合分片，首先你要对这个集合的数据库启用分片，执行如下命令：sh.enableSharding(“test”)</p>
</li>
<li><p>片键：片键是集合的一个键，MongoDB根据这个键拆分数据。例如：username 。在启用分片之前，先在希望作为片键的键上创建索引：db.users.ensureIndex({“username”:1})</p>
</li>
<li><p>对集合分片：sh.shardCollection(“test.users”,{“username”:1})</p>
</li>
<li><p>集合被拆分为多个数据块，每个数据块都是集合的一个数据子集。这是按照片键的范围排列的({“username”:minValue}–&gt;&gt;{“username”:maxValue}指出了每个数据块的范围)。</p>
</li>
<li><p>包含片键的查询能够直接被发送到目标分片或者是集群分片的一个子集。这样的查询叫做定向查询(targetd query)。有些查询必须被发送到所有分片，这样的查询叫做分散-聚合查询(</p>
<p>  scatter-gather query);mongos将查询分散到所有的分片上，然后经各个分片的查询结果聚集起来。</p>
</li>
<li><p>cluster.stop() 关闭整个集群。</p>
</li>
</ol>
<h2 id="BSON类型"><a href="#BSON类型" class="headerlink" title="BSON类型"></a>BSON类型</h2><h2 id="配置分片："><a href="#配置分片：" class="headerlink" title="配置分片："></a>配置分片：</h2><ol>
<li><p>何时进行分片：决定何时分片是一个值得权衡的问题。通常不必太早分片，因为分片不仅会增加部署的操作复杂度，还要求做出设计决策，而改决策以后很难再改。另外最好也不要在系统</p>
<p> 运行太久之后再分片，因为在一个过载的系统上不停机进行分配是很困难的。</p>
</li>
<li><p>分片的目的：增加可用的RAM，增加可用磁盘空间，减轻单台服务器的负载，处理单个mongod无法承受的吞吐量。</p>
</li>
<li><p>一般情况下至少应该创建3个或者以上的分片。</p>
</li>
<li><p>启动服务器：</p>
<p> 1). 配置服务器：配置服务器相当于集群的大脑，保存着集群和分片的元数据，即各分片包含哪些数据的信息。因此，应该首先建立配置服务器，鉴于它所包含的的数据极端重要性，必须启用</p>
<pre><code>  其日志功能，并确保其数据保存在非易失性驱动器上。每个配置服务器都应该位于单独的物理机上，最好是分布在不同地址位置的机器上。

  a. 启动配置服务器：mongod --configsvr --dbpath  /var/lib/mongodb -f  /var/lib/config/mognd.conf  。需要启动三台配置服务器，且都是可写的。

      为什么是3台配置服务器？因为我们需要考虑不时之需。但是，也不需要过多的配置服务器，因为配置服务器上的确认操作比较耗时。另外，如果有服务器宕机了，集群源数据就会变成只读的。

      --configsvr 选项指定mongod为新配置服务器。该选项并非必选项，因为它所做的不过是将mongod的默认监听端口改为27019，并大默认的数据目录改为/data/configdb而已(可以使用

      --port 和 --dbpath 选项修改这两项配置)。但建议使用--configsvr选项，因为它比价直白地说明了这些配置服务器的用途。

      配置服务器的1KB相当于200MB知识数据，它保存的真实数据的分布表。由于配置服务器并不需要太多的资源，因此可以将其部署在运行着其他程序的服务器上。 </code></pre>
<p> 2). mongos进程：三个配置服务器均处于运行状态后，启动一个mongos进程供应用程序连接。mongos进程需要配置服务器的地址，所以必须使用–configdb选项启动mongos:</p>
<pre><code>   mongos --configdb config-1:27019,config-2:27019,config-3:27019 -f /var/lib/mongos.conf

   默认情况下，mongos运行在27017端口。mongos本身不保存数据，它会在启动时从配置服务器加载集群数据。

   可以启动任意数量的mongos进程。通常的设置时每个应用程序服务器使用一个mongos进程(与应用服务器运行在同一台机器上)

   每个mongos进程必须按照列表排序，使用相同的配置服务器列表。</code></pre>
<p> 3). 将副本集转换为分片：有两种可能性：已经有一个副本集，或者从零开始建立集群。下例假设我们已经拥有了一个副本集。如果是从零开始的话，可先初始化一个空的副本集，然后按照本例操作。</p>
<pre><code>  a. 告知mongos副本集名称和副本集成员列表：sh.addShard(&quot;spock/server-1:27017,server-2:27017,server-4:27017&quot;)  mongos能够自动检测到没有包含在副本集成员表中的成员。

  b. 副本集作为分片添加到集群后，就可以将应用程序设置从连接到副本集改为连接到mongos。

  c. 副本集名称spokc被作为分片名称。如果之后希望移除这个分片或者是向这个分片迁移数据，可以使用spock来标志这个分片。

  d. 配置完分片后，必须将客户端设置为将所有请求发送到mongos，而不是副本集。同时配置防火墙规则，以确保客户端不能直接将请求发送到分片。

  e. 有一个--shardsvr选项，与前面介绍的--configsvr选项类似，它也没什么实用性(只是将默认端口改为27018)，但在操作中建议使用该选项。

  f. 不建议创建单mongod服务器分片(而不是副本集分片)，将单一服务器分片转换为副本集需要停机操作。</code></pre>
<p> 4). 增加集群容量：通过增加分片来增加集群容量。</p>
<p> 5). 数据分片：除非明确指定规则，否则MongoDB不会自动对数据进行拆分。如果有必要，必须明确告知数据库和集合。加入对music数据库中的artists集合按照name进行分片，</p>
<pre><code>   db.enableSharding(&quot;music&quot;)         对数据库分片是对集合分片的先决条件

   sh.shardCollection(&quot;music.artists&quot;,&#123;&quot;name&quot;:1&#125;)   对集合分片，集合会按照name键进行分片。如果是对已存在的集合分片，那么name键上必须有索引，否则会返回错误。

   shardCollection()命令会经集合拆分为多个数据块，这是MongoDB迁移数据的基本单元。命令执行后，MongoDB会均衡的将数据分散到集群的分片上。</code></pre>
</li>
<li><p>MongoDB如何追踪集群数据</p>
<p> 1). MongoDB将文档分组为块(chunk)，每个块由给定片键特定范围内的文档组成。一个块只存在于一个分片上，所以MongoDB用一个比较小的表就能够维护跟分片的映射。</p>
<p> 2). 当一个块增长到特定大小时，MongoDB会自动将其拆分为两个较小的块。</p>
<p> 3). 一个常见的误解释同一个块内的数据保存在磁盘的同一片区域。这是不正确的，块并不影响mongod保存集合数据的方式。</p>
<p> 4). 块信息保存在config.chunks集合中。左闭右开。</p>
<p> 5). 可以使用复合片键，工作方式与使用复合索引进行排序一样。</p>
<p> 6). 拆分块：mongos会记录在每个块中插入了多少数据，一旦达到某个阈值，就会检查是否需要对块进行拆分。mongos就会在配置服务器更新这个块的源信息。块拆分中只需要改变块源数据即可，</p>
<pre><code>  而无需进行数据移动。进行拆分时，配置服务器会创建新的块文档，同时修改旧的块范围，拆分完成以后，mongos会重置对原始块的追踪器，同时为新的块创建新的追踪器。</code></pre>
<p> 7). 分片有时可能会找不到任何可用的拆分点，因为合法拆分块方法有限。具有相同片键的文档必须保存在相同的块中。</p>
<p> 8). 如果mongos试图进行拆分时有一个服务器挂了，那么mongos就无法更新源数据。mongos不断重复发起拆分请求却无法进行拆分的过程，叫做拆分风暴。防止拆分风暴的唯一方法是尽可能保证</p>
<pre><code>  配置服务器的可用和健康。也可以重启mongos，重置引入计数器，这样他就不会再处于拆分阈值点了。</code></pre>
<p> 9). 如果mongos进程不断重启，它们的计数器可能永远也不会到达阈值点，因此块的增加不存在最大值，也就无法到达阈值点。</p>
<p> 10). 防止无法拆分的两种方法：一是减少mongos进程的波动，二是使块的大小比实际预期小一些，这样就更容易达到拆分阈值点。</p>
<p> 11). 可以在mongos启动时指定–nosplit选项，从而关闭块的拆分。</p>
</li>
<li><p>均衡器：均衡器负责数据的迁移。它会周期性地检查分片间是否存在不均衡，如果存在，则会开始块的迁移。虽然均衡器通常被看成单一的实体，但每个mongos有时也会扮演均衡器的角色。</p>
<p> 每隔几秒，mongos就会尝试变身均衡器。如果没有其他可用的均衡器，mongos就会对整个集群加锁，以防止配置服务器对整个集群进行修改，然后做一次均衡。</p>
<p> mongos成为均衡器后，就会检查每个集合的分块表，从而查看是否有分片达到了均衡阈值。</p>
</li>
</ol>
<p>选择片键</p>
<ol>
<li><p>对集合进行分片时，要选择一或两个字段用于拆分数据，这个键就叫做片键。</p>
</li>
<li><p>拆分数据最常用的数据分发方式有三种：升序片键、随机分发的片键和基于位置的片键。</p>
<p> 1). 升序片键：升序片键通常有点类似于”date”字段或者是ObjectId，是一种随着时间稳定增长的字段。缺点：例如ObjectId可能会导致接下来的所有的写入操作都在同一块分片上。</p>
<p> 2). 随机分发的片键：随机分发的片键可以是用户名，邮件地址，UDID，MD5散列值或者数据集中其他一些没有规律的键。缺点：MongoDB在随机访问超出RAM大小的数据时效率不高。</p>
<p> 3). 基于位置的片键：基于位置的片键可以是用户的IP、经纬度、或者地址。这里的”位置”比较抽象，不必与实际的物理位置字段相关。</p>
<pre><code>  如果希望特定范围内的块出现在特定的分片中，可以为分片添加tag，然后为块指定相应的tag</code></pre>
</li>
<li><p>片键策略：</p>
<p> 1). 散列片键：如果追求的是数据加载速度的极致，那么散列片键是最佳选择。散列片键可使其他任何键随机分发，因此，如果打算在大量查询中使用使用升序键，但同时又希望写入数据随机分发的话，</p>
<pre><code>  散列片键会是一个非常好的选择。缺点：无法使用散列片键做指定目标的范围查找。  

  创建步骤： db.users.ensureIndex(&#123;&quot;username&quot;:&quot;hashed&quot;&#125;)   ,   sh.shardCollection(&quot;app.users&quot;,&#123;&quot;username&quot;:&quot;hashed&quot;&#125;)</code></pre>
<p> 2). GridFS的散列片键</p>
<p> 3). 流水策略：如果有一些服务器比其他服务器更强大，我们可能希望让这些强大的服务器处理更多的负载。比如说：加入有一个使用SSD的分片能够处理10倍于其他机器的负载。我们可以强制将所有新数据</p>
<pre><code>  插入到SSD，然后让均衡器将旧的块移动到其他分片上。

  a. 为SSD指定一个标签：sh.addShardTag(&quot;shard-name&quot;,&quot;ssd&quot;)

  b. 将升序键的当前值一直到正无穷范围的块都指定分布在SSD分片上：sh.addTagRange(&quot;dbName.collName&quot;,&#123;&quot;_id&quot;:ObjectId()&#125;,...&#123;&quot;_id&quot;:MaxKey&#125;,&quot;ssd&quot;) 

      所有插入请求均会路由到这个块上，这个块始终位于标签的ssd的分片上。

  c. 除非修改标签范围，否则从升序键的当前值一直到正无穷都被固定在这个分片上。可以创建一个定时任务每天更新一次标签范围：

      use config

      var tag =db.tags.findOne(&#123;&quot;ns&quot;:&quot;dbName.collName&quot;,...&quot;max&quot;:&#123;&quot;shardKey&quot;:MaxKey&#125;&#125;)

      tag.min.shardKey = ObjectId()

      db.tags.save(tag)

      这样前一天的数据就会被移动到其他分片上了。

      此策略的另一个缺点：需要修改才能进行扩展。如果写请求超出了SSD的处理能力，无法进行负载均衡。

 4). 多热点：写请求分布在集群中时，分片是最高效的。这种技术会创建多个热点(最好在每个分片上都创建几个热点)，写请求于是会均衡地分布在集群内，而在单个分片上则是以升序分布的。

                 为了实现这种方式，需使用复合片键。复合片键中的第一个值只是比较粗略的随机值，势也比较低。</code></pre>
</li>
<li><p>片键规则和指导方针：</p>
<p> 1). 片键限制：片键不可以是数组。文档一旦插入，其片键就无法修改了。要修改文档的片键值，就必须先删除文档。</p>
<p> 2). 片键的势：选择一个值会变化的的键非常重要，即值很多，随着数据量的增大可以分出更多的片键。分片在势比较高的字段上性能更佳。</p>
</li>
<li><p>控制数据分发</p>
<p> 1). 对多个数据库和集合使用一个集群：通过tag标记，将重要的数据放到性能更好的服务器上，将不重要的数据放在性能一般的服务器上。</p>
<p> 2). 手动分片：如果不希望数据被自动分发，可以关闭均衡器，使用moveChunk命令手动对数据进行迁移。</p>
</li>
</ol>
<p>分片管理</p>
<ol>
<li><p>检查集群状态：</p>
<p> 1). 使用sh.status查看集群摘要信息: 块的数量比较多时，sh.status()命令会概述块的状态，而非打印出每个块的相关信息。如需查看所有的块，可使用sh.status(true)命令。</p>
<pre><code>  sh.status()显示的所有信息都来自config数据库。运行sh.status()命令，使用MapReduce获取这一数据。因此，如果启动数据库时指定--noscripting选项，则无法运行sh.status()命令。</code></pre>
<p> 2). 检查配置信息：</p>
<pre><code>  a. 集群相关的所有配置信息都保存在配置服务器上config数据库的集合中。可以直接访问该数据库，不过shell提供了一些辅助函数。

  b. 永远不要直接连接到配置服务器，以防止配置服务器数据被不小心修改或删除。应该先连接到mongos，然后通过config数据库来查询相关信息：use config

      如果通过mongos操作配置数据，mongos会保证将修改同步到所有配置服务器，也会防止危险的操作发生，如意外删除config数据库等。

  c. 总的来说，不应直接修改config数据库中的任何数据。如果确实修改了某些数据，通常需要重启所有的mongos服务器，才能看到效果。

  d. config中几个关键集合：

      shards : 跟踪记录集群中所有分片的信息。

      databases: 跟踪记录集群中所有数据库的信息，不管数据库有没有分片。

      collections: 跟踪记录所有分片集合的信息(非分片集合信息除外)

      chunks: 记录集合中所有块的信息。

      changelog: 跟踪记录集群的操作，因为该集合会记录所有拆分和迁移的操作。

      tags: 该集合的创建是在为系统配置分片标签时发生的。每个标签都与一个块范围相关联。

      settings: 该集合含有当前的均衡器设置和块大小的文档信息。通过修改该集合的文档，可开启和关闭均衡器，也可以修改块的大小。注意，应总是连接到mongos修改该集合的值。</code></pre>
</li>
<li><p>查看网络连接：</p>
<p> 1). 查看连接统计：可以使用connPoolStats命令，查看mongos和mongod之间的连接信息：db.adminCommand({“connPoolStats”:1})</p>
<pre><code>                     在一个分片上执行connPoolStats，输出信息中可以看到该分片与其他分片间的连接，包括连接到其他分片做数据迁移的连接。</code></pre>
<p> 2). 限制连接数量： 可在mongos的命令行配置中使用maxConns选项，这样可以限制mongos能够创建的连接数量。可以使用下面公式计算分片能够处理的来自单一mongos连接数量：</p>
<pre><code>                       maxConns = 20000 - (mongos进程的数量 * 3 ) - (每个副本集的成员数量 * 3 ) - (其他/mongos进程的数量)

                       MongoDB如果没有安全退出，那些已经打开的套接字很可能没有被关闭。

                       在出现大量重新连接时，除了重启进程，没有其他特殊有效的方法。</code></pre>
</li>
<li><p>服务器管理</p>
<p> 1). 添加服务器：使用addShard命令，向集群中添加新的分片</p>
<p> 2). 修改分片的服务器：要修改分片的成员，需直接连接到分片的主服务器上，然后对副本集进行重新配置。集群配置会自动检测更改，并将其更新到config.shards上。</p>
<p> 3). 通常来说，不应从集群中删除分片。执行removeShard命令排除数据和查看排出进度。</p>
<p> 4). 修改配置服务器：修改配置服务器非常困难，而且有风险，通常还需要停机。注意，修改配置服务器前，应做好备份。</p>
<pre><code>                         首先必须关闭所有mongos进程，然后使用新的--configdb参数重启所有mongos进程。</code></pre>
</li>
<li><p>数据均衡：</p>
<p> 1). 均衡器：均衡器只使用块的数量，而非数据大小，作为衡量分片间是否均衡的指标。自动均衡总是根据数据集的当前状态来决定数据迁移，而不考虑数据集历史状态。我们可以手动均衡数据集块的数量。</p>
<p> 2). 修改块的大小：块的大小默认为64M，这个大小的块既易于迁移，又不至于导致过多的流失。使用shell连接到mongos，修改config.setting集合，从而完成块大小的修改。</p>
<pre><code>   该设置的有效范围是整个集群：它会影响所有集合的数据库。因此，如需对一个集合使用较小的块，而对另一个集合使用较大的块，比较好的解决方式是取一个折中值(或者将这两个值放到不同的集合中)。

   如果MongoDB频繁进行数据迁移或文档增大，则可能需要增加块的大小。</code></pre>
<p> 3). 迁移块：同一块内的所有数据都位于同一分片上。如该分片的块数量比其他分片多，则MongoDB会将其中的一部分块迁移到其他块数量较少的分片上。移动快的过程叫迁移，MongoDB就是这样在集群中</p>
<pre><code>  实现数据均衡的。可在shell中使用moveChunk辅助函数，手动移动块。

  如果某个块的大小超出了系统指定的最大值，mongos则会拒绝移动这个块。移动之前必须先手动拆分这个块，可以使用splitAt命令对块进行拆分。特大块，无法被拆分。</code></pre>
<p> 4). 特大块：某些片键，值比较少，例如：日期等。可能会形成超出设置的最大块大小的块，这种块成为特大块.</p>
<pre><code>  出现特大块的表现之一是，某个分片的大小增长速度要比其他分片块的多。也可使用sh.status()来检查是否出现了特大块；特大块会存在一个jumbo属性。

  a. 分发特大块，一个复杂的过程

  b. 防止特大块的出现：修改片键，细化片键的粒度</code></pre>
<p> 5). mongos有时无法从配置服务器正确更新配置。如果发现配置有误，mongos的配置过旧或无法找到应有的数据，可以使用flushRouterConfig命令手动刷新所有缓存：db.adminCommand({“flushRouterConfig”:1})</p>
<pre><code>  如flushRouterConfig命令没能解决问题，则应重启所有的mongos或者mongod进程，以便清除所有可能的缓存。     </code></pre>
<p><a href="https://www.cnblogs.com/jtianlin/p/5128977.html">link</a><br><a href="https://cloud.tencent.com/developer/article/1451897">mongodb分片模式分片键的选择</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>mongo</category>
      </categories>
      <tags>
        <tag>mongo</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>pyppeteer使用及docker中产生大量僵尸进程的解决方法</title>
    <url>/2020/07/23/40298/</url>
    <content><![CDATA[<h3 id="pyppeteer简介"><a href="#pyppeteer简介" class="headerlink" title="pyppeteer简介"></a>pyppeteer简介</h3><p>Puppeteer(中文翻译”操纵木偶的人”) 是 Google Chrome 团队官方的无界面（Headless）Chrome 工具，它是一个 Node 库，提供了一个高级的 API 来控制 DevTools协议上的无头版 Chrome 。也可以配置为使用完整（非无头）的 Chrome。Chrome 素来在浏览器界稳执牛耳，因此，Chrome Headless 必将成为 web 应用自动化测试的行业标杆。使用 Puppeteer，相当于同时具有 Linux 和 Chrome 双端的操作能力，应用场景可谓非常之多。此仓库的建立，即是尝试各种折腾使用 GoogleChrome Puppeteer；以期在好玩的同时，学到更多有意思的操作。<br>而pyppeteer 是对无头浏览器 puppeteer的 Python 封装，可以让你使用python来操作Chrome。</p>
<p><a href="https://www.lagou.com/lgeduarticle/github.com/miyakogi/pyppeteer">Pyppeteer的GIT</a><br><a href="https://miyakogi.github.io/pyppeteer/reference.html">Pyppeteer官方文档</a></p>
<p>使用过程中的问题<br>pyppeteer api提供的close（）命令无法真正的关闭浏览器，会造成很多的僵尸进程<br>websockets 版本太高导致报错pyppeteer.errors.NetworkError: Protocol error Network.getCookies: Target close<br>chromium浏览器多开页面卡死问题<br>浏览器窗口很大，内容显示很小的问题<br>pyppeteer使用</p>
<h3 id="pyppeteer安装"><a href="#pyppeteer安装" class="headerlink" title="pyppeteer安装"></a>pyppeteer安装</h3><pre><code class="bash">python3 -m pip install pyppeteer
</code></pre>
<p>在初次使用pyppeteer的时候他会自动下载chromium（看心情，大部分情况下可以用龟速形容），或者直接去官网下载最新版的浏览器然后在代码中指定浏览器的路径。<br><a href="https://download-chromium.appspot.com/">chromium下载地址</a></p>
<p>简单入门</p>
<pre><code class="bash">import asynciofrom pyppeteer import launch

async def main():
    # 创建一个浏览器
    browser = await launch(&#123;
        &#39;executablePath&#39;: &#39;你下载的Chromium.app/Contents/MacOS/Chromium&#39;,
    &#125;)
    # 打开一个页面，同一个browser可以打开多个页面
    page = await browser.newPage()
    await page.goto(&#39;https://baidu.com&#39;) # 访问指定页面
    await page.screenshot(path=&#39;example.png&#39;)  # 截图
    await page.close() # 关闭页面
    await browser.close() # 关闭浏览器（实测中发现打开多个页面会产生大量僵尸进程）

asyncio.get_event_loop().run_until_complete(main()）</code></pre>
<p>运行上面这一段代码会产生一张页面截图，如果在运行中报错pyppeteer.errors.NetworkError: Protocol error Network.getCookies: Target close可以通过降低websockets 版本来解决</p>
<pre><code class="bash">pip uninstall websockets #卸载websockets
pip install websockets==6.0
或者
pip install websockets==6.0 --force-reinstall #指定安装6.0版本</code></pre>
<h3 id="重要参数设置及方法"><a href="#重要参数设置及方法" class="headerlink" title="重要参数设置及方法"></a>重要参数设置及方法</h3><pre><code class="bash">import asynciofrom pyppeteer import launch


async def intercept_request(req):
    # 不加载css和img等资源
    if req.resourceType in [&quot;image&quot;, &quot;media&quot;, &quot;eventsource&quot;, &quot;websocket&quot;, &quot;stylesheet&quot;, &quot;font&quot;]:
        await req.abort() #连接请求
    else:
        res = &#123;
            &quot;method&quot;: req.method,
            &quot;url&quot;: req.url,
            &quot;data&quot;: &quot;&quot; if req.postData == None else req.postData,
            &quot;res&quot;: &quot;&quot; if req.response == None else req.response
        &#125;
        print(res) # 打印请求的内容
        await  req.continue_() #继续请求，可以添加参数将请求地址重定向、改变请求的headers

async def intercept_response(res):
    resourceType = res.request.resourceType
    # 拦截ajax请求获取数据
    if resourceType in [&#39;xhr&#39;]:
        resp = await res.json()
        print(resp)# 这里可以操作mysql、redis或者设计一个class来保存数据

async def main():
    # 创建一个浏览器
    browser = await launch(&#123;
        &#39;executablePath&#39;: &#39;你下载的Chromium.app/Contents/MacOS/Chromium&#39;,
        &#39;headless&#39;: False, # 关闭无头模式。主要在测试环境调试使用
        &#39;devtools&#39;: True, # 打开 chromium 的 devtools与headless配个使用
        &#39;args&#39;: [ 
             &#39;--disable-extensions&#39;,
             &#39;--hide-scrollbars&#39;,
             &#39;--disable-bundled-ppapi-flash&#39;,
             &#39;--mute-audio&#39;,
             &#39;--no-sandbox&#39;,# --no-sandbox 在 docker 里使用时需要加入的参数，不然会报错
             &#39;--disable-setuid-sandbox&#39;,
             &#39;--disable-gpu&#39;,
          ],
         &#39;dumpio&#39;: True, #把无头浏览器进程的 stderr 核 stdout pip 到主程序，也就是设置为 True 的话，chromium console 的输出就会在主程序中被打印出来
    &#125;)
    # 打开一个页面，同一个browser可以打开多个页面
    page = await browser.newPage()
    # 是否启用JS，enabled设为False，则无渲染效果，如果页面有ajax请求需要开启此项
    await page.setJavaScriptEnabled(enabled=True)
    # 是否允许拦截请求，如果开启可以注册的两个回调函数，在浏览器发出请求和获取到请求之前指向这两个函数。
    await page.setRequestInterception(value=True)
    page.on(&#39;request&#39;, intercept_request) # 请求的内容
    page.on(&#39;response&#39;, intercept_response) # 响应的内容
    await page.goto(&#39;https://baidu.com&#39;) # 访问指定页面
    await page.screenshot(path=&#39;example.png&#39;)  # 截图
    await page.close() # 关闭页面
    await browser.close() # 关闭浏览器（实测中发现打开多个页面会产生大量僵尸进程）

asyncio.get_event_loop().run_until_complete(main()）</code></pre>
<h2 id="僵尸进程"><a href="#僵尸进程" class="headerlink" title="僵尸进程"></a>僵尸进程</h2><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>当一个父进程以fork()系统调用建立一个新的子进程后，核心进程就会在进程表中给这个子进程分配一个进入点，然后将相关信息存储在该进入点所对应的进程表内。这些信息中有一项是其父进程的识别码。 而当这个子进程结束的时候（比如调用exit命令结束），其实他并没有真正的被销毁，而是留下一个称为僵尸进程（Zombie）的数据结构（系统调用exit的作用是使进程退出，但是也仅仅限于一个正常的进程变成了一个僵尸进程，并不能完全将其销毁）。此时原来进程表中的数据会被该进程的退出码（exit code）、执行时所用的CPU时间等数据所取代，这些数据会一直保留到系统将它传递给它的父进程为止。由此可见，defunct进程的出现时间是在子进程终止后，但是父进程尚未读取这些数据之前。<br>此时，该僵尸子进程已经放弃了几乎所有的内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，记载该进程的退出状态信息供其他进程收集，除此之外，僵尸进程不再占有任何存储空间。他需要他的父进程来为他收尸，如果他的父进程没有安装SIGCHLD信号处理函数调用wait 或 waitpid() 等待子进程结束，也没有显式忽略该信号，那么它就一直保持僵尸状态，如果这时候父进程结束了，那么init进程会自动接手这个子进程，为他收尸，他还是能被清除掉的。 拿Nginx作为例子，默认是作为后台守护进程。它是这么工作的。第一，Nginx创建一个子进程。第二，原始的Nginx进程退出了。第三，Nginx子进程被init进程给接收了。</p>
<p>但是如果父进程是一个循环，不会结束，那么子进程就会一直保持僵尸状态，这就是系统中为什么有时候会有很多的僵尸进程。<br>一个子进程终止了，但一直被等待就变成了”僵尸“。<br>defunct状态下的僵尸进程是不能直接使用kill -9命令杀掉的，否则就不叫僵尸进程了。<br>Unix的进程是一个有序的树。每个进程可以派生子进程，每个进程具有一个除了最顶层以外的父进程，这个最顶层的进程是init进程。它是当你启动系统时由内核启动。这个init进程负责启动系统的其余部分，如启动SSH服务，从启动Docker守护进程，启动Apache / Nginx的，启动你的GUI桌面环境，等等。他们每个进程都可能会反过来派生出更多的子进程。</p>
<p>如果一个进程终止会发生什么？bash（PID 5）进程终止，它变成了一个所谓的“停止活动的进程”，也称为“僵尸进程”。</p>
<p>这时PID5要等待sshd2调用wait 或 waitpid() 然后彻底结束，假设sshd2没有调用相应的方法，那么PID5就会一直等待下去，当sshd2结束的时候PID5会被init进程接手然后处理掉。</p>
<p>但是在docker中init 1往往是你的任务进程，需要不间断的运行不能退出，这就导致了僵尸进程无人清理越来越多，因此不建议在docker中直接运行脚本，而是先启动/bin/bash然后启动脚本</p>
<pre><code class="bash">CMD [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;set -e &amp;&amp; 你的任务脚本&quot;]</code></pre>
<p>但是这种方法也有问题，不能优雅的结束进程。假设你用kill发送SIGTERM信号给bash.Bash终止了，但是没有发送SIGTERM给它的子进程！ 当bash结束了，内核结束整个容器中的所有进程。包扩通过SIGKILL信号没有被干净的终结的进程。SIGKILL不能被捕获，所以进程是没有办法干净的终结。假设你运行的应用程序正忙于写文件；在写的过程中，应用被不干净的终止了这个文件可能会崩溃。不干净的终止是很坏的事情。很像把服务器的电源给拔掉。 但是为什么要关心init进程是否被SIGTERM给终结了呢？那是因为docker stop 发送 SIGTERM信号给init进程了。“docker stop” 应该干净的停止容器，以至于稍后你能够用“docker start”启动它。</p>
<p>解决办法<br>在linux下找到该defunct僵尸进程的父进程，将该进程的父进程杀掉，然后init进程会自动接手其子进程并为子进程收尸。ps -ef | grep defunct_process_pid<br>docker中在启动真正的工作脚本之前先启动/bin/bash用来给僵尸进程收尸<br>docker环境搭建<br>镜像搭建<br>dockerfile文件</p>
<pre><code class="bash">FROM centos:7
RUN set -ex \
    # 预安装所需组件
    &amp;&amp; yum install -y wget tar libffi-devel zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make initscripts \
    &amp;&amp; wget https://www.python.org/ftp/python/3.6.0/Python-3.6.0.tgz \
    &amp;&amp; tar -zxvf Python-3.6.0.tgz \
    &amp;&amp; cd Python-3.6.0 \
    &amp;&amp; ./configure prefix=/usr/local/python3 \
    &amp;&amp; make \
    &amp;&amp; make install \
    &amp;&amp; make clean \
    &amp;&amp; rm -rf /Python-3.6.0* \
    &amp;&amp; yum install -y epel-release \
    &amp;&amp; yum install -y python-pip
# 设置默认为python3
RUN set -ex \
    # 备份旧版本python
    &amp;&amp; mv /usr/bin/python /usr/bin/python27 \
    &amp;&amp; mv /usr/bin/pip /usr/bin/pip-python2.7 \
    # 配置默认为python3
    &amp;&amp; ln -s /usr/local/python3/bin/python3.6 /usr/bin/python \
    &amp;&amp; ln -s /usr/local/python3/bin/pip3 /usr/bin/pip
# 修复因修改python版本导致yum失效问题
RUN set -ex \
    &amp;&amp; sed -i &quot;s#/usr/bin/python#/usr/bin/python2.7#&quot; /usr/bin/yum \
    &amp;&amp; sed -i &quot;s#/usr/bin/python#/usr/bin/python2.7#&quot; /usr/libexec/urlgrabber-ext-down \
    &amp;&amp; yum install -y deltarpm
# 基础环境配置
RUN set -ex \
    # 修改系统时区为东八区
    &amp;&amp; rm -rf /etc/localtime \
    &amp;&amp; ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;&amp; yum install -y vim \
    # 安装定时任务组件
    &amp;&amp; yum -y install cronie
# 支持中文
RUN localedef -c -f UTF-8 -i zh_CN zh_CN.utf8
# chrome浏览器依赖
RUN yum install kde-l10n-Chinese -y
RUN yum install pango.x86_64 libXcomposite.x86_64 libXcursor.x86_64 libXdamage.x86_64 libXext.x86_64 libXi.x86_64 libXtst.x86_64 cups-libs.x86_64 libXScrnSaver.x86_64 libXrandr.x86_64 GConf2.x86_64 alsa-lib.x86_64 atk.x86_64 gtk3.x86_64 -y
RUN yum install ipa-gothic-fonts xorg-x11-fonts-100dpi xorg-x11-fonts-75dpi xorg-x11-utils xorg-x11-fonts-cyrillic xorg-x11-fonts-Type1 xorg-x11-fonts-misc -y
# 更新pip版本
RUN pip install --upgrade pip
ENV LC_ALL zh_CN.UTF-8
RUN mkdir -p /usr/src/scrapy
COPY requirements.txt /usr/src/scrapy
RUN pip install -i https://pypi.douban.com/simple/ -r /usr/src/scrapy/requirements.txt</code></pre>
<p>docker-compose文件</p>
<pre><code class="bash">version: &#39;3.3&#39;
services:
  scrapy:
    privileged: true
    build: scrapy
    tty: true
    volumes:
      - type: bind
        source: /爬虫文件路径
        target: /usr/src/scrapy
    ports:
      - &quot;9999:9999&quot;
    networks:
      scrapynet:
        ipv4_address: 172.19.0.8
    command: [/bin/bash, -c, set -e &amp;&amp; python /usr/src/scrapy/job.py]

networks:
  scrapynet:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.19.0.0/24</code></pre>
<p>command: [/bin/bash, -c, set -e &amp;&amp; python /usr/src/scrapy/job.py]命令解释</p>
<p>/bin/bash 防止产生僵尸进程，-e 指令阻止bash把这个脚本当做简单的命令直接执行exec（）<br>python /usr/src/scrapy/job.py 真正的工作脚本<br>基于pyppeteer的爬虫脚本</p>
<pre><code class="bash">import asyncio,random,psutil,os,signal,time
from pyppeteer import launcher
# hook  禁用 防止监测webdriver
launcher.AUTOMATION_ARGS.remove(&quot;--enable-automation&quot;)
from pyppeteer import launch
async def intercept_request(req):
    if req.resourceType in [&quot;image&quot;]:
        await req.abort()
    else:
        res = &#123;
            &quot;method&quot;: req.method,
            &quot;url&quot;: req.url,
            &quot;data&quot;: &quot;&quot; if req.postData == None else req.postData,
            &quot;res&quot;: &quot;&quot; if req.response == None else req.response
        &#125;
        print(res)
        await req.continue_()


async def intercept_response(res):
    resourceType = res.request.resourceType
    if resourceType in [&#39;xhr&#39;]:
        resp = await res.json()
        print(resp)

class newpage(object):
    width, height = 1920, 1080
    def __init__(self, page_url,chrome_browser):
        self.url = page_url
        self.browser = chrome_browser

    async def run(self):
        t = random.randint(1, 4)
        tt = random.randint(t, 10)
        await asyncio.sleep(tt)
        try:
            page = await self.browser.newPage()
            await page.setUserAgent(
                userAgent=&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/70.0.3521.2 Safari/537.36&#39;)
            await page.setViewport(viewport=&#123;&#39;width&#39;: self.width, &#39;height&#39;: self.height&#125;)
            # 是否启用JS，enabled设为False，则无渲染效果
            await page.setJavaScriptEnabled(enabled=True)
            await page.setRequestInterception(value=True)
            page.on(&#39;request&#39;, intercept_request)
            page.on(&#39;response&#39;, intercept_response)
            await page.goto(self.url, options=&#123;&#39;timeout&#39;: 30000&#125;)
            await page.waitFor(selectorOrFunctionOrTimeout=1000)
            try:
                await page.close()
                return self.url
            except BaseException as err:
                return &quot;close_newpage: &#123;0&#125;&quot;.format(err)
        except BaseException as err:
            return &quot;newpage: &#123;0&#125;&quot;.format(err)

class Browser(object):
    width, height = 1920, 1080
    browser = None
    is_headless = True
    url_list = []

    def __init__(self,urls):
        self.url_list = urls

    # 封装了kill（）方法杀死chrome主进程，让init 1进程接管其僵尸子进程处理僵尸进程
    def kill(self,name):
        # win平台
        # subprocess.Popen(&quot;taskkill /F /IM chrome.EXE &quot;, shell=True)

        # linux平台
        try:
            pid = self.browser.process.pid
            pgid = os.getpgid(pid)
            # 强制结束
            os.kill(pid, signal.SIGKILL)
            print(&quot;结束进程：%d&quot; % pid)
            print(&quot;父进程是：%d&quot; % pgid)
            print(&quot;等待结果：%d&quot; % self.browser.process.wait())
        except BaseException as err:
            print(&quot;close: &#123;0&#125;&quot;.format(err))
        time.sleep(3)
        # 查看是否还有其他进程
        for proc in psutil.process_iter():
            if name in proc.name():
                try:
                    os.kill(proc.pid, signal.SIGTERM)
                    print(&#39;已杀死[pid:%s]的进程[pgid：%s][名称：%s]&#39; % (proc.pid,pgid,proc.name()))
                except BaseException as err:
                    print(&quot;kill: &#123;0&#125;&quot;.format(err))

    # 打开浏览器
    async def newbrowser(self):
        try:
            self.browser = await launch(&#123;
                &#39;headless&#39;: self.is_headless,
                &#39;devtools&#39;: not self.is_headless,
                &#39;dumpio&#39;: True,
                &#39;autoClose&#39;: True,
                # &#39;userDataDir&#39;: &#39;./userdata&#39;,
                &#39;handleSIGTERM&#39;: True,
                &#39;handleSIGHUP&#39;: True,
                # &#39;executablePath&#39;:&#39;C:/Users/zhang/Desktop/chrome-win/chrome.exe&#39;,
                &#39;args&#39;: [
                    &#39;--no-sandbox&#39;,  # --no-sandbox 在 docker 里使用时需要加入的参数，不然会报错
                    &#39;--disable-gpu&#39;,
                    &#39;--disable-extensions&#39;,
                    &#39;--hide-scrollbars&#39;,
                    &#39;--disable-bundled-ppapi-flash&#39;,
                    &#39;--mute-audio&#39;,
                    &#39;--disable-setuid-sandbox&#39;,
                    &#39;--disable-xss-auditor&#39;,
                    &#39;--window-size=%d,%d&#39; % (self.width, self.height)
                ]
            &#125;)
        except BaseException as err:
            print(&quot;launch: &#123;0&#125;&quot;.format(err))

        print(&#39;----打开浏览器----&#39;)

    async def open(self):
        await self.newbrowser()
        try:
            tasks = [asyncio.ensure_future(newpage(url,self.browser).run()) for url in self.url_list]
            for task in asyncio.as_completed(tasks):
                result = await task
                print(&#39;Task ret: &#123;&#125;&#39;.format(result))
        except BaseException as err:
            print(&quot;open: &#123;0&#125;&quot;.format(err))
        # browser.close()方法无法彻底退出chrome进程，这里我们自己封装了kill（）方法杀死chrome主进程，让init 1进程接管其僵尸子进程
        # await self.browser.close()

    def main(self):
        loop = asyncio.get_event_loop()
        loop.run_until_complete(self.open())
        print(&#39;----关闭浏览器----&#39;)
        self.kill(&#39;chrom&#39;)

if __name__ == &#39;__main__&#39;:
    url_list=[
        &#39;https://www.baidu.com/&#39;,
        &#39;https://www.baidu.com/&#39;,
        &#39;https://www.baidu.com/&#39;,
        &#39;https://www.baidu.com/&#39;,
    ]
    while True:
        # 不停的添加任务
        o = Browser(url_list)
        print(o.main())</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>pyppeteer</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>pyppeteer</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu20.04 安装 k8s</title>
    <url>/2020/07/31/5787/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文介绍如何在ubuntu20.04 上部署k8s集群，大致可以分为如下几个步骤：</p>
<h3 id="修改ubuntu配置"><a href="#修改ubuntu配置" class="headerlink" title="修改ubuntu配置"></a>修改ubuntu配置</h3><p>###　安装docker</p>
<h3 id="安装kubeadm、kubectl以及kubelet"><a href="#安装kubeadm、kubectl以及kubelet" class="headerlink" title="安装kubeadm、kubectl以及kubelet"></a>安装kubeadm、kubectl以及kubelet</h3><h3 id="初始化master节点"><a href="#初始化master节点" class="headerlink" title="初始化master节点"></a>初始化master节点</h3><h3 id="将slave节点加入网络"><a href="#将slave节点加入网络" class="headerlink" title="将slave节点加入网络"></a>将slave节点加入网络</h3><p>如果你对上面的某些名字感到陌生，没关系，下文会一一进行讲解，如果你想先了解一下 docker 和 k8s，可以参考 10分钟看懂Docker和K8S。好了，在正式开始之前，首先看一下我们都有哪些服务器，如果你对如何组建如下虚拟机网络感兴趣的话，可以参考 virtualbox 虚拟机组网：</p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">主机名	主机ip	版本	CPU	内存</span><br><span class="line">master1	<span class="number">192.168</span><span class="number">.56</span><span class="number">.11</span>	Ubuntu server <span class="number">18.04</span>	<span class="number">2</span>核	1G</span><br><span class="line">worker1	<span class="number">192.168</span><span class="number">.56</span><span class="number">.21</span>	Ubuntu server <span class="number">18.04</span>	<span class="number">2</span>核	1G</span><br></pre></td></tr></table></figure>
<p>因为k8s分为管理节点和工作节点，所以我们将要 在master1上部署管理节点，在worker1上部署工作节点。如果想了解如何创建这两个节点，可以参考 virtualbox 虚拟机组网 。服务器配置上，k8s 要求 CPU 最低为 2 核，不然在安装过程中会报错，虽然这个错误可以避免，但是为了稳定起见还是把虚拟机的配置成它想要的，至于内存 k8s 没有硬性要求，所以我就按我电脑的性能来分配了。</p>
<p>注意，本文的 docker、k8s 等软件安装均未指定具体版本，在本文完成时2019/6/27，下载到的版本如下，如有特殊版本需要请自行指定版本。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">软件名	版本</span><br><span class="line">docker	<span class="number">18.09</span><span class="number">.5</span></span><br><span class="line">kubectl	<span class="number">1.15</span><span class="number">.0</span>-<span class="number">00</span> amd64</span><br><span class="line">kubeadm	<span class="number">1.15</span><span class="number">.0</span>-<span class="number">00</span> amd64</span><br><span class="line">kubelet	<span class="number">1.15</span><span class="number">.0</span>-<span class="number">00</span> amd64</span><br></pre></td></tr></table></figure>
<h2 id="一-修改-ubuntu-配置"><a href="#一-修改-ubuntu-配置" class="headerlink" title="一. 修改 ubuntu 配置"></a>一. 修改 ubuntu 配置</h2><p>首先，k8s 要求我们的 ubuntu 进行一些符合它要求的配置。很简单，包括以下两步：关闭 Swap 内存 以及 配置免密登录，这一步两台主机都需要进行配置。</p>
<h2 id="关闭-swap-内存"><a href="#关闭-swap-内存" class="headerlink" title="关闭 swap 内存"></a>关闭 swap 内存</h2><p>这个swap其实可以类比成 windows 上的虚拟内存，它可以让服务器在内存吃满的情况下可以保持低效运行，而不是直接卡死。但是 k8s 的较新版本都要求关闭swap。所以咱们直接动手，修改/etc/fstab文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo vi /etc/fstab</span><br></pre></td></tr></table></figure>
<p>你应该可以看到如下内容，把第二条用#注释掉就好了，注意第一条别注释了，不然重启之后系统有可能会报file system read-only错误。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">UUID=e2048966-750b-<span class="number">4795</span>-a9a2-7b477d6681bf /   ext4    errors=remount-ro <span class="number">0</span>    <span class="number">1</span></span><br><span class="line"><span class="comment"># /dev/fd0        /media/floppy0  auto    rw,user,noauto,exec,utf8 0       0</span></span><br></pre></td></tr></table></figure>
<p>然后输入reboot重启即可，重启后使用top命令查看任务管理器，如果看到如下KiB Swap后均为 0 就说明关闭成功了。</p>
<p>关闭swap之后的任务管理器<br>上面说的是永久关闭swap内存，其实也可以暂时关闭，使用swapoff -a命令即可，效果会在重启后消失。</p>
<h2 id="配置免密登录"><a href="#配置免密登录" class="headerlink" title="配置免密登录"></a>配置免密登录</h2><p>k8s 要求 管理节点可以直接免密登录工作节点 的原因是：在集群搭建完成后，管理节点的 kubelet 需要登陆工作节点进行操作。而至于怎么操作很简单，这里就不详提了，可以参见文章 <a href="https://www.jianshu.com/p/e6684182471b">virtualbox 虚拟机组网</a> 的最后一个章节 免密钥登录 。</p>
<h2 id="二-安装-docker"><a href="#二-安装-docker" class="headerlink" title="二. 安装 docker"></a>二. 安装 docker</h2><p>docker 是 k8s 的基础，在安装完成之后也需要修改一些配置来适配 k8s ，所以本章分为 docker 的安装 与 docker 的配置 两部分。如果你已经安装并使用了一段时间的 docker 了话，建议使用docker -v查看已安装的 docker 版本，并在 k8s 官网上查询适合该版本的 k8s 进行安装。这一步两台主机都需要进行安装。</p>
<p>docker 的安装<br>docker 在 ubuntu 的安装上真是再简单不过了，执行如下命令即可，在安装之前请记得把镜像源切换到国内。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo apt install docker.io</span><br></pre></td></tr></table></figure>
<p>等安装完成之后使用docker -v来验证 docker是否可用。</p>
<h2 id="docker-的配置"><a href="#docker-的配置" class="headerlink" title="docker 的配置"></a>docker 的配置</h2><p>安装完成之后需要进行一些配置，包括 切换docker下载源为国内镜像站 以及 修改cgroups。</p>
<p>这个cgroups是啥呢，你可以把它理解成一个进程隔离工具，docker就是用它来实现容器的隔离的。docker 默认使用的是cgroupfs，而 k8s 也用到了一个进程隔离工具systemd，如果使用两个隔离组的话可能会引起异常，所以我们要把 docker 的也改成systemd。</p>
<p>这两者都是在/etc/docker/daemon.json里修改的，所以我们一起配置了就好了，首先执行下述命令编辑daemon.json：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo vi /etc/docker/daemon.json</span><br></pre></td></tr></table></figure>
<p>打开后输入以下内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;https://dockerhub.azk8s.cn&quot;</span>,</span><br><span class="line">    <span class="string">&quot;https://reg-mirror.qiniu.com&quot;</span>,</span><br><span class="line">    <span class="string">&quot;https://quay-mirror.qiniu.com&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">&quot;exec-opts&quot;</span>: [ <span class="string">&quot;native.cgroupdriver=systemd&quot;</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后:wq保存后重启 docker：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>
<p>然后就可以通过docker info | grep Cgroup来查看修改后的 docker cgroup 状态，发现变为systemd即为修改成功。</p>
<h2 id="三-安装-k8s"><a href="#三-安装-k8s" class="headerlink" title="三. 安装 k8s"></a>三. 安装 k8s</h2><p>安装完了 docker 就可以下载 k8s 的三个主要组件kubelet、kubeadm以及kubectl了。这一步两台主机都需要进行安装。先来简单介绍一下这三者：</p>
<p>kubelet: k8s 的核心服务<br>kubeadm: 这个是用于快速安装 k8s 的一个集成工具，我们在master1和worker1上的 k8s 部署都将使用它来完成。<br>kubectl: k8s 的命令行工具，部署完成之后后续的操作都要用它来执行<br>其实这三个的下载很简单，直接用apt-get就好了，但是因为某些原因，它们的下载地址不存在了。所以我们需要用国内的镜像站来下载，也很简单，依次执行下面五条命令即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使得 apt 支持 ssl 传输</span></span><br><span class="line">apt-get update &amp;&amp; apt-get install -y apt-transport-https</span><br><span class="line"><span class="comment"># 下载 gpg 密钥</span></span><br><span class="line">curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - </span><br><span class="line"><span class="comment"># 添加 k8s 镜像源</span></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/apt/sources.<span class="built_in">list</span>.d/kubernetes.<span class="built_in">list</span></span><br><span class="line">deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line"><span class="comment"># 更新源列表</span></span><br><span class="line">apt-get update</span><br><span class="line"><span class="comment"># 下载 kubectl，kubeadm以及 kubelet</span></span><br><span class="line">apt-get install -y kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure>
<p>直接在/etc/apt/sources.list里添加<a href="https://mirrors.aliyun.com/kubernetes/apt/%E6%98%AF%E4%B8%8D%E8%A1%8C%E7%9A%84%EF%BC%8C%E5%9B%A0%E4%B8%BA%E8%BF%99%E4%B8%AA%E9%98%BF%E9%87%8C%E9%95%9C%E5%83%8F%E7%AB%99%E4%BD%BF%E7%94%A8%E7%9A%84ssl%E8%BF%9B%E8%A1%8C%E4%BC%A0%E8%BE%93%E7%9A%84%EF%BC%8C%E6%89%80%E4%BB%A5%E8%A6%81%E5%85%88%E5%AE%89%E8%A3%85apt-transport-https%E5%B9%B6%E4%B8%8B%E8%BD%BD%E9%95%9C%E5%83%8F%E7%AB%99%E7%9A%84%E5%AF%86%E9%92%A5%E6%89%8D%E5%8F%AF%E4%BB%A5%E8%BF%9B%E8%A1%8C%E4%B8%8B%E8%BD%BD%E3%80%82">https://mirrors.aliyun.com/kubernetes/apt/是不行的，因为这个阿里镜像站使用的ssl进行传输的，所以要先安装apt-transport-https并下载镜像站的密钥才可以进行下载。</a></p>
<h2 id="四-安装-master-节点"><a href="#四-安装-master-节点" class="headerlink" title="四. 安装 master 节点"></a>四. 安装 master 节点</h2><p>下载完成后就要迎来重头戏了，初始化master节点，这一章节只需要在管理节点上配置即可，大致可以分为如下几步：</p>
<p>初始化master节点<br>部署flannel网络<br>配置kubectl工具</p>
<h3 id="初始化-master-节点-这一步会卡-是因为docker源-可以参考link"><a href="#初始化-master-节点-这一步会卡-是因为docker源-可以参考link" class="headerlink" title="初始化 master 节点  这一步会卡 是因为docker源 可以参考link"></a>初始化 master 节点  这一步会卡 是因为docker源 可以参考<a href="http://mls-tech.info/microservice/k8s/k8s-download-images/">link</a></h3><h2 id="获取镜像文件"><a href="#获取镜像文件" class="headerlink" title="获取镜像文件"></a>获取镜像文件</h2><p>查看需要的镜像</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubeadm config images <span class="built_in">list</span></span><br></pre></td></tr></table></figure>
<p>系统输出:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">k8s.gcr.io/kube-apiserver:v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">k8s.gcr.io/kube-scheduler:v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">k8s.gcr.io/kube-proxy:v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">k8s.gcr.io/pause:<span class="number">3.1</span></span><br><span class="line">k8s.gcr.io/etcd:<span class="number">3.3</span><span class="number">.10</span></span><br><span class="line">k8s.gcr.io/coredns:<span class="number">1.3</span><span class="number">.1</span></span><br></pre></td></tr></table></figure>
<p>编辑一个文件, 命名为： install_k8s_images.sh</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#! /bin/bash</span></span><br><span class="line">images=(</span><br><span class="line">    kube-apiserver:v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">    kube-controller-manager:v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">    kube-scheduler:v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">    kube-proxy:v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">    pause:<span class="number">3.1</span></span><br><span class="line">    etcd:<span class="number">3.3</span><span class="number">.10</span></span><br><span class="line">    coredns:<span class="number">1.3</span><span class="number">.1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> imageName <span class="keyword">in</span> $&#123;images[@]&#125; ; do</span><br><span class="line">    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName  <span class="comment">#  如果失败,改为docker pull $imageName</span></span><br><span class="line">    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName  <span class="comment"># 如果失败改为 docker tag $imageName k8s.gcr.io/$imageName</span></span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>将文件设置为可运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chmod a+x install_k8s_images.sh</span><br></pre></td></tr></table></figure>
<p>运行 install_k8s_images.sh 安装所需要的镜像</p>
<p>./install_k8s_images.sh<br>更新：以上需要的镜像我已经打包成一个文件，可以直接加载到 docker 中，参考 从本地上传安装 kubernetes 所需要的镜像</p>
<p>注意：以上步骤需要在Master和Node机器完成</p>
<p>配置Master节点<br>修改主节点的 hostname 为: master-node</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo hostnamectl <span class="built_in">set</span>-hostname master-node</span><br></pre></td></tr></table></figure>
<p>初始化 Kubernetes:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo kubeadm init --pod-network-cidr=<span class="number">10.244</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">16</span></span><br></pre></td></tr></table></figure>
<p>系统显示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W0907 <span class="number">16</span>:<span class="number">17</span>:<span class="number">44.359105</span>    <span class="number">1998</span> version.go:<span class="number">98</span>] could <span class="keyword">not</span> fetch a Kubernetes version <span class="keyword">from</span> the internet: unable to get URL <span class="string">&quot;https://dl.k8s.io/release/stable-1.txt&quot;</span>: Get https://dl.k8s.io/release/stable-<span class="number">1.</span>txt: net/http: request canceled <span class="keyword">while</span> waiting <span class="keyword">for</span> connection (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br><span class="line">W0907 <span class="number">16</span>:<span class="number">17</span>:<span class="number">44.359172</span>    <span class="number">1998</span> version.go:<span class="number">99</span>] falling back to the local client version: v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">[init] Using Kubernetes version: v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">	[WARNING IsDockerSystemdCheck]: detected <span class="string">&quot;cgroupfs&quot;</span> <span class="keyword">as</span> the Docker cgroup driver. The recommended driver <span class="keyword">is</span> <span class="string">&quot;systemd&quot;</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">	[WARNING SystemVerification]: this Docker version <span class="keyword">is</span> <span class="keyword">not</span> on the <span class="built_in">list</span> of validated versions: <span class="number">19.03</span><span class="number">.1</span>. Latest validated version: <span class="number">18.09</span></span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute <span class="keyword">or</span> two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action <span class="keyword">in</span> beforehand using <span class="string">&#x27;kubeadm config images pull&#x27;</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file <span class="keyword">with</span> flags to file <span class="string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span></span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">&quot;/var/lib/kubelet/config.yaml&quot;</span></span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[certs] Using certificateDir folder <span class="string">&quot;/etc/kubernetes/pki&quot;</span></span><br><span class="line">[certs] Generating <span class="string">&quot;etcd/ca&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] Generating <span class="string">&quot;etcd/healthcheck-client&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] Generating <span class="string">&quot;apiserver-etcd-client&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] Generating <span class="string">&quot;etcd/server&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] etcd/server serving cert <span class="keyword">is</span> signed <span class="keyword">for</span> DNS names [master-node localhost] <span class="keyword">and</span> IPs [<span class="number">192.168</span><span class="number">.43</span><span class="number">.10</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> ::<span class="number">1</span>]</span><br><span class="line">[certs] Generating <span class="string">&quot;etcd/peer&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] etcd/peer serving cert <span class="keyword">is</span> signed <span class="keyword">for</span> DNS names [master-node localhost] <span class="keyword">and</span> IPs [<span class="number">192.168</span><span class="number">.43</span><span class="number">.10</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> ::<span class="number">1</span>]</span><br><span class="line">[certs] Generating <span class="string">&quot;ca&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] Generating <span class="string">&quot;apiserver&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] apiserver serving cert <span class="keyword">is</span> signed <span class="keyword">for</span> DNS names [master-node kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] <span class="keyword">and</span> IPs [<span class="number">10.96</span><span class="number">.0</span><span class="number">.1</span> <span class="number">192.168</span><span class="number">.43</span><span class="number">.10</span>]</span><br><span class="line">[certs] Generating <span class="string">&quot;apiserver-kubelet-client&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] Generating <span class="string">&quot;front-proxy-ca&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] Generating <span class="string">&quot;front-proxy-client&quot;</span> certificate <span class="keyword">and</span> key</span><br><span class="line">[certs] Generating <span class="string">&quot;sa&quot;</span> key <span class="keyword">and</span> public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">&quot;/etc/kubernetes&quot;</span></span><br><span class="line">[kubeconfig] Writing <span class="string">&quot;admin.conf&quot;</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">&quot;kubelet.conf&quot;</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">&quot;controller-manager.conf&quot;</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">&quot;scheduler.conf&quot;</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">&quot;/etc/kubernetes/manifests&quot;</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">&quot;kube-apiserver&quot;</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">&quot;kube-controller-manager&quot;</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">&quot;kube-scheduler&quot;</span></span><br><span class="line">[etcd] Creating static Pod manifest <span class="keyword">for</span> local etcd <span class="keyword">in</span> <span class="string">&quot;/etc/kubernetes/manifests&quot;</span></span><br><span class="line">[wait-control-plane] Waiting <span class="keyword">for</span> the kubelet to boot up the control plane <span class="keyword">as</span> static Pods <span class="keyword">from</span> directory <span class="string">&quot;/etc/kubernetes/manifests&quot;</span>. This can take up to 4m0s</span><br><span class="line">[kubelet-check] Initial timeout of 40s passed.</span><br><span class="line">[apiclient] All control plane components are healthy after <span class="number">61.555344</span> seconds</span><br><span class="line">[upload-config] Storing the configuration used <span class="keyword">in</span> ConfigMap <span class="string">&quot;kubeadm-config&quot;</span> <span class="keyword">in</span> the <span class="string">&quot;kube-system&quot;</span> Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap <span class="string">&quot;kubelet-config-1.15&quot;</span> <span class="keyword">in</span> namespace kube-system <span class="keyword">with</span> the configuration <span class="keyword">for</span> the kubelets <span class="keyword">in</span> the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node master-node <span class="keyword">as</span> control-plane by adding the label <span class="string">&quot;node-role.kubernetes.io/master=&#x27;&#x27;&quot;</span></span><br><span class="line">[mark-control-plane] Marking the node master-node <span class="keyword">as</span> control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: mg39mb.hmfz2bao1t90fcdc</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class="keyword">in</span> order <span class="keyword">for</span> nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs <span class="keyword">from</span> a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation <span class="keyword">for</span> <span class="built_in">all</span> node client certificates <span class="keyword">in</span> the cluster</span><br><span class="line">[bootstrap-token] Creating the <span class="string">&quot;cluster-info&quot;</span> ConfigMap <span class="keyword">in</span> the <span class="string">&quot;kube-public&quot;</span> namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following <span class="keyword">as</span> a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> <span class="keyword">with</span> one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join <span class="built_in">any</span> number of worker nodes by running the following on each <span class="keyword">as</span> root:</span><br><span class="line"></span><br><span class="line">kubeadm join <span class="number">192.168</span><span class="number">.43</span><span class="number">.10</span>:<span class="number">6443</span> --token mg39mb.hmfz2bao1t90fcdc \</span><br><span class="line">    --discovery-token-ca-cert-<span class="built_in">hash</span> sha256:4343f8637818221cc153a4c556a6a29606f5a14ea040b3e9ee1e5e29af6e7381</span><br></pre></td></tr></table></figure>
<p>##　为当前用户保存 kubernetes 配置信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
<p>现在，你可以使用以下命令，加入新的节点(node):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubeadm join <span class="number">192.168</span><span class="number">.43</span><span class="number">.10</span>:<span class="number">6443</span> --token mg39mb.hmfz2bao1t90fcdc </span><br><span class="line">    --discovery-token-ca-cert-<span class="built_in">hash</span> sha256:4343f8637818221cc153a4c556a6a29606f5a14ea040b3e9ee1e5e29af6e7381</span><br></pre></td></tr></table></figure>
<p>现在，我们可以通过 kubetl 命令查看状态</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>
<p>得到如下结果:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">NAME          STATUS     ROLES    AGE     VERSION</span><br><span class="line">master-node   NotReady   master   3h44m   v1<span class="number">.15</span><span class="number">.3</span></span><br></pre></td></tr></table></figure>
<p>可以看到，当前只有一个节点，并且状态是:”NotReady”, 因为现在还没有配置任何Pod网络。</p>
<p>在Master上部署一个Pod网络<br>在本教程中，我们部署一个 Flannel pod network。在Master节点机器上执行以下命令:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>
<p>系统显示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">podsecuritypolicy.policy/psp.flannel.unprivileged created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/flannel created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/flannel created</span><br><span class="line">serviceaccount/flannel created</span><br><span class="line">configmap/kube-flannel-cfg created</span><br><span class="line">daemonset.apps/kube-flannel-ds-amd64 created</span><br><span class="line">daemonset.apps/kube-flannel-ds-arm64 created</span><br><span class="line">daemonset.apps/kube-flannel-ds-arm created</span><br><span class="line">daemonset.apps/kube-flannel-ds-ppc64le created</span><br><span class="line">daemonset.apps/kube-flannel-ds-s390x created</span><br></pre></td></tr></table></figure>
<p>执行后，查看pod网络的状态:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubectl get pods --<span class="built_in">all</span>-namespaces</span><br></pre></td></tr></table></figure>
<p>系统显示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">NAMESPACE     NAME                                  READY   STATUS     RESTARTS   AGE</span><br><span class="line">kube-system   coredns-5c98db65d4-fl5fs              <span class="number">0</span>/<span class="number">1</span>     Pending    <span class="number">0</span>          3h50m</span><br><span class="line">kube-system   coredns-5c98db65d4-nrsq7              <span class="number">0</span>/<span class="number">1</span>     Pending    <span class="number">0</span>          3h50m</span><br><span class="line">kube-system   etcd-master-node                      <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">0</span>          3h50m</span><br><span class="line">kube-system   kube-apiserver-master-node            <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">0</span>          3h50m</span><br><span class="line">kube-system   kube-controller-manager-master-node   <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">0</span>          3h50m</span><br><span class="line">kube-system   kube-flannel-ds-amd64-fkzck           <span class="number">0</span>/<span class="number">1</span>     Init:<span class="number">0</span>/<span class="number">1</span>   <span class="number">0</span>          80s</span><br><span class="line">kube-system   kube-proxy-vm9jj                      <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">0</span>          3h50m</span><br><span class="line">kube-system   kube-scheduler-master-node            <span class="number">1</span>/<span class="number">1</span>     Running    <span class="number">0</span>          3h50m</span><br></pre></td></tr></table></figure>
<p>整个过程需要花费一定的时间，知道所有服务都已经启动:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">NAMESPACE     NAME                                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-5c98db65d4-fl5fs              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          3h53m</span><br><span class="line">kube-system   coredns-5c98db65d4-nrsq7              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          3h53m</span><br><span class="line">kube-system   etcd-master-node                      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          3h53m</span><br><span class="line">kube-system   kube-apiserver-master-node            <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          3h53m</span><br><span class="line">kube-system   kube-controller-manager-master-node   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          3h53m</span><br><span class="line">kube-system   kube-flannel-ds-amd64-fkzck           <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          4m4s</span><br><span class="line">kube-system   kube-proxy-vm9jj                      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          3h53m</span><br><span class="line">kube-system   kube-scheduler-master-node            <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          3h53m</span><br></pre></td></tr></table></figure>
<p>这时，再查看节点状态:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line">NAME          STATUS   ROLES    AGE     VERSION</span><br><span class="line">master-node   Ready    master   3h54m   v1<span class="number">.15</span><span class="number">.3</span></span><br></pre></td></tr></table></figure>
<p>可以看到， master节点已经准备就绪。</p>
<h2 id="准备工作节点"><a href="#准备工作节点" class="headerlink" title="准备工作节点"></a>准备工作节点</h2><h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><p>修改主节点的 hostname 为: worker-node01</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo hostnamectl <span class="built_in">set</span>-hostname worker-node01</span><br></pre></td></tr></table></figure>
<h2 id="设置admin配置文件"><a href="#设置admin配置文件" class="headerlink" title="设置admin配置文件"></a>设置admin配置文件</h2><p>将主节点中的 /etc/kubernetes/admin.conf 文件拷贝到从节点相同目录下。</p>
<p>拷贝以后，在从节点执行:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">echo <span class="string">&quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot;</span> &gt;&gt; ~/.bash_profile</span><br></pre></td></tr></table></figure>
<p>执行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure>
<p>是改动立即生效</p>
<h2 id="将节点加入Pod网络"><a href="#将节点加入Pod网络" class="headerlink" title="将节点加入Pod网络"></a>将节点加入Pod网络</h2><p>现在，你可以使用以下命令，加入新的节点(node):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo kubeadm join <span class="number">192.168</span><span class="number">.43</span><span class="number">.10</span>:<span class="number">6443</span> --token mg39mb.hmfz2bao1t90fcdc --discovery-token-ca-cert-<span class="built_in">hash</span> sha256:4343f8637818221cc153a4c556a6a29606f5a14ea040b3e9ee1e5e29af6e7381</span><br></pre></td></tr></table></figure>
<p>系统显示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">	[WARNING IsDockerSystemdCheck]: detected <span class="string">&quot;cgroupfs&quot;</span> <span class="keyword">as</span> the Docker cgroup driver. The recommended driver <span class="keyword">is</span> <span class="string">&quot;systemd&quot;</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">	[WARNING SystemVerification]: this Docker version <span class="keyword">is</span> <span class="keyword">not</span> on the <span class="built_in">list</span> of validated versions: <span class="number">19.03</span><span class="number">.1</span>. Latest validated version: <span class="number">18.09</span></span><br><span class="line">[preflight] Reading configuration <span class="keyword">from</span> the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file <span class="keyword">with</span> <span class="string">&#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span></span><br><span class="line">[kubelet-start] Downloading configuration <span class="keyword">for</span> the kubelet <span class="keyword">from</span> the <span class="string">&quot;kubelet-config-1.15&quot;</span> ConfigMap <span class="keyword">in</span> the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">&quot;/var/lib/kubelet/config.yaml&quot;</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file <span class="keyword">with</span> flags to file <span class="string">&quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span></span><br><span class="line">[kubelet-start] Activating the kubelet service</span><br><span class="line">[kubelet-start] Waiting <span class="keyword">for</span> the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver <span class="keyword">and</span> a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run <span class="string">&#x27;kubectl get nodes&#x27;</span> on the control-plane to see this node join the cluster.</span><br></pre></td></tr></table></figure>
<p>再运行 get nodes 查看:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>
<p>系统显示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">NAME          STATUS   ROLES    AGE    VERSION</span><br><span class="line">kube-master   Ready    master   106m   v1<span class="number">.15</span><span class="number">.3</span></span><br><span class="line">kube-node01   Ready    &lt;none&gt;   96m    v1<span class="number">.15</span><span class="number">.3</span></span><br></pre></td></tr></table></figure>
<p>标明已经安装成功过。</p>
<h2 id="以下为第二种方案-测试失败"><a href="#以下为第二种方案-测试失败" class="headerlink" title="以下为第二种方案 (测试失败)"></a>以下为第二种方案 (测试失败)</h2><p>使用kubeadm的init命令就可以轻松的完成初始化，不过需要携带几个参数，如下。先不要直接复制执行，将赋值给–apiserver-advertise-address参数的 ip 地址修改为自己的master主机地址，然后再执行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubeadm init </span><br><span class="line">--apiserver-advertise-address=<span class="number">192.168</span><span class="number">.56</span><span class="number">.11</span> </span><br><span class="line">--image-repository registry.aliyuncs.com/google_containers  <span class="comment"># 如果失败可以改为 --image-repository </span></span><br><span class="line">--pod-network-cidr=<span class="number">10.244</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">16</span></span><br></pre></td></tr></table></figure>
<p>这里介绍一下一些常用参数的含义：</p>
<p>–apiserver-advertise-address: k8s 中的主要服务apiserver的部署地址，填自己的管理节点 ip<br>–image-repository: 拉取的 docker 镜像源，因为初始化的时候kubeadm会去拉 k8s 的很多组件来进行部署，所以需要指定国内镜像源，下不然会拉取不到镜像。<br>–pod-network-cidr: 这个是 k8s 采用的节点网络，因为我们将要使用flannel作为 k8s 的网络，所以这里填10.244.0.0/16就好<br>–kubernetes-version: 这个是用来指定你要部署的 k8s 版本的，一般不用填，不过如果初始化过程中出现了因为版本不对导致的安装错误的话，可以用这个参数手动指定。<br>–ignore-preflight-errors: 忽略初始化时遇到的错误，比如说我想忽略 cpu 数量不够 2 核引起的错误，就可以用–ignore-preflight-errors=CpuNum。错误名称在初始化错误时会给出来。<br>当你看到如下字样是，就说明初始化成功了，</p>
<h2 id="请把最后那行以kubeadm-join开头的命令复制下来，之后安装工作节点时要用到的，如果你不慎遗失了该命令，可以在master节点上使用kubeadm-token-create-–print-join-command命令来重新生成一条。"><a href="#请把最后那行以kubeadm-join开头的命令复制下来，之后安装工作节点时要用到的，如果你不慎遗失了该命令，可以在master节点上使用kubeadm-token-create-–print-join-command命令来重新生成一条。" class="headerlink" title="请把最后那行以kubeadm join开头的命令复制下来，之后安装工作节点时要用到的，如果你不慎遗失了该命令，可以在master节点上使用kubeadm token create –print-join-command命令来重新生成一条。"></a>请把最后那行以kubeadm join开头的命令复制下来，之后安装工作节点时要用到的，如果你不慎遗失了该命令，可以在master节点上使用kubeadm token create –print-join-command命令来重新生成一条。</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"> </span><br><span class="line">To start using your cluster, you need to run the following <span class="keyword">as</span> a regular user:</span><br><span class="line"> </span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) $HOME/.kube/config</span><br><span class="line"> </span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">&quot;kubectl apply -f [podnetwork].yaml&quot;</span> <span class="keyword">with</span> one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"> </span><br><span class="line">You can now join <span class="built_in">any</span> number of machines by running the following on each node</span><br><span class="line"><span class="keyword">as</span> root:</span><br><span class="line"> </span><br><span class="line">kubeadm join <span class="number">192.168</span><span class="number">.56</span><span class="number">.11</span>:<span class="number">6443</span> --token wbryr0.am1n476fgjsno6wa --discovery-token-ca-cert-<span class="built_in">hash</span> sha256:7640582747efefe7c2d537655e428faa6275dbaff631de37822eb8fd4c054807</span><br></pre></td></tr></table></figure>
<p>如果在初始化过程中出现了任何Error导致初始化终止了，使用kubeadm reset重置之后再重新进行初始化。</p>
<h2 id="配置-kubectl-工具"><a href="#配置-kubectl-工具" class="headerlink" title="配置 kubectl 工具"></a>配置 kubectl 工具</h2><p>这一步就比较简单了，直接执行如下命令即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/.kube &amp;&amp; </span><br><span class="line">cp /etc/kubernetes/admin.conf /root/.kube/config</span><br></pre></td></tr></table></figure>
<p>执行完成后并不会刷新出什么信息，可以通过下面两条命令测试 kubectl是否可用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看已加入的节点</span></span><br><span class="line">kubectl get nodes</span><br><span class="line"><span class="comment"># 查看集群状态</span></span><br><span class="line">kubectl get cs</span><br></pre></td></tr></table></figure>
<h2 id="部署-flannel-网络"><a href="#部署-flannel-网络" class="headerlink" title="部署 flannel 网络"></a>部署 flannel 网络</h2><p>flannel是什么？它是一个专门为 k8s 设置的网络规划服务，可以让集群中的不同节点主机创建的 docker 容器都具有全集群唯一的虚拟IP地址。想要部署flannel的话直接执行下述命令即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>
<p>输出如下内容即为安装完成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clusterrole.rbac.authorization.k8s.io/flannel created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/flannel created</span><br><span class="line">serviceaccount/flannel created</span><br><span class="line">configmap/kube-flannel-cfg created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-amd64 created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-arm64 created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-arm created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-ppc64le created</span><br><span class="line">daemonset.extensions/kube-flannel-ds-s390x created</span><br></pre></td></tr></table></figure>
<p>至此，k8s 管理节点部署完成。</p>
<h2 id="五-将-slave-节点加入网络"><a href="#五-将-slave-节点加入网络" class="headerlink" title="五. 将 slave 节点加入网络"></a>五. 将 slave 节点加入网络</h2><p>首先需要重复步骤 1 ~ 3 来安装 docker 、k8s 以及修改服务器配置，之后执行从步骤 4 中保存的命令即可完成加入，注意，这条命令每个人的都不一样，不要直接复制执行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubeadm join <span class="number">192.168</span><span class="number">.56</span><span class="number">.11</span>:<span class="number">6443</span> --token wbryr0.am1n476fgjsno6wa --discovery-token-ca-cert-<span class="built_in">hash</span> sha256:7640582747efefe7c2d537655e428faa6275dbaff631de37822eb8fd4c054807</span><br></pre></td></tr></table></figure>
<p>待控制台中输出以下内容后即为加入成功：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver <span class="keyword">and</span> a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">Run <span class="string">&#x27;kubectl get nodes&#x27;</span> on the master to see this node join the cluster.</span><br></pre></td></tr></table></figure>
<p>随后登录master1查看已加入节点状态，可以看到worker1已加入，并且状态均为就绪。至此，k8s 搭建完成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">root@master1:~<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME      STATUS   ROLES    AGE    VERSION</span><br><span class="line">master1   Ready    master   145m   v1<span class="number">.15</span><span class="number">.0</span></span><br><span class="line">worker1   Ready    &lt;none&gt;   87m    v1<span class="number">.15</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>
<h2 id="默认网卡问题修复"><a href="#默认网卡问题修复" class="headerlink" title="默认网卡问题修复"></a>默认网卡问题修复</h2><p>如果你是使用virtualBox部署的虚拟机，并且虚拟机直接无法使用网卡1的 ip 地址互相访问的话（例如组建双网卡，网卡1为 NAT 地址转换用来上网，网卡2为Host-only，用于虚拟机之间访问）。就需要执行本节的内容来修改 k8s 的默认网卡。不然会出现一些命令无法使用的问题。如果你的默认网卡可以进行虚拟机之间的相互访问，则没有该问题。</p>
<p>##修改 kubelet 默认地址<br>访问kubelet配置文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo vi /etc/systemd/system/kubelet.service.d/<span class="number">10</span>-kubeadm.conf</span><br></pre></td></tr></table></figure>
<p>在最后一行ExecStart 之前 添加如下内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Environment=<span class="string">&quot;KUBELET_EXTRA_ARGS=--node-ip=192.168.56.21&quot;</span></span><br></pre></td></tr></table></figure>
<p>重启kubelet：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">systemctl stop kubelet.service &amp;&amp; \</span><br><span class="line">systemctl daemon-reload &amp;&amp; \</span><br><span class="line">systemctl start kubelet.service</span><br></pre></td></tr></table></figure>
<p>至此修改完成，更多信息详见 kubectl logs、exec、port-forward 执行失败问题解决 。</p>
<p>＃＃　修改 flannel 的默认网卡<br>编辑flannel配置文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo kubectl edit daemonset kube-flannel-ds-amd64 -n kube-system</span><br></pre></td></tr></table></figure>
<p>找到spec.template.spec.containers.args字段并添加–iface=网卡名，例如我的网卡是enp0s8：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">- args:</span><br><span class="line">  - --ip-masq</span><br><span class="line">  - --kube-subnet-mgr</span><br><span class="line">  <span class="comment"># 添加到这里</span></span><br><span class="line">  - --iface=enp0s8</span><br></pre></td></tr></table></figure>
<p>:wq保存修改后输入以下内容删除所有 flannel，k8s 会自动重建：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">kubectl delete pod -n kube-system -l app=flannel</span><br></pre></td></tr></table></figure>
<p><a href="https://www.jianshu.com/p/fd9941c21e55">至此修改完成，更多内容请见 解决k8s无法通过svc访问其他节点pod的问题</a></p>
<p>总结<br>至此你应该已经搭建好了一个完整可用的双节点 k8s 集群了。接下来你可以通过如下内容继续深入 k8s，排名分先后，推荐依次阅读：</p>
<p><a href="https://www.jianshu.com/p/80c88ae38396">让你的 k8s 使用更简单</a><br><a href="https://www.jianshu.com/p/8d60ce1587e1">k8s 基本使用</a><br><a href="https://www.jianshu.com/p/132319e795ae">k8s 如何让你的应用活的更久</a><br>参考<br><a href="https://links.jianshu.com/go?to=https://www.kubernetes.org.cn/5462.html">kubeadm安装Kubernetes 1.14最佳实践</a><br><a href="https://links.jianshu.com/go?to=https://www.cnblogs.com/hongdada/p/9771857.html">Docker中的Cgroup Driver:Cgroupfs 与 Systemd</a><br><a href="https://links.jianshu.com/go?to=https://blog.csdn.net/qq_14845119/article/details/83349471">Ubuntu16.04搭建Kubernetes</a><br><a href="https://links.jianshu.com/go?to=https://blog.csdn.net/huwh_/article/details/77899108">Flannel介绍</a><br><a href="https://links.jianshu.com/go?to=https://kubernetes.io/docs/home/">k8s 官方文档</a><br>链接：<a href="https://www.jianshu.com/p/f2d4dd4d1fb1">https://www.jianshu.com/p/f2d4dd4d1fb1</a></p>
]]></content>
      <categories>
        <category>docker</category>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>拥抱人工智能，从机器学习开始</title>
    <url>/2020/07/22/12454/</url>
    <content><![CDATA[<h2 id="目录："><a href="#目录：" class="headerlink" title="目录："></a>目录：</h2><h3 id="1-机器学习：一种实现人工智能的方法"><a href="#1-机器学习：一种实现人工智能的方法" class="headerlink" title="1. 机器学习：一种实现人工智能的方法"></a>1. 机器学习：一种实现人工智能的方法</h3><h3 id="2-机器学习算法：是使计算机具有智能的关键"><a href="#2-机器学习算法：是使计算机具有智能的关键" class="headerlink" title="2. 机器学习算法：是使计算机具有智能的关键"></a>2. 机器学习算法：是使计算机具有智能的关键</h3><h3 id="3-Anaconda：初学Python、入门机器学习的首选"><a href="#3-Anaconda：初学Python、入门机器学习的首选" class="headerlink" title="3. Anaconda：初学Python、入门机器学习的首选"></a>3. Anaconda：初学Python、入门机器学习的首选</h3><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h3><h2 id="背景："><a href="#背景：" class="headerlink" title="背景："></a>背景：</h2><p>自“阿尔法狗”（AlphaGo）完胜人类围棋顶尖高手后，有关人工智能（AI）的讨论就从未停歇。工业4.0方兴未艾，人工智能引领的工业5.0时代却已悄然苏醒。<br>人工智能的火爆离不开互联网、云计算、大数据、芯片和软件等技术的发展，而深度学习的进步却是当今人工智能大爆炸的核心驱动。<br>作为一个跨学科产物，人工智能的内容浩如烟海，各种复杂的模型和算法更让人望而生畏。那么作为一个普通程序员，在已有语言技能的前提下，该如何拥抱变化，向人工智能靠拢？如何在自己的工作中应用人工智能？学习人工智能应该从哪里开始？ 人工智能并非遥不可及，人人都可以做人工智能！<br>人工智能是让机器像人一样思考，而机器学习则是人工智能的核心，是使计算机具有智能的根本途径。学习人工智能，首先要了解机器学习的相关算法。 本文我们将与大家一起探讨机器学习的相关算法，共同揭开人工智能的神秘面纱。</p>
<h2 id="1-机器学习"><a href="#1-机器学习" class="headerlink" title="1. 机器学习"></a>1. 机器学习</h2><p>回目录</p>
<p>一种实现人工智能的方法</p>
<p>智能是现代生活中一个很常见的词，例如智能手机、智能家居产品、智能机器人等，但是不同的场合智能的含义也不一样。我们所说的“人工智能”（Artificial Intelligence, AI）则是指让机器像人一样思考，具备人类的智能。</p>
<p>从诞生至今，人工智能这个领域经历了一次又一次的繁荣与低谷，其发展上大体上可以分为“推理期”，“知识期”和“学习期”。推理期主要注重逻辑推理但是感知器过于简单；知识期虽然建立了各种各样的专家系统，但是自主学习能力和神经网络资源能力都不足。学习期机器能够自己学习知识，而直到1980年后，机器学习因其在很多领域的出色表现，才逐渐成为热门学科。近代，随着互联网、云计算、大数据的发展，以及GPU、芯片和软件技术的提升，深度学习开始兴起，拓展了人工智能的领域范围，也推动着社会从数字化向智能化的变革。</p>
<p>人工智能的主要包含几个部分：首先是感知，包括视觉、语音、语言;然后是决策，例如做出预测和判断;最后是反馈，如果想做一套完整的系统，就像机器人或是自动驾驶，则需要一个反馈。 人工智能众多的能力中，很重要的一个能力是其学习能力-机器学习，它是人工智能的核心，是使计算机具有智能的关键。不能自我学习，人工智能也只是徒有其表。</p>
<p>认识人工智能，还需要理清几个概念之间的关系：人工智能是一个大的概念，是让机器像人一样思考甚至超越人类；而机器学习是实现人工智能的一种方法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测；深度学习是机器学习的一种实现方式，通过模拟人神经网络的方式来训练网络；而统计学是机器学习和神经网络的一种基础知识。</p>
<p>机器学习最大的特点是利用数据而不是指令来进行各种工作，其学习过程主要包括：数据的特征提取、数据预处理、训练模型、测试模型、模型评估改进等几部分。接下来我们重点介绍机器学习过程中的常见算法。</p>
<h2 id="2-机器学习算法：是使计算机具有智能的关键-1"><a href="#2-机器学习算法：是使计算机具有智能的关键-1" class="headerlink" title="2. 机器学习算法：是使计算机具有智能的关键"></a>2. 机器学习算法：是使计算机具有智能的关键</h2><p>回目录</p>
<p>是使计算机具有智能的关键 算法是通过使用已知的输入和输出以某种方式“训练”以对特定输入进行响应。代表着用系统的方法描述解决问题的策略机制。人工智能的发展离不开机器学习算法的不断进步。 机器学习算法可以分为传统的机器学习算法和深度学习。传统机器学习算法主要包括以下五类：</p>
<p>回归：建立一个回归方程来预测目标值，用于连续型分布预测<br>分类：给定大量带标签的数据，计算出未知标签样本的标签取值<br>聚类：将不带标签的数据根据距离聚集成不同的簇，每一簇数据有共同的特征<br>关联分析：计算出数据之间的频繁项集合<br>降维：原高维空间中的数据点映射到低维度的空间中</p>
<p>下面我们将选取几种常见的算法，一一介绍。</p>
<h3 id="1-线性回归：找到一条直线来预测目标值"><a href="#1-线性回归：找到一条直线来预测目标值" class="headerlink" title="1. 线性回归：找到一条直线来预测目标值"></a>1. 线性回归：找到一条直线来预测目标值</h3><p>一个简单的场景：已知房屋价格与尺寸的历史数据，问面积为2000时，售价为多少？</p>
<p>此类问题可以用回归算法来解决。回归是指确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，通过建立一个回归方程（函数）来估计特征值对应的目标变量的可能取值。 最常见的是线性回归（Y= a X + b），即找到一条直线来预测目标值。回归的求解就是求解回归方程的回归系数（a，b）的过程，并且使误差最小。 房价场景中，根据房屋面积和售价的关系，求出回归方程，则可以预测给定房屋面积时的售价。</p>
<p>线性回归的应用非常广泛，例如：</p>
<p>预测客户终生价值： 基于老客户历史数据与客户生命周期的关联关系，建立线性回归模型，预测新客户的终生价值，进而开展针对性的活动。</p>
<p>机场客流量分布预测： 以海量机场WiFi数据及安检登机值机数据，通过数据算法实现机场航站楼客流分析与预测。</p>
<p>货币基金资金流入流出预测： 通过用户基本信息数据、用户申购赎回数据、收益率表和银行间拆借利率等信息，对用户的申购赎回数据的把握，精准预测未来每日的资金流入流出情况。</p>
<p>电影票房预测： 依据历史票房数据、影评数据、舆情数据等互联网公众数据，对电影票房进行预测。</p>
<h3 id="2-逻辑回归：找到一条直线来分类数据"><a href="#2-逻辑回归：找到一条直线来分类数据" class="headerlink" title="2. 逻辑回归：找到一条直线来分类数据"></a>2. 逻辑回归：找到一条直线来分类数据</h3><p>逻辑回归虽然名字叫回归，却是属于分类算法，是通过Sigmoid函数将线性函数的结果映射到Sigmoid函数中，预估事件出现的概率并分类。<br>Sigmoid是归一化的函数，可以把连续数值转化为0到1的范围，提供了一种将连续型的数据离散化为离散型数据的方法。<br>因此，逻辑回归从直观上来说是画出了一条分类线。位于分类线一侧的数据，概率&gt;0.5,属于分类A；位于分类线另一侧的数据，概率&lt;0.5,属于分类B。<br>例如图中通过计算患肿瘤的概率，将结果分类两类，分别位于逻辑分类线的两侧。</p>
<h3 id="3-K-近邻：用距离度量最相邻的分类标签"><a href="#3-K-近邻：用距离度量最相邻的分类标签" class="headerlink" title="3. K-近邻：用距离度量最相邻的分类标签"></a>3. K-近邻：用距离度量最相邻的分类标签</h3><p>一个简单的场景：已知一个电影中的打斗和接吻镜头数，判断它是属于爱情片还是动作片。当接吻镜头数较多时，根据经验我们判断它为爱情片。那么计算机如何进行判别呢？</p>
<p>可以使用K近邻算法，其工作原理如下：</p>
<p>计算样本数据中的点与当前点之间的距离<br>算法提取样本最相似数据(最近邻)的分类标签<br>确定前k个点所在类别的出现频率. 一般只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数<br>返回前k个点所出现频率最高的类别作为当前点的预测分类<br>电影分类场景中，k取值为3，按距离依次排序的三个点分别是动作片(108,5)、动作片(115,8)、爱情片(5,89)。在这三个点中，动作片出现的频率为三分之二，爱情片出现的频率为三分之一，所以该红色圆点标记的电影为动作片。</p>
<p>K近邻算法的一个常见应用是手写数字识别。手写字体对于人脑来说，看到的数字是一幅图像，而在电脑看来这是一个二维或三维数组，那怎么对数字进行识别?</p>
<p>使用K近邻算法的进行识别的具体步骤为：</p>
<p>首先将每个图片处理为具有相同的色彩和大小：宽高是32像素x32像素。<br>将3232的二进制图像矩阵转换成11024的测试向量。<br>将训练样本储存在训练矩阵中，创建一个m行1024列的训练矩阵，矩阵的每行数据存储一个图像。<br>计算目标样本与训练样本的距离，选择前k个点所出现频率最高的数字作为当前手写字体的预测分类。</p>
<h3 id="4-朴素贝叶斯：选择后验概率最大的类为分类标签"><a href="#4-朴素贝叶斯：选择后验概率最大的类为分类标签" class="headerlink" title="4. 朴素贝叶斯：选择后验概率最大的类为分类标签"></a>4. 朴素贝叶斯：选择后验概率最大的类为分类标签</h3><p>一个简单的场景：一号碗(C1)有30颗水果糖和10颗巧克力糖，二号碗(C2)有水果糖和巧克力糖各20颗。现在随机选择一个碗，从中摸出一颗糖，发现是水果糖。</p>
<p>问这颗水果糖(X)最有可能来自哪个碗？这类问题可以借助贝叶斯公式来计算，不需要针对目标变量建立模型。在分类时，通过计算样本属于各个类别的概率，然后取概率值大的类别作为分类类别。</p>
<p>P(X|C): 条件概率，C中X出现的概率<br>P(C): 先验概率，C出现的概率<br>P(C|X): 后验概率，X属于C类的概率</p>
<p>假设有 C1 和 C2 两个类，由于 P(X)都是一样的，所以不需要考虑 P(X) 只需考虑如下：<br>如果 P(X|C1)P(C1) &gt; P(X|C2)P(C2)，则 P(C1|X) &gt; P(C2|X)，得 X 属于C1；<br>如果 P(X|C1) P(C1) &lt; P(X|C2) P(C2)，则 P(C2|X) &lt; P(C2|X)，得 X 属于C2。</p>
<p>例如上面的例子中： P(X): 水果糖的概率为5/8<br>P(X|C1): 一号碗中水果糖的概率为3/4<br>P(X|C2): 二号碗中水果糖的概率为2/4<br>P(C1)=P(C2): 两个碗被选中的概率相同，为1/2</p>
<p>则水果糖来自一号碗的概率为:<br>$P(C1|X)=P(X|C1)P(C1)/P(X)=(3/4)(1/2)/(5/8)=3/5<br>水果糖来自二号碗的概率为:<br>P(C2|X)=P(X|C2)P(C2)/P(X)=(2/4)(1/2)/(5/8)=2/5<br>P(C1|X)＞P(C2|X)<br>因此这颗糖最有可能来自一号碗。</p>
<p>朴素贝叶斯的主要应用有文本分类、垃圾文本过滤，情感判别，多分类实时预测等。</p>
<h3 id="5-决策树：构造一棵熵值下降最快的分类树"><a href="#5-决策树：构造一棵熵值下降最快的分类树" class="headerlink" title="5. 决策树：构造一棵熵值下降最快的分类树"></a>5. 决策树：构造一棵熵值下降最快的分类树</h3><p>一个简单的场景：<br>相亲时，可能首先检测相亲对方是否有房。如果有，则考虑进一步接触。如果没有房，则观察其是否有上进心，如果没有，直接Say Goodbye。如果有，则可以列入候选名单。</p>
<p>这就是一个简单的决策树模型。决策树是一种树型结构，其中每个内部结点表示在一个属性上的测试，每个分支代表一个测试输出，每个叶结点代表一种类别。采用的是自顶向下的递归方法，选择信息增益最大的特征作为当前的分裂特征。</p>
<p>决策树可以应于：用户分级评估、贷款风险评估、选股、投标决策等。</p>
<h3 id="6-支持向量机（SVM）：构造超平面，分类非线性数据"><a href="#6-支持向量机（SVM）：构造超平面，分类非线性数据" class="headerlink" title="6. 支持向量机（SVM）：构造超平面，分类非线性数据"></a>6. 支持向量机（SVM）：构造超平面，分类非线性数据</h3><p>一个简单的场景：<br>要求用一根线将不同颜色的球分开，要求尽量在放更多球之后，仍然适用。 A、B两条线都可以满足条件。再继续增加球，线A仍可以将球很好的分开，而线B则不可以。</p>
<p>进一步增加难度，当球没有明确的分界线，用一条直线已经无法将球分开，该怎么解决？</p>
<p>这个场景中涉及支持向量机的的两个问题：</p>
<p>当一个分类问题，数据是线性可分时，只要将线的位置放在让小球距离线的距离最大化的位置即可，寻找这个最大间隔的过程，就叫做最优化。<br>一般的数据是线性不可分的，可以通过核函数，将数据从二维映射到高位，通过超平面将数据切分。<br>不同方向的最优决策面的分类间隔通常是不同的，那个具有“最大间隔”的决策面就是SVM要寻找的最优解。这个真正的最优解对应的两侧虚线所穿过的样本点，就是SVM中的支持样本点，称为支持向量。</p>
<p>SVM的应用非常广泛，可以应用于垃圾邮件识别、手写识别、文本分类、选股等。</p>
<h3 id="7-K-means：计算质心，聚类无标签数据"><a href="#7-K-means：计算质心，聚类无标签数据" class="headerlink" title="7. K-means：计算质心，聚类无标签数据"></a>7. K-means：计算质心，聚类无标签数据</h3><p>在上面介绍的分类算法中，需要被分类的数据集已经有标记，例如数据集已经标记为○或者×，通过学习出假设函数对这两类数据进行划分。而对于没有标记的数据集，希望能有一种算法能够自动的将相同元素分为紧密关系的子集或簇，这就是聚类算法。</p>
<p>举个具体的例子，例如有一批人的年龄的数据，大致知道其中有一堆少年儿童，一堆青年人，一堆老年人。</p>
<p>聚类就是自动发现这三堆数据，并把相似的数据聚合到同一堆中。如果要聚成3堆的话，那么输入就是一堆年龄数据，注意，此时的年龄数据并不带有类标号，也就是说只知道里面大致有三堆人，至于谁是哪一堆，现在是不知道的，而输出就是每个数据所属的类标号，聚类完成之后，就知道谁和谁是一堆了。</p>
<p>而分类就是，事先告诉你，少年儿童、青年人及老年人的年龄是什么样的，现在新来了一个年龄，输入它的年龄，输出她属于的分类。一般分类器是需要训练的，它才能识别新的数据。</p>
<p>K-Means算法是一种常见的聚类算法，其基本步骤为：</p>
<p>随机生成k个初始点作为质心；<br>将数据集中的数据按照距离质心的远近分到各个簇中；<br>将各个簇中的数据求平均值，作为新的质心，重复上一步，直到所有的簇不再改变。 两个分类间隔越远，则聚类效果越好。<br>K-means算法的一个案例是：客户价值细分，精准投资。<br>以航空公司为例，因为业务竞争激烈，企业营销焦点从产品中心转为客户中心；建立合理的客户价值评估模型，进行客户分类，进行精准营销，是解决问题的关键。</p>
<p>识别客户价值，通过五个指标：最近消费时间间隔R，消费频率F，飞行里程 M和折扣系数的平均值C，客户关系长度L（LRFMC模型）。采用K-Means算法对客户数据进行客户分群，聚成五类（需结合业务的理解与分析来确定客户的类别数量）绘制客户群特征雷达图。</p>
<p>客户价值分析：</p>
<p>重要保持客户：C、F、M较高，R低。应将资源优先投放到这类客户身上，进行差异化管理，提高客户的忠诚度和满意度。<br>重要发展客户：C较高，R、F、M较低。这类客户入会时长（L）短、当前价值低、发展潜力大，应促使客户增加在本公司和合作伙伴处的消费。<br>重要挽留客户：C、F 或 M 较高，R较高 或 L变小，客户价值变化的不确定性高。应掌握客户最新信息、维持与客户的互动。<br>一般和低价值客户：C、F、M、L低、R较高。这类客户可能在打折促销时才会选择消费。</p>
<p>K-means算法的一个比较有趣的案例是进行图像压缩。在彩色图像中，每个像素的大小为3字节（RGB），可以表示的颜色总数为256 256 256。利用K-means算法把类似的颜色分别放在K个簇中，因此只需要保留每个像素的标签，以及每个簇的颜色编码即可完成图像的压缩。</p>
<h3 id="8-关联分析：挖掘啤酒与尿布（频繁项集）的关联规则"><a href="#8-关联分析：挖掘啤酒与尿布（频繁项集）的关联规则" class="headerlink" title="8. 关联分析：挖掘啤酒与尿布（频繁项集）的关联规则"></a>8. 关联分析：挖掘啤酒与尿布（频繁项集）的关联规则</h3><p>20世纪90年代美国沃尔玛超市中，超市管理人员分析销售数据时发现 “啤酒”与“尿布”两件看上去毫无关系的商品会经常出现在同一个购物篮中。经过调查发现，这种现象出现在年轻的父亲身上。在美国有婴儿的家庭中，一般是母亲在家中照看婴儿，年轻的父亲去超市买尿布时，往往会顺便为自己购买啤酒。如果在卖场只能买到两件商品之一，他很有可能会放弃购物而去另一家可以同时买到啤酒与尿布的商店。由此，沃尔玛发现了这一独特的现象，开始在卖场尝试将啤酒与尿布摆放在相同区域，让年轻的父亲可以同时找到这两件商品，从而获得了很好的商品销售收入。</p>
<p>“啤酒+尿布”故事中利用的就是关联算法，比较常见的一种关联算法是FP-growth算法。</p>
<p>算法中几个相关的概念：</p>
<p>频繁项集：在数据库中大量频繁出现的数据集合。例如购物单数据中{‘啤酒’}、{‘尿布’}、{‘啤酒’, ‘尿布’}出现的次数都比较多。<br>关联规则：由集合 A，可以在某置信度下推出集合 B。即如果 A 发生了，那么 B 也很有可能会发生。例如购买了{‘尿布’}的人很可能会购买{‘啤酒’}。<br>支持度：指某频繁项集在整个数据集中的比例。假设数据集有 10 条记录，包含{‘啤酒’, ‘尿布’}的有 5 条记录，那么{‘啤酒’, ‘尿布’}的支持度就是 5/10 = 0.5。<br>置信度：有关联规则如{‘尿布’} -&gt; {‘啤酒’}，它的置信度为 {‘尿布’} -&gt; {‘啤酒’}<br>假设{‘尿布’, ‘啤酒’}的支持度为 0.45，{‘尿布’}的支持度为 0.5，则{‘尿布’} -&gt; {‘啤酒’}的置信度为 0.45 / 0.5 = 0.9。</p>
<p>应用比较广泛，例如： 用于制定营销策略。如同啤酒与尿布的例子，超市如果将啤酒和尿布放在相邻的位置，会增加两者的销量。 用于发现共现词。在浏览器中输入”普元”时，浏览器自动弹出如”普元平台”，”普元EOS”等备选记录。 FP-growth算法一个简单的案例：通过购物车数据，分析商品之间的关联关系。</p>
<p>分析步骤为：</p>
<p>从购物车数据中挖掘出频繁项集<br>从频繁项集中产生关联规则，计算支持度<br>输出置信度</p>
<p>根据结果，可以分析出购买了鞋子，极有可能会同时购买袜子；购买了鸡蛋与面包，极有可能会购买牛奶。</p>
<h3 id="9-PCA降维：减少数据维度，降低数据复杂度"><a href="#9-PCA降维：减少数据维度，降低数据复杂度" class="headerlink" title="9. PCA降维：减少数据维度，降低数据复杂度"></a>9. PCA降维：减少数据维度，降低数据复杂度</h3><p>降维是指将原高维空间中的数据点映射到低维度的空间中。因为高维特征的数目巨大，距离计算困难，分类器的性能会随着特征数的增加而下降；减少高维的冗余信息所造成的误差,可以提高识别的精度。</p>
<p>比较常用的是主成分分析算法（PCA）。它是通过某种线性投影，将高维的数据映射到低维的空间中表示，并期望在所投影的维度上数据的方差最大，以此使用较少的数据维度，同时保留住较多的原数据点的特性。</p>
<p>例如对数字进行降维，当使用1个特征向量的时候，3的基本轮廓已经保留下来了，特征向量使用的越多就越与原始数据接近。</p>
<h3 id="10-人工神经网络：逐层抽象，逼近任意函数"><a href="#10-人工神经网络：逐层抽象，逼近任意函数" class="headerlink" title="10. 人工神经网络：逐层抽象，逼近任意函数"></a>10. 人工神经网络：逐层抽象，逼近任意函数</h3><p>前面介绍了九种传统的机器学习算法，现在介绍一下深度学习的基础：人工神经网络。 它是模拟人脑神经网络而设计的模型，由多个节点（人工神经元）相互联结而成，可以用来对数据之间的复杂关系进行建模。不同节点之间的连接被赋予了不同的权重，每个权重代表了一个节点对另一个节点的影响大小。每个节点代表一种特定函数，来自其他节点的信息经过其相应的权重综合计算。是一个可学习的函数，接受不同数据的训练，不断通过调整权重而得到契合实际模型,一个三层的神经网络可以逼近任意的函数。</p>
<p>例如利用单层神经网络实现逻辑与门和同或门。</p>
<p>多层神经网络的每一层神经元学习到的是前一层神经元值的更抽象的表示，通过抽取更抽象的特征来对事物进行区分，从而获得更好的区分与分类能力。例如在图像识别中，第一个隐藏层学习到的是 “边缘”的特征，第二层学习由“边缘”组成的“形状”的特征，第三层学习到的是由“形状”组成的“图案”的特征，最后的隐藏层学习到的是由“图案”组成的“目标”的特征。</p>
<h3 id="11-深度学习：赋予人工智能以璀璨的未来"><a href="#11-深度学习：赋予人工智能以璀璨的未来" class="headerlink" title="11. 深度学习：赋予人工智能以璀璨的未来"></a>11. 深度学习：赋予人工智能以璀璨的未来</h3><p>深度学习是机器学习的分支，是对人工神经网络的发展。深度学习是当今人工智能爆炸的核心驱动，赋予人工智能以璀璨的未来。</p>
<p>看一下深度学习与传统机器学习的区别。传统机器学习特征处理和预测分开，特征处理一般需要人工干预完成。这类模型称为浅层模型，或浅层学习，不涉及特征学习，其特征主要靠人工经验或特征转换方法来抽取。</p>
<p>要提高一种表示方法的表示能力，其关键是构建具有一定深度的多层次特征表示 。一个深层结构的优点是可以增加特征的重用性，从而指数级地增加表示能力。从底层特征开始，一般需要多步非线性转换才能得到较为抽象的高层语义特征。这种自动学习出有效特征的方式称为“表示学习”。</p>
<p>深度学习就是一种基于对数据进行表征学习的方法，使用多层网络，能够学习抽象概念，同时融入自我学习，逐步从大量的样本中逐层抽象出相关的概念，然后做出理解，最终做出判断和决策。通过构建具有一定“深度”的模型，可以让模型来自动学习好的特征表示（从底层特征，到中层特征，再到高层特征），从而最终提升预测或识别的准确性。</p>
<p>目前深度学习的应用十分广泛，例如图像识别、语音识别、机器翻译、自动驾驶、金融风控、智能机器人等。</p>
<h2 id="3-Anaconda：初学Python、入门机器学习的首选-1"><a href="#3-Anaconda：初学Python、入门机器学习的首选-1" class="headerlink" title="3. Anaconda：初学Python、入门机器学习的首选"></a>3. Anaconda：初学Python、入门机器学习的首选</h2><p>回目录</p>
<p>入门机器学习的首选 已经了解了机器学习过程中使用的算法，那么该如何动手实践呢？ Anaconda是初学Python、入门机器学习的首选。它是一个用于科学计算的Python发行版，提供了包管理与环境管理的功能，可以很方便地解决多版本python并存、切换以及各种第三方包安装问题。</p>
<p>集成包功能：</p>
<p>NumPy：提供了矩阵运算的功能，其一般与Scipy、matplotlib一起使用，Python创建的所有更高层工具的基础，不提供高级数据分析功能<br>Scipy：依赖于NumPy，它提供便捷和快速的N维向量数组操作。提供模块用于优化、线性代数、积分以及其它数据科学中的通用任务。<br>Pandas：基于NumPy 的一种工具，该工具是为了解决数据分析任务而创建的，包含高级数据结构，以及和让数据分析变得快速、简单的工具<br>Matplotlib：Python最著名的绘图库<br>其中， Scikit-Learn是Anaconda中集成的开源机器学习工具包，主要涵盖分类，回归和聚类算法，可以直接调用传统机器学习的算法进行使用。同时Anaconda也兼容Google开发的第二代人工智能系统TensorFlow，进行深度学习的开发。</p>
<p>最后通过一个基于Python的决策树案例，来直观了解一下机器学习的过程。 贷款申请的决策树，用以对未来的贷款申请进行分类。</p>
<p>具体实现过程：</p>
<p>准备数据集：从贷款申请样本数据表中，选取对训练数据具有分类能力的特征<br>构建树：选择信息增益最大的特征作为分裂特征构建决策树<br>数据可视化：使用Matplotlib对数据进行可视化<br>执行分类：用于实际数据的分类。例如输入测试数据[0,1]，它代表没有房子，但是有工作，分类结果为“房贷”。</p>
<h2 id="4-总结-1"><a href="#4-总结-1" class="headerlink" title="4. 总结"></a>4. 总结</h2><p>回目录</p>
<p>希望通过本次介绍，大家能够对机器学习涉及的算法有初步的认识，为以后进行相关人工智能方面的研究所有帮助。机器学习其实没有那么复杂，只是将统计学、概率论等数学知识应用在人工智能领域。借助现有的软件平台，可以轻松的调用已经集成的算法，让工程师不再为复杂的算法理论而烦恼，可以有更多的时间去开发和创新！</p>
<p>原文:<a href="https://tianchi.aliyun.com/notebook-ai/detail?postId=6239">天池</a><br>人工智能: <a href="https://tianchi.aliyun.com/forum/postDetail?postId=115954">人工智能基础视频</a></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>获取scrapy request 头部信息及捕捉异常信息</title>
    <url>/2020/07/29/28653/</url>
    <content><![CDATA[<p>获取scrapy request 头部信息 及捕捉异常信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> Amazon.items <span class="keyword">import</span> AmazonItem</span><br><span class="line"><span class="keyword">from</span> scrapy_redis_sentinel.spiders <span class="keyword">import</span> RedisSpider</span><br><span class="line"><span class="keyword">from</span> Amazon.tools <span class="keyword">import</span> GetAmazonUrlCountry , GetLanguage,replace_string, replace_list, formtting_rank,formtting_info,GetAmazonUrlDomain,GetAmazonUrlCID</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> urllib3</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> dateutil.parser <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> Amazon.ConfigDB <span class="keyword">import</span> RedisDB,MongoDB</span><br><span class="line">mongo_conn=MongoDB(<span class="string">&quot;AmazonDB&quot;</span>,<span class="string">&quot;AmazonAddKW&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AmazonkwSpider</span>(<span class="params">RedisSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;amazonkw&#x27;</span></span><br><span class="line">    redis_key = <span class="string">&quot;amazonkw&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># def start_requests(self):</span></span><br><span class="line">    <span class="comment">#     url=&quot;http://httpbin.org/ip&quot;</span></span><br><span class="line">    <span class="comment">#     yield scrapy.Request(url,  callback=self.parse)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># res=response.request.headers</span></span><br><span class="line">        <span class="comment"># print(res)</span></span><br><span class="line">        <span class="comment"># print(response.text)</span></span><br></pre></td></tr></table></figure>
<h2 id="scrapy-middleware中间件"><a href="#scrapy-middleware中间件" class="headerlink" title="scrapy  middleware中间件"></a>scrapy  middleware中间件</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define here the models for your spider middleware</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://docs.scrapy.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> dateutil.parser <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> Amazon.ConfigDB <span class="keyword">import</span> RedisDB,RedisPool,MongoDB</span><br><span class="line"><span class="keyword">from</span> Amazon.tools <span class="keyword">import</span> GetAmazonUrlCountry , GetLanguage,replace_string, replace_list, formtting_rank,formtting_info,GetAmazonUrlDomain,GetAmazonUrlCID</span><br><span class="line">redis_ua=RedisPool()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AmazonSpiderMiddleware</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="comment"># Not all methods need to be defined. If a method is not defined,</span></span><br><span class="line">    <span class="comment"># scrapy acts as if the spider middleware does not modify the</span></span><br><span class="line">    <span class="comment"># passed objects.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler</span>):</span></span><br><span class="line">        <span class="comment"># This method is used by Scrapy to create your spiders.</span></span><br><span class="line">        s = cls()</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_spider_input</span>(<span class="params">self, response, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called for each response that goes through the spider</span></span><br><span class="line">        <span class="comment"># middleware and into the spider.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Should return None or raise an exception.</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_spider_output</span>(<span class="params">self, response, result, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called with the results returned from the Spider, after</span></span><br><span class="line">        <span class="comment"># it has processed the response.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Must return an iterable of Request, dict or Item objects.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">            <span class="keyword">yield</span> i</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_spider_exception</span>(<span class="params">self, response, exception, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called when a spider or process_spider_input() method</span></span><br><span class="line">        <span class="comment"># (from other spider middleware) raises an exception.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Should return either None or an iterable of Request, dict</span></span><br><span class="line">        <span class="comment"># or Item objects.</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_start_requests</span>(<span class="params">self, start_requests, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called with the start requests of the spider, and works</span></span><br><span class="line">        <span class="comment"># similarly to the process_spider_output() method, except</span></span><br><span class="line">        <span class="comment"># that it doesn’t have a response associated.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Must return only requests (not items).</span></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> start_requests:</span><br><span class="line">            <span class="keyword">yield</span> r</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_opened</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        spider.logger.info(<span class="string">&#x27;Spider opened: %s&#x27;</span> % spider.name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DownloaderMiddleware</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="comment"># Not all methods need to be defined. If a method is not defined,</span></span><br><span class="line">    <span class="comment"># scrapy acts as if the downloader middleware does not modify the</span></span><br><span class="line">    <span class="comment"># passed objects.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls, crawler</span>):</span></span><br><span class="line">        <span class="comment"># This method is used by Scrapy to create your spiders.</span></span><br><span class="line">        s = cls()</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called for each request that goes through the downloader</span></span><br><span class="line">        <span class="comment"># middleware.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Must either:</span></span><br><span class="line">        <span class="comment"># - return None: continue processing this request</span></span><br><span class="line">        <span class="comment"># - or return a Response object</span></span><br><span class="line">        <span class="comment"># - or return a Request object</span></span><br><span class="line">        <span class="comment"># - or raise IgnoreRequest: process_exception() methods of</span></span><br><span class="line">        <span class="comment">#   installed downloader middleware will be called</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_response</span>(<span class="params">self, request, response, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called with the response returned from the downloader.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Must either;</span></span><br><span class="line">        <span class="comment"># - return a Response object</span></span><br><span class="line">        <span class="comment"># - return a Request object</span></span><br><span class="line">        <span class="comment"># - or raise IgnoreRequest</span></span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span></span><br><span class="line">        <span class="comment"># Called when a download handler or a process_request()</span></span><br><span class="line">        <span class="comment"># (from other downloader middleware) raises an exception.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Must either:</span></span><br><span class="line">        <span class="comment"># - return None: continue processing this exception</span></span><br><span class="line">        <span class="comment"># - return a Response object: stops process_exception() chain</span></span><br><span class="line">        <span class="comment"># - return a Request object: stops process_exception() chain</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_opened</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        spider.logger.info(<span class="string">&#x27;Spider opened: %s&#x27;</span> % spider.name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment"># from scrapy.contrib.downloadermiddleware.useragent import UserAgentMiddleware</span></span><br><span class="line"><span class="keyword">from</span> Amazon.settings <span class="keyword">import</span> USER_AGENTS</span><br><span class="line"><span class="comment"># from settings import PROXIES</span></span><br><span class="line"><span class="comment"># class RandomUserAgent(UserAgentMiddleware):</span></span><br><span class="line"><span class="comment">#     def process_request(self, request, spider):</span></span><br><span class="line"><span class="comment">#         _ua = random.choice(USER_AGENTS)</span></span><br><span class="line"><span class="comment">#         request.headers.setdefault(&#x27;User-Agent&#x27;, _ua)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># class ProxyMiddleware(object):</span></span><br><span class="line"><span class="comment"># 	def process_request(self, request, spider):</span></span><br><span class="line"><span class="comment">#         proxy = requests.get(&quot;http://172.20.0.252:5010/get/&quot;)</span></span><br><span class="line">		<span class="comment"># proxy = random.choice(PROXIES)print(proxy,&quot;*&quot;*100)</span></span><br><span class="line">		<span class="comment"># if proxy[&#x27;user_pass&#x27;] is not None:</span></span><br><span class="line">		<span class="comment"># 	request.meta[&#x27;proxy&#x27;] = &quot;http://%s&quot; % proxy[&#x27;ip_port&#x27;]</span></span><br><span class="line">		<span class="comment"># 	encoded_user_pass = base64.encodestring(proxy[&#x27;user_pass&#x27;])</span></span><br><span class="line">		<span class="comment"># 	request.headers[&#x27;Proxy-Authorization&#x27;] = &#x27;Basic &#x27; + encoded_user_pass</span></span><br><span class="line">		<span class="comment"># 	print (&quot;**************ProxyMiddleware have pass************&quot;) + proxy[&#x27;ip_port&#x27;]</span></span><br><span class="line">		<span class="comment"># else:</span></span><br><span class="line">		<span class="comment"># 	# print (&quot;**************ProxyMiddleware no pass************&quot;) + proxy[&#x27;ip_port&#x27;]</span></span><br><span class="line">		<span class="comment"># 	request.meta[&#x27;proxy&#x27;] = &quot;http://%s&quot; % proxy[&#x27;ip_port&#x27;]</span></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"><span class="keyword">from</span> w3lib.http <span class="keyword">import</span> basic_auth_header</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.retry <span class="keyword">import</span> RetryMiddleware</span><br><span class="line"></span><br><span class="line"><span class="comment"># 代理服务器</span></span><br><span class="line">proxyServer = <span class="string">&quot;http://http-dyn.abuyun.com:9020&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代理隧道验证信息</span></span><br><span class="line">proxyUser = <span class="string">&quot;H6587BH09900664D&quot;</span></span><br><span class="line">proxyPass = <span class="string">&quot;20C4314AF6C62E0F&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># for Python2</span></span><br><span class="line"><span class="comment"># proxyAuth = &quot;Basic &quot; + base64.b64encode(proxyUser + &quot;:&quot; + proxyPass)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># for Python3</span></span><br><span class="line">proxyAuth = <span class="string">&quot;Basic &quot;</span> + base64.urlsafe_b64encode(<span class="built_in">bytes</span>((proxyUser + <span class="string">&quot;:&quot;</span> + proxyPass), <span class="string">&quot;ascii&quot;</span>)).decode(<span class="string">&quot;utf8&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomProxy</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">        request.meta[<span class="string">&quot;proxy&quot;</span>] = proxyServer</span><br><span class="line">        self.ua =  redis_ua.sget(<span class="string">&quot;user-agent&quot;</span>)</span><br><span class="line">        request.headers[<span class="string">&quot;User-Agent&quot;</span>]=<span class="built_in">str</span>(self.ua,encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">        request.headers[<span class="string">&quot;Proxy-Authorization&quot;</span>] = proxyAuth  </span><br><span class="line">        <span class="comment"># print(request)</span></span><br><span class="line">        request.cookies=&#123;</span><br><span class="line">            <span class="string">&quot;session-id&quot;</span>:<span class="string">&quot;134-0075797-0381056&quot;</span>,</span><br><span class="line">            <span class="string">&quot;session-id-time&quot;</span>:<span class="string">&quot;2082787201l&quot;</span>,</span><br><span class="line">            <span class="string">&quot;i18n-prefs&quot;</span>:<span class="string">&quot;USD&quot;</span>,</span><br><span class="line">            <span class="string">&quot;lc-main&quot;</span>:<span class="string">&quot;en_US&quot;</span>,</span><br><span class="line">            <span class="string">&quot;sp-cdn&quot;</span>:<span class="string">&quot;L5Z9:CN&quot;</span>,</span><br><span class="line">            <span class="string">&quot;ubid-main&quot;</span>:<span class="string">&quot;134-0448665-3732200&quot;</span>,</span><br><span class="line">            <span class="string">&quot;session-token&quot;</span>:<span class="string">&quot;KBeUZ2ocx7ObasfCr4XpPQE7t5RPj80VGzKb+EbFEEAMWbzwl8YuNtcPmqhZ6kUUtVxpwwOJSOy0XvZvPIKuxoUIgKbIuo6Z3qaX1Lk/0ewvaJY55aR+ayz/kJ9jUmL2HhLMwE8ipxIPqc/lzRRpAUxD4DuCd2PidfXY+sG5IhTVooAuK4UMzq1gB3Azo/BO&quot;</span></span><br><span class="line">        &#125;  </span><br><span class="line">    <span class="comment"># def process_request(self, request, spider):</span></span><br><span class="line">        <span class="comment"># proxy = &quot;tps121.kdlapi.com:15818&quot;</span></span><br><span class="line">        <span class="comment"># request.meta[&#x27;proxy&#x27;] = &quot;https://%s&quot; %proxy</span></span><br><span class="line">        <span class="comment"># # 用户名密码认证</span></span><br><span class="line">        <span class="comment"># request.headers[&#x27;Proxy-Authorization&#x27;] = basic_auth_header(&#x27;t19351016044852&#x27;, &#x27;y4asuamy&#x27;)  # 白名单认证可注释此行</span></span><br><span class="line">        <span class="comment"># return None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># def __init__(self):</span></span><br><span class="line">    <span class="comment">#     self.proxy =  redis_ua.sget(&quot;daxiangIP&quot;)</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># def process_request(self,request, spider):</span></span><br><span class="line">        <span class="comment"># proxy = requests.get(&quot;http://172.20.0.252:5010/get/&quot;).content</span></span><br><span class="line">        <span class="comment"># proxy=eval(str(proxy,encoding=&quot;utf-8&quot;))[&quot;proxy&quot;]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(&quot;ip_proxy=&#123;&#125;&quot;.format(str(self.proxy,encoding=&quot;utf8&quot;)),&quot;*&quot;*30)</span></span><br><span class="line">        <span class="comment"># request.meta[&#x27;proxy&#x27;] = &#x27;https://27.188.65.244:8060&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># from fake_useragent import UserAgent</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgentMiddlware</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="comment">#随机更换user-agent</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,crawler</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RandomUserAgentMiddlware,self).__init__()</span><br><span class="line">        <span class="comment"># self.ua =  random.choice(USER_AGENTS)</span></span><br><span class="line">        self.ua =  redis_ua.sget(<span class="string">&quot;user-agent&quot;</span>)</span><br><span class="line">        <span class="comment"># redis_ua.rpush(&#x27;user-agent&#x27;,self.ua)</span></span><br><span class="line">        self.ua=<span class="built_in">str</span>(self.ua,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        <span class="comment"># self.ua =  UserAgent(verify_ssl=False)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span>(<span class="params">cls,crawler</span>):</span></span><br><span class="line">        <span class="keyword">return</span> cls(crawler)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self,request,spider</span>):</span></span><br><span class="line">        request.headers.setdefault(<span class="string">&quot;User-Agent&quot;</span>,self.ua)</span><br><span class="line">        <span class="comment"># request.headers.setdefault(&quot;User-Agent&quot;,self.ua.random)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GetFailedUrl</span>(<span class="params">RetryMiddleware</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, settings</span>):</span></span><br><span class="line">        self.max_retry_times = settings.getint(<span class="string">&#x27;RETRY_TIMES&#x27;</span>)</span><br><span class="line">        self.retry_http_codes = <span class="built_in">set</span>(<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> settings.getlist(<span class="string">&#x27;RETRY_HTTP_CODES&#x27;</span>))</span><br><span class="line">        self.priority_adjust = settings.getint(<span class="string">&#x27;RETRY_PRIORITY_ADJUST&#x27;</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_response</span>(<span class="params">self, request, response, spider</span>):</span></span><br><span class="line">        <span class="comment"># print(response.text)</span></span><br><span class="line">        <span class="keyword">if</span> response.status != <span class="number">200</span> <span class="keyword">or</span> <span class="string">R&quot;robot check&quot;</span> <span class="keyword">in</span> response.text:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="built_in">str</span>(spider.name) + <span class="string">&quot;.txt&quot;</span>, <span class="string">&quot;a&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(response.url + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            <span class="comment"># print(response.url,&quot;*&quot;*100)</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">R&quot;www.amazon.com/s?k=&quot;</span> <span class="keyword">in</span> request_url:</span><br><span class="line">                db = MongoDB(<span class="string">&quot;AddTask&quot;</span>,<span class="string">&quot;Add_List&quot;</span>)</span><br><span class="line">                items=&#123;&#125;</span><br><span class="line">                items[<span class="string">&quot;cid&quot;</span>]=GetAmazonUrlCID(request_url)</span><br><span class="line">                items[<span class="string">&#x27;kwURL&#x27;</span>]=[]</span><br><span class="line">                items[<span class="string">&#x27;Finished_time&#x27;</span>]=parse(<span class="built_in">str</span>(datetime.now())[<span class="number">0</span>:<span class="number">19</span>])</span><br><span class="line">                items[<span class="string">&#x27;link_url&#x27;</span>]=request_url</span><br><span class="line">                items[<span class="string">&#x27;status&#x27;</span>]=<span class="string">&quot;failed&quot;</span></span><br><span class="line">                items[<span class="string">&#x27;error&#x27;</span>]=<span class="built_in">str</span>(exception)</span><br><span class="line">                <span class="keyword">if</span> db.getInfo(&#123;<span class="string">&#x27;id&#x27;</span>:<span class="built_in">int</span>(items[<span class="string">&quot;cid&quot;</span>])&#125;):</span><br><span class="line">                    db.updateDict(&#123;<span class="string">&#x27;id&#x27;</span>:<span class="built_in">int</span>(items[<span class="string">&#x27;cid&#x27;</span>])&#125;,&#123;<span class="string">&#x27;$set&#x27;</span>:items&#125;)</span><br><span class="line">                <span class="comment"># print(&quot;*&quot;*100,str(exception))</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                db_ = MongoDB(<span class="string">&quot;AmazonDB&quot;</span>,<span class="string">&quot;AmazonContent&quot;</span>)</span><br><span class="line">                items=&#123;&#125;</span><br><span class="line">                items[<span class="string">&#x27;id&#x27;</span>]=db_.getID(<span class="string">&quot;amazonUrl&quot;</span>)</span><br><span class="line">                items[<span class="string">&quot;cid&quot;</span>]=GetAmazonUrlCID(request_url)</span><br><span class="line">                items[<span class="string">&#x27;Finished_time&#x27;</span>]=parse(<span class="built_in">str</span>(datetime.now())[<span class="number">0</span>:<span class="number">19</span>])</span><br><span class="line">                items[<span class="string">&#x27;link_url&#x27;</span>]=request_url</span><br><span class="line">                items[<span class="string">&#x27;status&#x27;</span>]=<span class="string">&quot;failed&quot;</span></span><br><span class="line">                items[<span class="string">&#x27;error&#x27;</span>]=<span class="built_in">str</span>(exception)</span><br><span class="line">                db_.insertDict(items)</span><br><span class="line">            <span class="keyword">return</span> request</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> response</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(exception, self.EXCEPTIONS_TO_RETRY):</span><br><span class="line">            request_url=<span class="built_in">str</span>(request)[<span class="number">5</span>:-<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="built_in">str</span>(spider.name) + <span class="string">&quot;.txt&quot;</span>, <span class="string">&quot;a&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(request_url + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">                print(<span class="string">&quot;*&quot;</span>*<span class="number">20</span>,request_url)</span><br><span class="line">            <span class="keyword">if</span> <span class="string">R&quot;www.amazon.com/s?k=&quot;</span> <span class="keyword">in</span> request_url:</span><br><span class="line">                db = MongoDB(<span class="string">&quot;AddTask&quot;</span>,<span class="string">&quot;Add_List&quot;</span>)</span><br><span class="line">                items=&#123;&#125;</span><br><span class="line">                items[<span class="string">&quot;cid&quot;</span>]=GetAmazonUrlCID(request_url)</span><br><span class="line">                items[<span class="string">&#x27;kwURL&#x27;</span>]=[]</span><br><span class="line">                items[<span class="string">&#x27;Finished_time&#x27;</span>]=parse(<span class="built_in">str</span>(datetime.now())[<span class="number">0</span>:<span class="number">19</span>])</span><br><span class="line">                items[<span class="string">&#x27;link_url&#x27;</span>]=request_url</span><br><span class="line">                items[<span class="string">&#x27;status&#x27;</span>]=<span class="string">&quot;failed&quot;</span></span><br><span class="line">                items[<span class="string">&#x27;error&#x27;</span>]=<span class="built_in">str</span>(exception)</span><br><span class="line">                <span class="keyword">if</span> db.getInfo(&#123;<span class="string">&#x27;id&#x27;</span>:<span class="built_in">int</span>(items[<span class="string">&quot;cid&quot;</span>])&#125;):</span><br><span class="line">                    db.updateDict(&#123;<span class="string">&#x27;id&#x27;</span>:<span class="built_in">int</span>(items[<span class="string">&#x27;cid&#x27;</span>])&#125;,&#123;<span class="string">&#x27;$set&#x27;</span>:items&#125;)</span><br><span class="line">                <span class="comment"># print(&quot;*&quot;*100,str(exception))</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                db_ = MongoDB(<span class="string">&quot;AmazonDB&quot;</span>,<span class="string">&quot;AmazonContent&quot;</span>)</span><br><span class="line">                items=&#123;&#125;</span><br><span class="line">                items[<span class="string">&#x27;id&#x27;</span>]=db_.getID(<span class="string">&quot;amazonUrl&quot;</span>)</span><br><span class="line">                items[<span class="string">&quot;cid&quot;</span>]=GetAmazonUrlCID(request_url)</span><br><span class="line">                items[<span class="string">&#x27;Finished_time&#x27;</span>]=parse(<span class="built_in">str</span>(datetime.now())[<span class="number">0</span>:<span class="number">19</span>])</span><br><span class="line">                items[<span class="string">&#x27;link_url&#x27;</span>]=request_url</span><br><span class="line">                items[<span class="string">&#x27;status&#x27;</span>]=<span class="string">&quot;failed&quot;</span></span><br><span class="line">                items[<span class="string">&#x27;error&#x27;</span>]=<span class="built_in">str</span>(exception)</span><br><span class="line">                db_.insertDict(items)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># from scrapy import signals</span></span><br><span class="line"><span class="comment"># import pyppeteer</span></span><br><span class="line"><span class="comment"># import asyncio</span></span><br><span class="line"><span class="comment"># import os</span></span><br><span class="line"><span class="comment"># import json</span></span><br><span class="line"><span class="comment"># import redis</span></span><br><span class="line"><span class="comment"># from scrapy.http import HtmlResponse</span></span><br><span class="line"><span class="comment"># from Amazon.ConfigDB import RedisDB,RedisPool,MongoDB</span></span><br><span class="line"><span class="comment"># import logging</span></span><br><span class="line"><span class="comment"># pyppeteer_level = logging.WARNING</span></span><br><span class="line"><span class="comment"># logging.getLogger(&#x27;pyppeteer&#x27;).setLevel(pyppeteer_level)</span></span><br><span class="line"><span class="comment"># logging.getLogger(&#x27;websockets.protocol&#x27;).setLevel(pyppeteer_level)</span></span><br><span class="line"><span class="comment"># pyppeteer_logger = logging.getLogger(&#x27;pyppeteer&#x27;)</span></span><br><span class="line"><span class="comment"># pyppeteer_logger.setLevel(logging.WARNING)</span></span><br><span class="line"><span class="comment"># # redisconn=RedisDB(db=0)</span></span><br><span class="line"><span class="comment"># redis_ua = RedisPool()</span></span><br><span class="line"><span class="comment"># pyppeteer.DEBUG = False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># def _patch_pyppeteer():</span></span><br><span class="line"><span class="comment">#     from typing import Any</span></span><br><span class="line"><span class="comment">#     from pyppeteer import connection, launcher</span></span><br><span class="line"><span class="comment">#     import websockets.client</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     class PatchedConnection(connection.Connection):  # type: ignore</span></span><br><span class="line"><span class="comment">#         def __init__(self, *args: Any, **kwargs: Any) -&gt; None:</span></span><br><span class="line"><span class="comment">#             super().__init__(*args, **kwargs)</span></span><br><span class="line"><span class="comment">#             # the _ws argument is not yet connected, can simply be replaced with another</span></span><br><span class="line"><span class="comment">#             # with better defaults.</span></span><br><span class="line"><span class="comment">#             self._ws = websockets.client.connect(</span></span><br><span class="line"><span class="comment">#                 self._url,</span></span><br><span class="line"><span class="comment">#                 loop=self._loop,</span></span><br><span class="line"><span class="comment">#                 # the following parameters are all passed to WebSocketCommonProtocol</span></span><br><span class="line"><span class="comment">#                 # which markes all three as Optional, but connect() doesn&#x27;t, hence the liberal</span></span><br><span class="line"><span class="comment">#                 # use of type: ignore on these lines.</span></span><br><span class="line"><span class="comment">#                 # fixed upstream but not yet released, see aaugustin/websockets#93ad88</span></span><br><span class="line"><span class="comment">#                 max_size=None,  # type: ignore</span></span><br><span class="line"><span class="comment">#                 ping_interval=None,  # type: ignore</span></span><br><span class="line"><span class="comment">#                 ping_timeout=None,  # type: ignore</span></span><br><span class="line"><span class="comment">#             )</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     connection.Connection = PatchedConnection</span></span><br><span class="line"><span class="comment">#     # also imported as a  global in pyppeteer.launcher</span></span><br><span class="line"><span class="comment">#     launcher.Connection = PatchedConnection</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># class DownloaderMiddleware(object):</span></span><br><span class="line"><span class="comment">#     # Not all methods need to be defined. If a method is not defined,</span></span><br><span class="line"><span class="comment">#     # scrapy acts as if the downloader middleware does not modify the</span></span><br><span class="line"><span class="comment">#     # passed objects.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     def __init__(self):</span></span><br><span class="line"><span class="comment">#         # print(&quot;Init downloaderMiddleware use pypputeer.&quot;)</span></span><br><span class="line"><span class="comment">#         # os.environ[&#x27;PYPPETEER_CHROMIUM_REVISION&#x27;] = &#x27;588429&#x27;</span></span><br><span class="line"><span class="comment">#         # pyppeteer.DEBUG = False</span></span><br><span class="line"><span class="comment">#         print(os.environ.get(&#x27;PYPPETEER_CHROMIUM_REVISION&#x27;))</span></span><br><span class="line"><span class="comment">#         loop = asyncio.get_event_loop()</span></span><br><span class="line"><span class="comment">#         task = asyncio.ensure_future(self.getbrowser())</span></span><br><span class="line"><span class="comment">#         loop.run_until_complete(task)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#         # self.browser = task.result()</span></span><br><span class="line"><span class="comment">#         # print(self.browser)</span></span><br><span class="line"><span class="comment">#         # print(self.page)</span></span><br><span class="line"><span class="comment">#         # self.page = await browser.newPage()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     async def getbrowser(self):</span></span><br><span class="line"><span class="comment">#         ua=redis_ua.sget(&quot;user-agent&quot;)</span></span><br><span class="line"><span class="comment">#         redis_ua.rpush(&#x27;user-agent&#x27;,ua)</span></span><br><span class="line"><span class="comment">#         # proxies=redis_ua.sget(&quot;daxiangIP&quot;)</span></span><br><span class="line"><span class="comment">#         # redisconn.lpush(&#x27;proxies:ipx&#x27;,proxies)</span></span><br><span class="line"><span class="comment">#         # Proxies=str(proxies,encoding=&#x27;utf-8&#x27;)</span></span><br><span class="line"><span class="comment">#         # print(ua,Proxies,&quot;&gt;&quot;*30)</span></span><br><span class="line"><span class="comment">#         # self.browser = await pyppeteer.launch(&#123;&#x27;headless&#x27;: False,&#x27;timeout&#x27;:0, </span></span><br><span class="line"><span class="comment">#         #                                   &#x27;args&#x27;: [</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--window-size=&#123;1300&#125;,&#123;600&#125;&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--disable-extensions&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--hide-scrollbars&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--disable-bundled-ppapi-flash&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--mute-audio&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--no-sandbox&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--disable-setuid-sandbox&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--disable-gpu&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--disable-infobars&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                       &#x27;--proxy-server=http://http-dyn.abuyun.com:9020&#x27;,</span></span><br><span class="line"><span class="comment">#         #                                   ],</span></span><br><span class="line"><span class="comment">#         #                                   &#x27;dumpio&#x27;: True</span></span><br><span class="line"><span class="comment">#         #                                   &#125;)</span></span><br><span class="line"><span class="comment">#         self.browser = await pyppeteer.connect(&#123;&#x27;browserWSEndpoint&#x27;: &#x27;ws://172.20.3.221:3000?--proxy-server=http://http-dyn.abuyun.com:9020&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #     &#x27;headless&#x27;: False,&#x27;timeout&#x27;:0,</span></span><br><span class="line"><span class="comment">#         # #                                 #     &#x27;args&#x27;: [</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--window-size=&#123;1300&#125;,&#123;600&#125;&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--disable-extensions&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--hide-scrollbars&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--disable-bundled-ppapi-flash&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--mute-audio&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--no-sandbox&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--disable-setuid-sandbox&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--disable-gpu&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--disable-infobars&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #       &#x27;--proxy-server=http://http-dyn.abuyun.com:9020&#x27;,</span></span><br><span class="line"><span class="comment">#         # #                                 #   ],</span></span><br><span class="line"><span class="comment">#         # #                                 #   &#x27;dumpio&#x27;: True</span></span><br><span class="line"><span class="comment">#                                             &#125;)</span></span><br><span class="line"><span class="comment">#         self.page = await self.browser.newPage()</span></span><br><span class="line"><span class="comment">#         # await page.setExtraHTTPHeaders(&#123;&#x27;Proxy-Authorization&#x27;: &#x27;Basic H6587BH09900664D:20C4314AF6C62E0F&#x27;&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#         await self.page.authenticate(&#123;&quot;username&quot;: &quot;H6587BH09900664D&quot;, &quot;password&quot;: &quot;20C4314AF6C62E0F&quot;&#125;)          </span></span><br><span class="line"><span class="comment">#         # await self.page.setExtraHTTPHeaders(&quot;http://http-dyn.abuyun.com:9020&quot;) </span></span><br><span class="line"><span class="comment">#         # await self.page.setCookie(cookie)</span></span><br><span class="line"><span class="comment">#         await self.page.setViewport(viewport=&#123;&#x27;width&#x27;: 1366, &#x27;height&#x27;: 768&#125;)</span></span><br><span class="line"><span class="comment">#         await self.page.setUserAgent(str(ua,encoding=&#x27;utf-8&#x27;))</span></span><br><span class="line"><span class="comment">#         # await self.page.setUserAgent(&quot;Chrome (AppleWebKit/537.1; Chrome50.0; Windows NT 6.3) AppleWebKit/537.36 (KHTML like Gecko) Chrome/51.0.2704.79 Safari/537.36 Edge/14.14393&quot;)</span></span><br><span class="line"><span class="comment">#         await self.page.setJavaScriptEnabled(enabled=True)</span></span><br><span class="line"><span class="comment">#         await self.page.evaluate(</span></span><br><span class="line"><span class="comment">#             &#x27;&#x27;&#x27;() =&gt;&#123; Object.defineProperties(navigator,&#123; webdriver:&#123; get: () =&gt; false &#125; &#125;) &#125;&#x27;&#x27;&#x27;)  </span></span><br><span class="line"><span class="comment">#         await self.page.evaluate(&#x27;&#x27;&#x27;() =&gt;&#123; window.navigator.chrome = &#123; runtime: &#123;&#125;,  &#125;; &#125;&#x27;&#x27;&#x27;)</span></span><br><span class="line"><span class="comment">#         await self.page.evaluate(</span></span><br><span class="line"><span class="comment">#             &#x27;&#x27;&#x27;() =&gt;&#123; Object.defineProperty(navigator, &#x27;languages&#x27;, &#123; get: () =&gt; [&#x27;en-US&#x27;, &#x27;en&#x27;] &#125;); &#125;&#x27;&#x27;&#x27;)</span></span><br><span class="line"><span class="comment">#         await self.page.evaluate(</span></span><br><span class="line"><span class="comment">#             &#x27;&#x27;&#x27;() =&gt;&#123; Object.defineProperty(navigator, &#x27;plugins&#x27;, &#123; get: () =&gt; [1, 2, 3, 4, 5,6], &#125;); &#125;&#x27;&#x27;&#x27;)</span></span><br><span class="line"><span class="comment">#         await self.page.waitFor(10000)</span></span><br><span class="line"><span class="comment">#         # cooki=redisconn.get(&quot;ali1688cookie&quot;)</span></span><br><span class="line"><span class="comment">#         # redisconn.rpush(&#x27;ali1688cookie&#x27;,cooki)</span></span><br><span class="line"><span class="comment">#         # cookieStr=str(cooki,encoding=&#x27;utf-8&#x27;)</span></span><br><span class="line"><span class="comment">#         # for cook in json.loads(cookieStr):</span></span><br><span class="line"><span class="comment">#         #     await self.page.setCookie(cook)</span></span><br><span class="line"><span class="comment">#         return self.page</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#     @classmethod</span></span><br><span class="line"><span class="comment">#     def from_crawler(cls, crawler):</span></span><br><span class="line"><span class="comment">#         # This method is used by Scrapy to create your spiders.</span></span><br><span class="line"><span class="comment">#         s = cls()</span></span><br><span class="line"><span class="comment">#         crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span></span><br><span class="line"><span class="comment">#         return s</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     def process_request(self, request, spider):</span></span><br><span class="line"><span class="comment">#         # Called for each request that goes through the downloader</span></span><br><span class="line"><span class="comment">#         # middleware.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#         # Must either:</span></span><br><span class="line"><span class="comment">#         # - return None: continue processing this request</span></span><br><span class="line"><span class="comment">#         # - or return a Response object</span></span><br><span class="line"><span class="comment">#         # - or return a Request object</span></span><br><span class="line"><span class="comment">#         # - or raise IgnoreRequest: process_exception() methods of</span></span><br><span class="line"><span class="comment">#         #   installed downloader middleware will be called</span></span><br><span class="line"><span class="comment">#         loop = asyncio.get_event_loop()</span></span><br><span class="line"><span class="comment">#         task = asyncio.ensure_future(self.usePypuppeteer(request))</span></span><br><span class="line"><span class="comment">#         loop.run_until_complete(task)</span></span><br><span class="line"><span class="comment">#         # return task.result()</span></span><br><span class="line"><span class="comment">#         return HtmlResponse(url=request.url, body=task.result(), encoding=&quot;utf-8&quot;, request=request)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     async def intercept_request(self,req):</span></span><br><span class="line"><span class="comment">#         if req.resourceType in [&#x27;image&#x27;, &#x27;media&#x27;, &#x27;eventsource&#x27;, &#x27;websocket&#x27;]:</span></span><br><span class="line"><span class="comment">#             await req.abort()</span></span><br><span class="line"><span class="comment">#         else:</span></span><br><span class="line"><span class="comment">#             await req.continue_()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     async def intercept_response(self,res):</span></span><br><span class="line"><span class="comment">#         resourceType = res.request.resourceType</span></span><br><span class="line"><span class="comment">#         # if resourceType in [&#x27;xhr&#x27;, &#x27;fetch&#x27;]:</span></span><br><span class="line"><span class="comment">#         #     resp = await res.text()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#     async def usePypuppeteer(self, request):</span></span><br><span class="line"><span class="comment">#         ws = self.browser.wsEndpoint</span></span><br><span class="line"><span class="comment">#         # print(ws,&quot;running...&quot;)</span></span><br><span class="line"><span class="comment">#         while True:</span></span><br><span class="line"><span class="comment">#             try:</span></span><br><span class="line"><span class="comment">#                 await self.page.goto(request.url,&#123;&#x27;timeout&#x27;:0,&#x27;waitUntil&#x27;: &#x27;domcontentloaded&#x27;&#125;)</span></span><br><span class="line"><span class="comment">#                 if R&#x27;/s?k=&#x27; in request.url :</span></span><br><span class="line"><span class="comment">#                     next_url = await self.page.querySelector(&#x27;.a-last&#x27;)</span></span><br><span class="line"><span class="comment">#                 else:</span></span><br><span class="line"><span class="comment">#                     next_url = await self.page.querySelector(&#x27;#title&#x27;)</span></span><br><span class="line"><span class="comment">#                 print(next_url)</span></span><br><span class="line"><span class="comment">#                 if not next_url:</span></span><br><span class="line"><span class="comment">#                     continue</span></span><br><span class="line"><span class="comment">#                 break</span></span><br><span class="line"><span class="comment">#             except Exception as ex:</span></span><br><span class="line"><span class="comment">#                 print(&quot;network error ...&gt;&gt;&gt;1&quot;)</span></span><br><span class="line"><span class="comment">#                 # await self.page.close()</span></span><br><span class="line"><span class="comment">#                 await self.usePypuppeteer(request)</span></span><br><span class="line"><span class="comment">#                 # self.page.close()</span></span><br><span class="line"><span class="comment">#                 # await self.browser.disconnect()  </span></span><br><span class="line"><span class="comment">#                 # self.browser = await pyppeteer.connect(&#123;&#x27;browserWSEndpoint&#x27;: ws&#125;)</span></span><br><span class="line"><span class="comment">#                 # ua=redis_ua.sget(&quot;user-agent&quot;)</span></span><br><span class="line"><span class="comment">#                 # redis_ua.rpush(&#x27;user-agent&#x27;,ua)</span></span><br><span class="line"><span class="comment">#                 # self.page = await self.browser.newPage()</span></span><br><span class="line"><span class="comment">#                 # await self.page.authenticate(&#123;&quot;username&quot;: &quot;H6587BH09900664D&quot;, &quot;password&quot;: &quot;20C4314AF6C62E0F&quot;&#125;)          </span></span><br><span class="line"><span class="comment">#                 # await self.page.setViewport(viewport=&#123;&#x27;width&#x27;: 1366, &#x27;height&#x27;: 768&#125;)</span></span><br><span class="line"><span class="comment">#                 # await self.page.setUserAgent(str(ua,encoding=&#x27;utf-8&#x27;))</span></span><br><span class="line"><span class="comment">#                 # await self.page.setJavaScriptEnabled(enabled=True)</span></span><br><span class="line"><span class="comment">#                 # await self.page.evaluate(</span></span><br><span class="line"><span class="comment">#                 #     &#x27;&#x27;&#x27;() =&gt;&#123; Object.defineProperties(navigator,&#123; webdriver:&#123; get: () =&gt; false &#125; &#125;) &#125;&#x27;&#x27;&#x27;)  </span></span><br><span class="line"><span class="comment">#                 # await self.page.evaluate(&#x27;&#x27;&#x27;() =&gt;&#123; window.navigator.chrome = &#123; runtime: &#123;&#125;,  &#125;; &#125;&#x27;&#x27;&#x27;)</span></span><br><span class="line"><span class="comment">#                 # await self.page.evaluate(</span></span><br><span class="line"><span class="comment">#                 #     &#x27;&#x27;&#x27;() =&gt;&#123; Object.defineProperty(navigator, &#x27;languages&#x27;, &#123; get: () =&gt; [&#x27;en-US&#x27;, &#x27;en&#x27;] &#125;); &#125;&#x27;&#x27;&#x27;)</span></span><br><span class="line"><span class="comment">#                 # await self.page.evaluate(</span></span><br><span class="line"><span class="comment">#                 #     &#x27;&#x27;&#x27;() =&gt;&#123; Object.defineProperty(navigator, &#x27;plugins&#x27;, &#123; get: () =&gt; [1, 2, 3, 4, 5,6], &#125;); &#125;&#x27;&#x27;&#x27;)</span></span><br><span class="line"><span class="comment">#                 # await self.page.waitFor(10000)</span></span><br><span class="line"><span class="comment">#                 # self.saveMongo(request,ex)</span></span><br><span class="line"><span class="comment">#                 continue</span></span><br><span class="line"><span class="comment">#         if R&#x27;/s?k=&#x27; in request.url :</span></span><br><span class="line"><span class="comment">#             await self.page.setRequestInterception(True)</span></span><br><span class="line"><span class="comment">#             self.page.on(&#x27;request&#x27;, self.intercept_request)</span></span><br><span class="line"><span class="comment">#             # self.page.on(&#x27;response&#x27;, self.intercept_response)</span></span><br><span class="line"><span class="comment">#             await self.page.evaluate(&#x27;window.scrollBy(0, document.body.scrollHeight)&#x27;)</span></span><br><span class="line"><span class="comment">#             await asyncio.sleep(3)</span></span><br><span class="line"><span class="comment">#         else:</span></span><br><span class="line"><span class="comment">#             # await asyncio.sleep(3)</span></span><br><span class="line"><span class="comment">#             #鼠标滚动到底</span></span><br><span class="line"><span class="comment">#             for i in range(0,6):</span></span><br><span class="line"><span class="comment">#                 await self.page.evaluate(&#x27;window.scrollBy(0, &#123;&#125;)&#x27;.format(800*i))</span></span><br><span class="line"><span class="comment">#                 await asyncio.sleep(4)</span></span><br><span class="line"><span class="comment">#             # await self.page.evaluate(&#x27;window.scrollBy(0, document.body.scrollHeight*1/2)&#x27;)</span></span><br><span class="line"><span class="comment">#             # await asyncio.sleep(3)</span></span><br><span class="line"><span class="comment">#         content = await self.page.content()</span></span><br><span class="line"><span class="comment">#         # content = await self.page.evaluate(&#x27;document.body.textContent&#x27;, force_expr=True) </span></span><br><span class="line"><span class="comment">#         return content</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     def saveMongo(self, request, exception):</span></span><br><span class="line"><span class="comment">#         if exception:</span></span><br><span class="line"><span class="comment">#             print(request.url)</span></span><br><span class="line"><span class="comment">#             request_url=str(request.url)</span></span><br><span class="line"><span class="comment">#             if R&quot;www.amazon.com/s?k=&quot; in request_url:</span></span><br><span class="line"><span class="comment">#                 db = MongoDB(&quot;AddTask&quot;,&quot;Add_List&quot;)</span></span><br><span class="line"><span class="comment">#                 items=&#123;&#125;</span></span><br><span class="line"><span class="comment">#                 items[&quot;cid&quot;]=GetAmazonUrlCID(request_url)</span></span><br><span class="line"><span class="comment">#                 items[&#x27;kwURL&#x27;]=[]</span></span><br><span class="line"><span class="comment">#                 items[&#x27;Finished_time&#x27;]=parse(str(datetime.now())[0:19])</span></span><br><span class="line"><span class="comment">#                 items[&#x27;link_url&#x27;]=request_url</span></span><br><span class="line"><span class="comment">#                 items[&#x27;status&#x27;]=&quot;failed&quot;</span></span><br><span class="line"><span class="comment">#                 items[&#x27;error&#x27;]=str(exception)</span></span><br><span class="line"><span class="comment">#                 if db.getInfo(&#123;&#x27;id&#x27;:int(items[&quot;cid&quot;])&#125;):</span></span><br><span class="line"><span class="comment">#                     db.updateDict(&#123;&#x27;id&#x27;:int(items[&#x27;cid&#x27;])&#125;,&#123;&#x27;$set&#x27;:items&#125;)</span></span><br><span class="line"><span class="comment">#                 # print(&quot;*&quot;*100,str(exception))</span></span><br><span class="line"><span class="comment">#             else:</span></span><br><span class="line"><span class="comment">#                 db_ = MongoDB(&quot;AmazonDB&quot;,&quot;AmazonContent&quot;)</span></span><br><span class="line"><span class="comment">#                 items=&#123;&#125;</span></span><br><span class="line"><span class="comment">#                 items[&#x27;id&#x27;]=db_.getID(&quot;amazonUrl&quot;)</span></span><br><span class="line"><span class="comment">#                 items[&quot;cid&quot;]=GetAmazonUrlCID(request_url)</span></span><br><span class="line"><span class="comment">#                 items[&#x27;Finished_time&#x27;]=parse(str(datetime.now())[0:19])</span></span><br><span class="line"><span class="comment">#                 items[&#x27;link_url&#x27;]=request_url</span></span><br><span class="line"><span class="comment">#                 items[&#x27;status&#x27;]=&quot;failed&quot;</span></span><br><span class="line"><span class="comment">#                 items[&#x27;error&#x27;]=str(exception)</span></span><br><span class="line"><span class="comment">#                 db_.insertDict(items)</span></span><br><span class="line"><span class="comment">#             return None</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     def process_response(self, request, response, spider):</span></span><br><span class="line"><span class="comment">#         # Called with the response returned from the downloader.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#         # Must either;</span></span><br><span class="line"><span class="comment">#         # - return a Response object</span></span><br><span class="line"><span class="comment">#         # - return a Request object</span></span><br><span class="line"><span class="comment">#         # - or raise IgnoreRequest</span></span><br><span class="line"><span class="comment">#         return response</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     def process_exception(self, request, exception, spider):</span></span><br><span class="line"><span class="comment">#         # Called when a download handler or a process_request()</span></span><br><span class="line"><span class="comment">#         # (from other downloader middleware) raises an exception.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#         # Must either:</span></span><br><span class="line"><span class="comment">#         # - return None: continue processing this exception</span></span><br><span class="line"><span class="comment">#         # - return a Response object: stops process_exception() chain</span></span><br><span class="line"><span class="comment">#         # - return a Request object: stops process_exception() chain</span></span><br><span class="line"><span class="comment">#         pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     def spider_opened(self, spider):</span></span><br><span class="line"><span class="comment">#         spider.logger.info(&#x27;Spider opened: %s&#x27; % spider.name)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># _patch_pyppeteer()</span></span><br></pre></td></tr></table></figure>










]]></content>
  </entry>
  <entry>
    <title>一套完整的交易系统操作学习心得</title>
    <url>/2018/09/13/47862/</url>
    <content><![CDATA[<p>老杨我做金融交易多年，现在主做外汇和黄金。金融市场高手众多，自己不敢妄称高手。开此贴的目的<br>只是把自己做金融交易的心得体会做一个文字的记录，若有说得不对的地方，还请各位不惜赐教，指出<br>不足之处。<br>因为涉及到的知识点比较零散，所以会以连载的形式更新本帖，为避免太监的嫌疑，所以会把每天<br>的交易记录发上来，一来提醒自己更新，二来希望能抛砖引玉引出高手，大家共同讨论，共同进步。<br>也许很多朋友会问这样一个问题，你到底赚了多少钱，我想说，我不知道自己赚了多少钱，我赚了<br>的只是交易的点数而已，所以在谈完整交易系统之前，我先来谈谈我们来做交易的目的。请容老杨我慢<br>慢道来……<br>世界上任何一个领域的成功人士，都是先做好了那个领域的事情，而后，财富的增加只是自然而然<br>的事。是对于他做好了这件事的奖励而已。比如迈克尔乔丹是打篮球打得最好的，那么他也是篮球领域<br>财富最多的，迈克尔杰克逊是跳舞最好的，那么他也是跳舞领域财富最多的，当我们谈论起这些人的时<br>候，脑海中第一个浮现的不是他们坐拥的财富，而是他们杰出的能力……不可否认，我们来做交易，不<br>论是股票，期货，还是外汇黄金。最开始都是奔着赚钱来的，但是慢慢的在这个领域久了，你会发现从<br>一开始什么都不懂，凭手气来交易是行不通的，于是开始学习，开始研究技术面，基本面，慢慢的知道<br>什么是K线形态，什么是MACD，什么是RSI……到慢慢的从技术面上升到哲理层面，交易好似一种哲<br>学，一种对人性的理解与感悟。<br>什么是完整的交易系统，简单的来讲，就是能让你稳定，持续在市场中盈利的交易系统。也许每个<br>人的交易策略和风格不太一样，但有一点一定是相通的，那就是高手，都是把一招练到了极致，就好比<br>武侠世界里面的高手，每个人掌握的招式不同，但都是高手，相同的，只是他们有自己用得最好的一<br>招，没有人比他用得更好，于是他就成了高手。，大家可以来讨论讨论<br>做金融也是一样，有人专门分析基本面，有人专门研究K线，有人专门研究macd……不管你研究的<br>是什么，只要你能把一个招式练到极致，高手就自然而然诞生了。<br>下面是我的交易系统所包含的几个重要的方面，希望能抛砖引玉<br>1，进场点<br>2，出场点<br>3，预判盘整<br>4，预判V字反转（如5月的非农）<br>5，预判假突破<br>6，资金管理<br>7，风险控制<br>我一直觉得，金融市场就好比打仗的战场，很多人因为各种各样的原因进到了这个里面，面对战场<br>的瞬息万变，有人靠着自身的技巧活到了最后，甚至成为英雄，有人默默无闻，在这个市场里做着吃力<br>不讨好的工作，当然更多的，是成为了战场的炮灰，连名字都没留下就消失在这个市场里。<br>在上战场之前需要进行新兵训练，同样的，在进金融市场之前也需要进行训练，如果你上战场之前<br>没有进行训练，什么都不懂，十有＊＊会沦为炮灰，金融市场也是一样，如果你没有经过训练，什么都<br>不懂，十有＊＊是来给庄家，给老手送钱的炮灰。<br>所以接下来，就让我们从新兵训练营开始吧，are you ready？<br>—————————————————————————<br>##　新兵训练营<br>做金融好比当兵，不管你是什么都不懂的新手，还是混迹于各大金融市场几十年的老手，有一些基<br>本的纪律是一定要遵守的。我见过做单爆仓的，跳楼的，倾家荡产的，基本上可以归纳为犯了以下三个<br>错误，所以老杨认为，这三点是做金融铁的纪律，如果触犯任何一条，那么爆仓对于你而言只是时间问<br>题。<br>1，不止损<br>2，重仓<br>3，频繁交易<br>其中还牵涉到一些细节问题，容老杨喝口茶，一一道来。<br>——————————————————————————————————————</p>
<h3 id="错误一：不止损"><a href="#错误一：不止损" class="headerlink" title="错误一：不止损"></a>错误一：不止损</h3><p>止损的重要性，很多人都已经提过，不可否认大家来到这个市场都是想赚钱的，没谁希望亏钱，但<br>是作为一个操盘手，你每下一个单，第一要考虑的并不是这个单你能赚多少，而是你能承受住多少的亏<br>损。<br>不光是做单，做生意，做事，做人。都要把事情最坏的结果想清楚，这个结果是否是你能承受的，<br>如果不能，请停止。<br>给大家举一个例子，我刚做金融半年的时候，有一个跟我差不多年级的操盘手接了一个客户账户，<br>此君平时没有什么交易技巧，靠感觉做单，以刷单为乐，当时他从公司接过账户的时候，我预料到他会<br>持续亏损，建议他不要接，然后他说了一句“不怕，富贵险中求”。从那一刻起，就是他悲剧的开始，10万<br>的客户资金5天亏损了2万。他瞒着公司不报告情况，反而在剩余8万的时候下了个重仓，不止损。过夜之<br>后，8万还剩4万被公司发现，强行平仓了。于是此君只能依靠工资偿还欠公司的债务，开始了为期几年<br>的长工生涯（我们那时候工资才几百块一个月）。<br>如果说你设置的止损非常容易被扫掉，很多时候刚刚扫你的止损，行情就按着你预判的方向走，让<br>你痛心疾首后悔莫及。造成这种情况只有两个愿意，1，你的止损位置没放好。2，你选择的进场点没选<br>好。止损是必须的事情，因为这个市场上，即使是称之为神的人也做不到100％的正确。<br>止损的重要性相信很多大神都已经无数次提到过，这里就不再赘述。接下来要讲讲从严格止损这条<br>纪律延伸出来的几个细节，也算是老杨的一点个人心得体会。<br>————————————————————————————————————<br>关于严格止损最重要的一点延伸，就是不锁单。很多人当仓位出现亏损的时候不愿止损，而是进行锁<br>仓。期望着有一天亏损会变成盈利。试问一下，几年前大盘四千五千点以上的锁仓，现在解了么？上个<br>月在1500做多黄金的童鞋们，仓位解了么？也许有人这里要来反驳我，说“我做的是价值投资，不是短线<br>交易，我是做长线的”<br>但是亲～你的资金被占用着，无法运转，那就不叫做长线，而是叫被套牢了。真正的长线是站在利<br>润基础之上长线持有盈利的仓位，博取更大的利润，别骗自己了……<br>锁仓是一种侥幸行为，期望着在这个市场上永远不亏钱，但那是做不到的。一个单子被严格止损之<br>后，剩下的资金还有运转的可能，还有盈利的希望，而且锁仓会严重影响你的交易心态，让你总想着那<br>亏损的单子，影响接下来的交易。<br>—————————————————————————<br>如果趋势前期开了仓，在趋势发展中会遇到阻力或支撑，在这些位置开反向仓位作为趋势单的护<br>航，盈利40点以上即提保护损，开仓本身也带损，这样的锁仓可以么？貌似可以吃到整段的趋势<br>我并不反对任何形式的交易方法，以上所有，都是我的个人见解及操作方法。<br>你说的这种，属于在顺势中遭遇回调行情，我不反对你的做法，但我想说说我的做法。<br>当一波趋势发起，我做到了，并且持有盈利的仓位，但是遭遇了阻力或者支撑，我会判断回调的位<br>置，因为遇到阻力并不一定会出现回调。也有可能是横盘，所以我不会在那里做反向单来锁仓，如果我<br>认为趋势没有结束，那么我会把止损放在平保的位置继续持有，如果我认为回调点位会比较大，那么我<br>会出掉原来的趋势单，然后做新的单子，然后再等趋势发起的时候再进趋势单。<br>——————————————————————————————</p>
<h3 id="关于严格止损的延伸二"><a href="#关于严格止损的延伸二" class="headerlink" title="关于严格止损的延伸二"></a>关于严格止损的延伸二</h3><p>止损，一定是设置自动止损，而不是手动止损。<br>这不仅仅是怕碰到秒杀行情导致手动无法平仓止损的情况，更重要的是一个交易心态因素在里面，<br>要一个人眼睁睁的看着账户亏损还是需要一定勇气和决心的。心态不坚定的人在这里就会扛单，会锁<br>仓，会出现各种各样的状况……所以，我每一次下单必带好自动止损，雷打不动。<br>————————————————————————————————</p>
<h3 id="错误二：重仓"><a href="#错误二：重仓" class="headerlink" title="错误二：重仓"></a>错误二：重仓</h3><p>我相信做金融的人，有不少人是非常推崇，甚至一直坚持重仓交易的。因为在他们的概念里，重仓<br>要么就是大赚，要么就是大亏。为什么不博一把，来个一夜暴富呢？但是在我看来，重仓的结果只有一<br>个，那就是大亏！为什么，容我细细道来。<br>不错，重仓是有可能大赚，做金融做的是个概率游戏，100％的正确或者100％的错误是不存在的，<br>但重仓最大的问题是，你一夜翻了几番之后，你会愿意减小你的仓位么？你会从此退出这个市场，不再<br>博弈么？从你重仓的那一刻开始，你就从一个金融交易者变成了一个赌徒，而赌徒是不会愿意在手上还<br>有大把筹码的时候离开赌桌的，从你梦想一夜暴富的那一刻开始，你就已经走上了不归路，哪怕你运气<br>好用10万重仓赚回了50万，又会想用50万去赚500万，无穷无尽的欲望控制着你。但是请听我一句劝，<br>没有人可以做到100％正确，重仓迟早有亏损的那一天，而那一天是你第一次重仓亏损，也会是最后一<br>次，因为你会把之前赚的钱又再次亏回去。<br>我曾经认识一个朋友喜欢重仓，本金8万他一个星期赚到了28万，然后沾沾自喜，继续满仓操作，4<br>月12号的黄金大跌让他爆仓了。在5月他重新入金20万，第一天就亏损15万，继续入金60万……到前几<br>天我听说他60万被套牢，又入80万资金在扛着他之前60万重仓所造成的亏损，这种人，神仙也救不了他<br>了……<br>——————————————————————————————————————</p>
<h3 id="错误三：频繁交易"><a href="#错误三：频繁交易" class="headerlink" title="错误三：频繁交易"></a>错误三：频繁交易</h3><p>关于交易频率，也许不同的金融产品有所不同，但有一点是需要格外提醒新兵的，那就是新兵通常<br>根据感觉来做单，而不是根据交易系统的进单信号来做单。<br>我以股票为例，很多新兵看到某支股票涨了，马上会想他还要涨，结果进在了天花板上，看到回调<br>一点点，马上又抛掉。还有的看到某支股票跌得厉害，心里想跌了这么多，总要涨一点了吧，于是大举<br>杀入，最后的结果是越跌越残……<br>再以黄金为例，涨了2个点以为就要暴涨了，马上进多，跌了3个点又以为跌的趋势来了，马上出掉<br>多单进空。追涨杀跌。最终落得多空都亏钱。<br>我认为，交易的频率多少并不重要，而是你是否拥有一套完整，严格并经过市场验证有效的交易系<br>统，如果你根据交易系统进单，那么一天不管是10次交易还是100次交易，都是正确的。反之，如果你不<br>是根据交易系统而是凭感觉，凭手气来进单，那么即使1次也是不应该的。追涨杀跌是亏钱的捷径。<br>新兵训练营已经结束了，接下来要讲的是一套完整的交易系统应该包括哪些方面，属于中级教程，<br>讲完了之后还会讲到交易心态和交易哲学，希望对大家有所帮助。<br>##　—————————————————————————————<br>我这里贴一段我老师以前的讲义，希望大家能够喜欢，并从中有所收获。<br>把金融交易当成是自己在创业。<br>把金融交易当成是自己在创业。正所谓出发点错则步步皆错。我们在做交易的立场是把他当成是创<br>业来干的，你才会全力以赴。<br>说到创业又和成功学本身有或多或少的关系。我做外汇近10年，一直这样勉励自己。既然是创业，<br>那么我们就首先要具备创业者的心态以及成业者的方式去做才可能成功。本身站在成功的概率而言，多<br>数人会是20％成功，80％失败。我们暂且定义成功是一个小概率的事情，所以要求我们自己本身要与众<br>不同。<br>首先创业者需要具备的下面四点不同的必备创业特质：第一，要拥有超强的自我学习能力；第二，<br>要拥有超强的自我检讨能力；第三，要拥有超强的自我改造成长能力；第四，要拥有超强的独立运作能<br>力。<br>从自我学习到自我检讨，从自我改造成长到独立运作，本身就需要自己是一个自动自发的人。把交<br>易当成事业来创不是一句空话，很多人如果是带着侥幸的心态、带着玩一玩而已的心态来做的，其实离<br>开金融市场是最后的选择。不管任何事物，只要我们没有把它当成一回事，市场和成功本身也不会当我<br>们当成是一回事。这个行业不允许混日子，没有中间路线，它只有“赚”或者“亏”两个极端。如果你做别的<br>行业，比如医生，律师，你哪怕是医死人了，或者败诉了，你依然可以拿到报酬。而交易会给我们做错<br>事情做出惩罚－－－－－亏损。亏损很多时候亏的不单单是钱，还会亏掉你继续做下去的信心。所以既<br>然来做交易，我们很有必要把交易当成是我们人生的事业来做。我们是在创业，如果仅仅只是为了养家<br>糊口，仅仅只是希望通过交易可以让自己生活过的好一点，这就不是在创业。<br>就深层次的意义而论，创业非创大业不可。很多人是为了房子、车子、美女这些生活的必须品。再<br>重申一下，房子车子美女仅仅只是生活的必需品，成功的附带品。。所以我们不能有小市民思想，这既<br>是格局的问题，也是出发点的问题。这让我想起一句话：定位决定地位，思路决定出路，资本决定资<br>格。假设两个做交易的人，A是为了房子车子来做交易的，B是为了成立一个私募基金走向国际的来做交<br>易。我们可以预见他们谁的成就会更大。<br>还有比成功更深一步的态度，当一个人一再可以去追求成功，而在追求使命和意义的时候，他站在<br>的高度固然是不一样的。也许你们会问，那我们应该走什么路线？我说说我个人的看法。只要分三步<br>走：第一，成为操盘手，稳定盈利的操盘手；第二，成为投资人，例如私募基金；第三步，成为资本家<br>来做交易，或者说来做金融投机。既要目光高远，又要脚踏实地。远近都抓——远的是目标参照物，近<br>的是实施方案。你必须从自己出发，这样一步一个脚印去做，才是一条创业之路。再重复一下创业必备<br>的特质：拥有超强的自学能力，拥有超强的自我检讨能力，拥有超强的自我改造能力，拥有超强的独立<br>运作能力。希望大家都在奋斗不息的路上，正所谓，行走可以不断地到达，到达后而不再行走就如同死<br>亡。有一句话叫做：只要心还愿意攀登，就没有到达不了的高度。<br>我站在一个过来人的角度知道这一点，多人来做外汇是茫然的：第一是不知道自己所站在的人生位<br>置，也不知道未来要到达的位置是什么；第二是不知道自己怎么样做才可以成功，在茫然的情况下，每<br>天面对的都是昨天或者很多个昨日的问题，从而无法进步，我希望今天这个课程可以真正帮助到大家，<br>能够从新认识自己，和从新认识金融交易。<br>—————————————————————————<br>不知道大家对于财富的观念是什么样，这里我想谈一谈PN我对财富的看法。<br>我认为，财富可以分为两种，一种为内在财富，一种为外在财富。内在财富包括一个人的知识，素<br>质，涵养，性格。外在财富包括票子，房子，车子……当我们在追求财富的路上，经常会看见这样一些<br>文章，介绍某某名人的第一桶金，他们的第一笔生意为他们赚取了多少财富，但却少有人问津他们在赚<br>取第一笔财富之前经历的无数苦难，当然更不会看到这些苦难才塑造了这些名人富人的个性，成为了他<br>们的内在财富，而又是这些内在财富，为他们创造了无数的外在财富……这种急功近利的思想，创造了<br>无数浮躁的，想要一夜暴富的人。而外在财富是需要内在财富作为地基来承载的，只有懂得了善待财<br>富，发挥财富的作用的人，才能让自己的财富越来越多，这就好比没有哪个富翁简历上写着这人是通过<br>买＊＊中头奖成为了富翁一样，而据调查，中＊＊头奖的人在中奖之后的不长时间里，会变得比中奖之<br>前更贫穷，那是因为他们没有内在财富来承载这突如其来的外在财富，所以财富不会留在不懂得珍惜，<br>不懂得善待他们的人手里。所以，人生的第一桶金，乃至之后的数桶金应该是你的内在财富，只有掌握<br>了内在财富，他们才能为你带来无数的外在财富。<br>———————————————————————————<br>从今天开始，老杨我讲授交易系统里面的几个重要部分。但有一点需要事先说出来。<br>交易系统和指标千千万，就好比武功招式千千万，没有哪一个是最好的，适合自己的才是最好的。<br>所以老杨我在此教授的并不是本人交易系统中的细节，而是教如何打造属于你自己的交易系统，授人以<br>鱼不如授人以渔<br>##　第一讲：进场点<br>关于进场点的选择，请各位注意，我用的是“选择”而不是“判断”，因为根据做单风格的不同，会形成<br>不同的进场点。简单归纳有如下几个：<br>1，极限点位挂单法，根据各种各样的指标或者猜测，如斐波那契回调位，整数关口等提前预判价格<br>会到某一个点位，然后提前在此点位进行挂单，优点在于，一旦这种方式成功，会抓到行情的最大利<br>润，一个点都不放过，并产生极大的成就感。<br>2，支撑阻力位进单法：这种也是根据各种判断支撑阻力的方式，如前期支撑阻力位，均线支撑阻力<br>位等，提前预判价格会在哪个价位受到支撑或者阻力，从而进单的方式。<br>3，指标进单法，根据各种指标的形态来决定进单，如macd金叉，RSI超买超卖，乃至各种EA智能交<br>易程序。<br>4，形态进场法，根据各种K线形态来进单，如大形态的三角，头肩，到小形态的K线组合如启明星，<br>锤子线，以及上行下行通道，艾略特波浪形态等等。<br>5，破位进场法，在横盘或箱体整理之后，突破横盘和箱体的那一刻进场的方法<br>6，第六感进单法，想怎么进就怎么进，没有理由，纯粹凭感觉，新手最爱，老手也有根据盘感来进<br>单的时候。<br>市场上95％的交易者进场无外乎我上面列举的那些，其中1－5需要或多或少的技术含量，第6种要么<br>技术含量很高要么技术含量很低，在此不做过多的研究。<br>在金融市场上最终能够存活下来的，并可以通过交易为生，我们称这种状态为“稳定盈利”，稳定盈利<br>重在一个“稳”字，所以我们在建立交易系统的时候，要避开一切激进的因素，如抢回调，追单，左侧交易<br>等。<br>做单的节奏就如太极的阴阳轮回一般，行情的单边与盘整也是一个轮回关系。盘整之后就是单边，<br>单边之后就是盘整，甚至有这样的说法叫横有多长，竖有多高。所以我个人并没有选择第1种进场法，大<br>跌和大涨之后，多数情况下都是盘整，即使抢到了最高最低点，也要经历漫长的等待。<br>前段时间忙于一些工作上的事情没有来更新，今天重新开始，先给大家带来一个问题，看看大家的<br>看法是什么样的，稍后我会给出我的答案。<br>这个行情，前期受阻100，现在继续涨，那么后市会怎么走呢？<br>接下来讲解上午的那个问题，盘面受阻100之后，后市如何看？<br>其实大家的回答都对，也都不对。之所以这么说，是因为大家的回答都只是一种可能，而这些可<br>能，都是没有经过实盘盘面确认的。比如……<br>可能性1：行情突破100阻力继续涨，形成N型。<br>可能性2：行情继续受阻100，形成M头，双顶。<br>可能性3，突破100之后假突破，刚刚突破又下跌。<br>甚至可能性4：在阻力位来回盘整震荡。<br>还有很多的可能……<br>这些可能性，其实就是分析师每天做的工作，他们会把各种可能性都想到，总有一个是对的，但是<br>我们作为一个操盘手，行情只会走出一种，判断会出现哪一种就是我们的工作。<br>之所以谈到这些，就是在选择进场点的时候，一定要等待确认你想法的那个信号出现，这个确认的<br>信号，就是你的进场信号，他也许是反转形态，也许是macd开叉，也许是RSI超买超卖，而在确认信号<br>出现之前，你的预判都只是猜测而已，这个进场概念，对于选择在支撑阻力位进场的朋友尤为重要。<br>很多朋友问我，我的进场点是什么，这里可以稍微透露一点，我采用的是爆发点进场，在行情爆发<br>之前大约10分钟到30分钟左右进单，这样进的好处是止损可以比较小，也不需要等待很长的时间就可以<br>见到利润，当行情跑起来之后，我可以把止损放在平保不亏的位置，这样即使行情发生我没有预见到的<br>反转，我也只是不赚不亏。<br>对于进场点的讲解，如果大家没什么问题，接下来就开始讲出场了。<br>今天看到一篇博文，里面有一段话跟我上面的进场观点有异曲同工之妙，这里引用一下。希望能帮<br>助大家更好的理解我说的支撑阻力位≠进场点，一定要等待确认信号之后才可以。<br>“你知道吗？这世上没有任何人可以预测走势。没有人可以知道明天的股价会怎么走，当你认为你可<br>以通过学习或者其他方法来预测走势时，你已经把自己排除在了1％的顶尖的交易员之外了。<br>这世上没有人可以预测，你不能，我不能，任何人都不能。我们所能做的就是跟随……做对唯一的<br>选择就是：顺市。你可以说是顺势，也许意义有那一点点地不同。太简单拉，简单的难以想象。简单到<br>如果有外星人，他们都懂。<br>可是你知道何谓市吗？你知道如何顺市吗？简单的道理，不是简单的行为能达到的！正如很多人终<br>于知道：幸福。可是何谓幸福？如何才能达到？ ”<br>以今天（2013年6月11日）的黄金行情为例，我在15点03分进了空单。<br>也许有朋友没有接触过国外的外汇平台，这里显示的9点03分是柏林时间，跟北京时间相差6小时，9<br>点03分＋6小时就是15点03分。<br>当时的行情图，这里为方便看清楚，用1分的。<br>这就是我所谓的爆发点进场，这里大约提前2分钟，行情在15点05分开始爆发。<br>————————————————————————————</p>
<h2 id="第二讲：出场点以及盘整的预判"><a href="#第二讲：出场点以及盘整的预判" class="headerlink" title="第二讲：出场点以及盘整的预判"></a>第二讲：出场点以及盘整的预判</h2><p>之所以把这两个合在一起讲，是因为在讲解这两点之前，有一个必须解决的前提，就是分析周期。<br>很多人问我，看盘的时候应该看什么周期的，其实这没有一个标准答案，因为市场是变化的，复杂<br>的，不能根据单一的周期来解决所有的行情。举个极端的例子，如果你要做短线，那么是无法从月图来<br>确认进场和出场的，同样，如果你要做长线，那么你看1分图是看不到目标位的。<br>所以我看盘都是多周期配合，小周期确认进场，大周期判断行情的大小及出场预判位，再根据小周<br>期确认信号出场。单一周期虽然也能做单，但比较片面。<br>行情的大小以及盘整的时间都跟周期有关，日图发起的行情肯定不是5分图可以比拟的，盘整也是一<br>样，5分的盘整可能一两个小时就结束了，但日图级别的盘整可能持续几个星期。<br>先讲单边行情，短线还是长线，不是根据自己的喜好来决定，而是根据盘面的状况来决定，如果是5<br>分发起的行情，当然是短线，但如果是日图甚至周图发起的行情，为什么又一定只拿短线利润，而不敢<br>长线持有呢？归根到底是交易系统不够完善，无法判断发起的单边行情到底是短线还是长线，在我看<br>来，短线长线的交易信号都是一样的，所不同的只是出现的周期不同，会造成的持续时间和行情大小的<br>不同。<br>盘整根据周期的不同，可以决定你做单的思路，比如如果出现日图级别的盘整，那么只能做日图周<br>期之下的短线行情，月图出现盘整，才可以做日图级别的行情，如果是60分30分出现盘整，那基本就是<br>不做单的休息信号，可以离开电脑去做点别的事。很多人甚至很多高手都无法提前预判盘整的出现，在<br>震荡行情中不断下单，不断止损，之前赚取的利润碰到一次盘整震荡就会亏得所剩无几。<br>因为我有完善的交易系统，进过无数次市场验证是有效的，可以在爆发点进场<br>举例<br>今天刚才的黄金（6月13日）<br>————————————————————————————<br>关于选择适合自己的技术组成交易系统的问题，我会告诉大家什么是伪技术，什么是真技术。<br>现在的金融市场，充斥着各种伪技术，伪专家，伪高手。先看看什么是伪技术。<br>所谓的伪技术，就是复盘，也就是行情走出来之后回头去看会非常有效，看起来非常牛逼，感觉掌<br>握了这个技术就掌握了通往稳定盈利的金钥匙一般，但是在实盘操作的时候却毫无指导作用，只是让人<br>意淫行情会怎么走的技术。复盘无敌，实盘无效。<br>举个例子，很多教技术分析的书上会教这样一个技术，当布林带开口的时候是单边，收口的时候是<br>盘整。然后配上这样一副图。<br>对于这个技术，我有两个问题，第一，我如何判断布林什么时候开口？第二开口之后方向往哪边<br>走？当年我试着用这个技术来做单，结果我相信跟大多数用这个技术的朋友一样，亏多，几乎不赚。也<br>许有其他高手能解决我上面这两个问题的，那这个技术不失为一个好技术。<br>现在有一个实盘布林图是这样。<br>请问后市如何发展。<br>如果根据布林开口是单边来看这里要做多。可后市的结果却是：<br>跟这样的伪技术类似的还有形态，什么头肩，双顶，双底，旗形，蝴蝶。都是事后来看非常牛逼，<br>但是事前却很难预判到，以最简单的双顶为例，我上面那个受阻100的例子，双顶只是可能性的一种，走<br>出来就是双顶，如果走出是双顶形态，事后来看双顶就是个很牛逼的形态技术，但如果没有顶住呢？没<br>走出双顶就是别的形态了，那一开始就预判双顶不是猜测又是什么呢？<br>我在这里并不是批判这些指标或者技术，而是各位在选择的时候，一定要选择那些可以提前预判后<br>市的技术，或者把本来不能预判的改进成可以预判，而不是沉浸在马后炮的技术中不可自拔。自认为掌<br>握了厉害的东西，其实一文不值。话说老远我现在也还在用布林带，只是用法跟市面上的书上教的用法<br>不太一样罢了。<br>——————————————————————————<br>今天在继续更新帖子内容之前，我发现好多回帖的朋友都没有看懂我这篇帖子所表述的内容，所以<br>看起来云里雾里，不知所云，甚至觉得老杨我废话连篇，就是没有说到点子上，其实老杨句句到点，只<br>是你没有理解，所以在这里先解释一下。<br>我们常听到一句话，叫授人以鱼不如授人以渔，说的是给别人鱼不如教授打渔的方法，这句话放在<br>金融市场上可以这么理解，如果我喊单，荐股，那就是授人以鱼。而接受鱼的人，今天有鱼今天就有得<br>吃，明天人家不给，那明天就得挨饿，甚至万一给的是条臭鱼，毒鱼也因为分不清楚，傻傻的吃了下<br>去。<br>而授人以渔则是教授打渔的方法，好比给了你一张网，然后你可以用这张网去捕捞属于你自己的<br>鱼，不再跟在别人屁股后面吃嗟来之食，这也是大多数人所期望的，只是殊不知别人的网不一定适合<br>你，即使你拿到了也不一定能用好。“纸上得来终觉浅绝知此事要躬行”别人的交易技巧永远没有自己研究<br>出来的记忆深刻，运用熟练。<br>所以这就是我的帖子讲的内容，我不是给你鱼，甚至也不是给你渔网，而是教你如何编织属于你自<br>己渔网，在你编织自己的渔网时，应该要注意的地方，毕竟细节不同，大道相通。<br>如果你觉得自己编网费时费力，那老杨的这篇帖子您就权当废话，不看也罢。<br>———————————————————————————<br>假专家？真专家！<br>PN我记得前几年看过一档CCTV－2的股评栏目，当时已经到了节目的末尾，主持人请网友发表对股<br>票走势的看法，网友A出来说看涨，网友B说看跌。然后主持人请教专家的意见，专家说，股票会涨，但<br>也有跌的可能性。股评到此结束，谢谢各位收看……<br>当时我一口水直接喷在了电视机上……在中国金融界存在着这样一批人，他们谈起国际经济形式，<br>国家经济政策来滔滔不绝，似乎这些事就是他拍板决定的一样，一大堆尔等凡人没听过的专业术语，让<br>人摸不着头脑却又觉得无比厉害。但是……<br>只要到给出具体建议，如何操作的时候，这些人就集体哑了，这还算好的，怕就怕那种自己明明没<br>有带着别人赚钱的能力，还喜欢时不时出来说两句，让本来的亏损继续奔腾的建议……<br>说这是假专家，只是针对于金融市场的交易而言，这些人的话，对实际的操作并无太大的指导作<br>用。<br>其实照中国这国情，这些才是真专家吧。我不多说，大家都懂的……<br>等会来更新伪高手。<br>————————————————————————————<br>boll是常用指标，我帖子里也提到了我现在依然在用，只是用法不是单纯的依靠boll来判断行情的单<br>边和盘整，还是那句话，没有100％正确的指标或技术，但可以通过配合提高正确率。<br>因为我是纯技术派，所以只要是能用K线表示的都可以用，我也并没有只做黄金，前面有外汇的晒<br>单，偶尔还帮别人看看股票。<br>————————————————————————————<br>伪高手？真高手<br>各大论坛，QQ群里不乏各路高手，但其中隐含了不少伪高手，甚至是骗子。通过短时间高额利润做<br>诱饵，骗取交易者的信任。这类人通常有一个特点，就是会把自己捧得跟神一般，动不动就号称超越索<br>罗斯，超越巴菲特。似乎只要跟着他们做，就能永远摆脱亏损，实现利润的奔腾。<br>可事实却并不是让人设想的那么完美，大多数人依然在这个市场上亏钱，然后曝光一个又一个的骗<br>子。<br>真正的高手，不说技术如何，态度一定是谦和的，谦逊的。因为高手之所以是高手，是因为他们经<br>历过市场的风风雨雨，勇于承认自己的错误，并且顺着市场的趋势来操作，我们所有人都是市场的学<br>生。<br>老杨今天能在此与各位朋友交流，实在是人生一大快事，很多人尊称我为高手，如果PN我是高手，<br>那我也是一个亏钱的高手，我前面提到那些不能违反的纪律其实我都曾经违反过，犯错不可怕，可怕的<br>认识不到自己的错误，无法改正错误。金融是一个充分暴露人性的地方，贪婪，恐惧，倔强，死要面<br>子。这些情绪作为一个成功的交易者而言都是需要摒弃的。<br>大道至简，当你顺应了市场之后，交易其实是很简单的事，简单到只有进场和出场而已。<br>—————————————————————————————<br>把出场点讲完吧～<br>出场的把握，其实在进场的那一刻就应该要有一个预判，也就是前面提到的周期问题，日图发起的<br>单边肯定不是一两天就结束了，至少也能看到日图的支撑阻力位。当60分受阻的时候，其实可以无视小<br>周期的停顿，这也是为什么有些人拿的住单，在回调和盘整到来的时候可以很淡定的继续持有头寸，因<br>为他们会判断行情的大小（同样是跟周期有关）。<br>至于具体的出场点把握，如果你的进场把握得很好，那么支撑阻力位，均线支撑阻力出场，就已经<br>可以让你做到稳定盈利了！下面的内容你可以不用看，但是，如果你的目标不是赚钱，而是交易本身，<br>希望成为一个交易高手的话……<br>你需要解决这么一个问题，当看不到支撑阻力（比如突破了前高前低），或者在两个支撑阻力之<br>间，如何判断出场，我们在实盘的时候很多时候都会发现在原来没有出现支撑阻力的地方形成了新的支<br>撑阻力。因为还没到下一个阻力，所以继续持有应该出掉的头寸，结果盈利变成平保，甚至亏损。这个<br>问题曾经在很长的一段时间内困扰着我，直到我解决了这个问题。<br>虽然有些核心的内容非入门的学生是不教的，但这里就当给大家发个福利好了。我用到K线的反转形<br>态。用反转形态足以在绝大多数情况下解决这个问题了。<br>——————————————————————————————<br>今天讲下正确的交易心态，在讲正确的交易心态或者说讲到交易心态，我们有一个前提，这堂课更<br>多是针对做金融多年的老手，有些可能新手听起来不能马上体会，但是对你后期交易是有帮助的<br>很多人做了很久交易，就是无法稳定盈利，很对单子也作对了，就是拿不住，很多机会自己看出来<br>了，就是没有做进去，最后遗憾，很多单子明明自己预感到是要平仓的就是没有去平仓最由盈变亏，很<br>多时候自己知道不是好的机会，就是忍不住去交易不是机会的“机会”这些都是老手们存在的问题<br>能影响心态的还有一个原因就是你的仓位，你下大了这是一个，另外一个是没有止损<br>或者止损过大，资金管理不完善一样会影响心态，唯一要做的事把那些影响你心态的做法改掉，回<br>归到正常的做法<br>昨天我一个群里的朋友说到，同样是做外汇的，怎么人与人之间差距怎么这么大呢<br>这种心态是一种不平衡的心态，因为你起了攀比之心，还有很多人做交易进去之后老是去盯住价<br>格，价格波动一下血压就高一下，这些都会影响你心态<br>你们可能会问，那怎么做呢？我讲东西喜欢讲根本核心，解决问题如果不解决核心，真正的问题都<br>得不到解决，什么是核心？是我们的交易理念！<br>记住，你不是在做外汇，根不是在做那个货币，也不是在做交易。<br>你会问那做什么？做机会！交易市场从来都不缺少机会，缺少的是淡定地能把握机会的人，每天都<br>有很多机会是送钱的交易机会，捉住了吗？<br>回到核心根本，如果你的交易技术系统确保是可以盈利，为什么还是没有做到稳定盈利，那应该就<br>是在这些方面出了问题，是什么影响了你不能平静淡定去面对市场<br>一个是你有很多做法需要改掉，另外一个是心态里的东西，不欲则刚。<br>举个例子，你是一个单身男生，你去泡MM，你和她在一起的时候整天想要接吻牵手上床，这些都是<br>你的欲望反而让你自己紧张，你还是把那些抛在脑后，所有老子说后其身而身先，外其身而身存。<br>交易也是一样。<br>你老是想我要赚多少多少，或者我不能亏，又或者我不能错，这些都不是不欲则刚，你要进入无我<br>的状态<br>交易之路也是修行之路，这些需要你自己慢慢提升，前提是先要知道自己的提升方向，你要对盈亏<br>对错没有任何情绪“小钱靠累，中钱靠智，大钱靠玩”你是在玩，有规则地玩，我们知道交易就是交战，市<br>场就是战场，你一旦还有盈亏对错，就是还有战心。<br>孙子讲的“百战百胜都不是最高明” ，鬼谷子也是一样的观点，不战而屈人之兵才是最高明的。<br>你会想，我们一旦做了交易就是战啊，如何不战？不做交易？对！你已经没有了交易的心态，你的<br>心至少要这样，老子讲的：无为才可以无不为，为者必失，执着必败，是以圣人无为故而无败，无执故<br>而无失，你没有了牵绊那些概念去战，才能做到旁观者清。<br>你会问，怎么样才算是没有战的概念来左右自己，还是刚才说到的，你做交易的似乎已经放下了盈<br>亏对错，达到真正的无我，你用自己的意念去意淫市场就是为，你还有盈亏和对错的概念去交易就是<br>执，很多人把老子想简单了其实是他自己简单，多数人理解的无为就是什么都不做。<br>真正无为的意思是顺势而为，而不加自己的意愿进去。<br>你强加自己意愿进去猜测就是老子说的为者必败。<br>对盈亏对错麻木吧。<br>需要时间。<br>交易稳定盈利很难。<br>是难。<br>但是成功本来就不是一件简单的事，如果谁都能简简单单做到，那就无所谓成功了。<br>————————————————————————————————<br>先谢谢各位朋友的支持，交易系统的创建不是一朝一夕的事情，只希望老杨的这点浅见能对各位有<br>所帮助。<br>前面有朋友回帖说希望能更多的结合实盘讲述一下交易的技巧，那么今天就来讲述一下，如何让利<br>润奔腾。<br>以前天（2013年6月18日）的黄金行情为例，当天的预判是看空，然后等待空单确认信号的出现，<br>目标位在1360附近。附上当天的实盘图（15分）和我的交割单。<br>这是一个典型的日内单边行情，从最高点1386开始下跌，在1382也就是第一个绿色箭头处出现第一<br>个进场信号，于是下第一个空单，到后面出现一波小幅上涨，因为预判的目标是1360，可以判断上涨只<br>是回调，应该继续进空，根据信号，在第二个和第三个箭头处下了2个空单，然后行情如预判继续下跌，<br>在第四个箭头处再次出现进场信号，加仓做空，第五个箭头处也出现了进场信号，但是我没有加仓，因<br>为仓位已经比较重，一直拿到目标位就好。除第二个单有些许浮亏之外，其他的单子都是进在爆发点。<br>这就是我加仓的方法，站在利润的基础上，依然是根据进场信号选择爆发点来加仓，很多我认识的<br>朋友，对于加仓没有一个正确的认识，随心所欲，想加就加，殊不知，加仓也是有规矩可循的。对于我<br>而言，长线短线在我眼里是一码事，只是时间周期的不同（参看前面关于周期的讲授）信号都是一样<br>的。<br>以中长线为例，现在发起一轮中长线行情，预判要维持1个月。那么在自己的长线目标位到达之前，<br>选择日内顺势信号进行加仓，直到自己的目标到位，或者出现了足以让你把所有头寸都出掉的信号。完<br>成获利目标。<br>其实对于技术不太熟练的朋友，也可以选择分段操作，一段一段的吃利润，落袋为安，见势不妙就<br>马上止损。再提一下仓位的控制，针对双向交易的，如果在一波长线上涨趋势中，出现了日内的看跌信<br>号，顺势的多单如果是正常仓位，逆市的就减半，以控制风险。<br>真正的长线，是站在利润基础之上的，这里来一个假设，假设我第一个单出现了浮亏状态，但是又<br>没有打我的止损，出现了第二个进场信号，这里，我的选择是不进，因为手上已经有了浮亏的单子，证<br>明我前面的爆发点没有确认对，再加仓风险也会增加，不如持有原有的头寸，毕竟我追求的是稳定盈<br>利，稳字为先，少赚，不赚也要比亏损好。后面加的仓位也要按照严格止损的要求带好止损，如果加仓<br>被止损，比如亏损30点，那么我会把第一个已经获利的单子止损放在获利30点的位置，这样即使行情出<br>现大逆转，我也不亏。该止损的，就严格止损，该赚的，就要狠狠的赚。<br>————————————————————————————<br>像下午波动这么快的行情，要抓爆发点，我也只有去看1分图甚至30秒的图。贴下1分图的进场点。<br>——————————————————————————————————<br>今天来系统的讲讲风控管理意识和资金管理<br>我讲东西喜欢先讲本质再讲表面，因为如果是只讲表面的东西对各位成长作用不大，所以在个人成<br>长上的三部曲，第一步是改变观念，第二步是改变行为，第三步才到改变结果。比如穷人的观念是钱很<br>少，单身挫男的观念是女孩子很少，而富人的观念是钱很多，觉得女孩子很多很多。心里贫穷的人无法<br>富有，有什么样的观念就会有什么样的行为。行为又导致结果的好坏。<br>举个例子。先来聊一个轻松的话题，做这个行业应该多数都是男生，就聊一个男生的话题，你们是<br>不是见到美女都喜欢看人家，你在看美女的时候，美女回看过来的时候你会不由自主地把你的眼神移开<br>看别的地方，不敢再看美女，你们回想一下自己是不是这样，多数人绝对是这样。为什么呢，因为在你<br>的意识观念中，你会觉得这样看别人会显得自己很好色猥琐，会让别人觉得你不礼貌。你不能让美女发<br>现你在偷偷地看她，这些意识观念是你的老师你的父母和整个社会潜移默化输入给你的。我今天想告诉<br>你一个新的正确观念，先站在女人的角度，一个美女可能花了几十分钟打扮自己如果无人欣赏，她心里<br>肯定是不好受的，你用欣赏的眼神大方地欣赏她告诉她的美，你很绅士地欣赏她的美她心里是高兴的，<br>就好像一个男人，即使是一个你不喜欢的女生用同样的眼神来欣赏你的帅，你心里也是高兴的，你想的<br>是我还是有人欣赏的嘛。这是女人的角度，再站在男人的角度看看这个问题，我们首先确认一个点，任<br>何正常的男人都喜欢看美女，包括你的爸爸我的爸爸，你的爷爷我的爷爷，包括秦始皇，曹操，李世<br>民。只要他是一个正常的男人都喜欢看美女，也就是说，你喜欢看美女证明了你是一个正常的男人，你<br>为什么要压抑自己不去看呢，你要做一个坦荡的人，站在美女的角度，因为男人看她的时候当她回看男<br>生的时候99％都是把眼神移开看别的地方，你不敢继续看她，她回想你不够自信，不够强大，当然你肯<br>定不能色迷迷地盯着人家的乳沟或者屁股看。你如果自信微笑大方地去欣赏她的美，坚定地欣赏她，看<br>到她自己不好意思看你。你再移开，这时候美女想的是，这个男人够强大，这个能人够男人，这个男人<br>很特别。要明白，成功人士的眼神都是很坚定的，因为成功人士他们目标坚定，决心坚定，眼神才能坚<br>定。而多数人的眼神都是游移零散的。当然，如何才能练就一双有魅力的眼神，如何认识更多美女，到<br>建立吸引，牵手，拥抱，接吻，解开扣子，推到，让她爽，到建立长期吸引。当然，这些不是在这里教<br>大家的重点，只是从这个例子，告诉我们，不同观念就会造就不同行为，我相信你知道了我今天告诉你<br>的这个观念，你以后会大方地欣赏美女的美，你以后你会活得更加坦荡，你的眼神也会更加自信和有魅<br>力。观念改变了，你的行为才会跟着改变。行为改变了你的命运结果才会改变。<br>通过这个例子大家意识到了观念意识的重要性，我们回到今天的课程主题，风控管理意识和资金管<br>理方案，说到风控管理意识，首先我们来做交易时是来做投资的而不是来做赌博的，这里说下投资和赌<br>博的区别，区别在于，投资是掌握了一定胜算的情况下才去承担一定的风险，赌博是在没有掌握任何胜<br>算的情况下希望通过侥幸成功而盲目地去承担风险，就拿开公司来说，一个对开公司的流程熟悉，发展<br>规划做足准备，在掌握胜算下去承担一定的风险，这叫投资，但是一个既不懂公司运作流程，也没有做<br>什么准备，没有掌握任何可见胜算就来开公司就是在赌博，我们交易也是一样，你如果不懂里面的游戏<br>规则，技术也不行，系统也没有，理念也不懂，毫无胜算带着侥幸来做交易你就是在赌博。但是你如果<br>学好了技术，有了自己可以稳定盈利的交易系统，掌握胜算做交易，你就是在投资。<br>说到风险，首先说一下风险这两个字是怎么来的，古代人们出海打渔是没有天气预报的所以如果一<br>旦遇到大风暴就会有翻船的危险，风险来于不可控和未知，这就是风险的由来，但是现在的这个风险是<br>可控的，因为有天气预报了。我们交易讲的风控就是把风险降到最低，我们先要有风控意识。<br>再讲到管理，一个国家管理不力或者没有管理就会乱。一支军队管理不力或者没有管理就会散掉，<br>一个公司管理不力就会垮掉，一个个人不善管理他的人生和生活也就一塌糊涂，我们的账户如果没有合<br>理管理就会亏和不稳定，你首先要有这个管理意识。<br>你有了风险控制意识，你也有了资金管理意识，那下面讲的就是怎么做。一个一个讲。<br>先讲我认为不对的做法，第一个是对冲锁单，为什么不对，第一，因为你有停损为什么要锁单，第<br>二，锁单只能证明你的技术不过关判断分析需要提升，第三，锁单会影响你正常交易的心态。第二个是<br>挂单，为什么挂单我不支持，第一挂单和猜对没什么区别，第二挂单没有等验证信号，第三你人在看行<br>情为什么要挂单不直接手动交易，人不在为什么非要去做单。所以我自己包括我的学生是不允许这样做<br>的。<br>再说到进场的仓位，其实这个是根据个人胜算而论，高手肯定下大点，新手肯定是先小仓开始做，<br>一万美金的仓位，正常是下法，单个货币建议新手下0。1或者0。2。你的胜算越高下的仓位跟着提高，<br>如果你已经可以稳定盈利了，一万美金的仓位你可以下单边货币0。5或者1手2手。这个是正常的做法。<br>还有一种做法是根据行情而定，举例，你是做日内交易的，拿黄金交易来说，如果黄金的中线看涨，那<br>你日内交易的时候多单属于顺势单下1手，空单的日内信号属于逆中线趋势就下0。5手。你要稳定盈利你<br>的仓位也一定要稳定，没有节奏地忽大忽小就是没有管理的表现。<br>再说到止损，首先我们先认识一个观念，有止损亏了也对，没有止损抗单抗赚了也错。也就是说我<br>们无论如何都要上止损，这是游戏规则，你要是不遵循这个游戏规则只能自讨苦吃。止损是保证你还有<br>下一次参与的筹码，不伤元气，也是亏小赚大的关键。那怎么放止损，放在哪，我的做法是放在进场波<br>段的前高点或者前低点，空单就放前高，多单就放前低。主要是看你是根据那个时段进场的就看哪个时<br>段里图的波段。<br>再说到止盈，这个需要技术含量，看到哪里需要综合分析，如果是日内交易者的话，除了看支撑阻<br>力位以外一般都是睡前都会把仓位平掉第二天再从新开始，如果做中短线的主要是看支撑阻力为去定。<br>再说到加仓，加仓是本身你已经有一个方向的单子赚钱了，然后站在利润至上顺势继续放大利润，<br>但是新手会容易犯一个错，会在亏损的时候继续加仓，这有赌博的心态成分了。最后结果决然是悲剧<br>的。<br>你想要稳定盈利你的资金管理的规则一定要定好，而不是随心所欲，我的核心理念是先稳定盈利，<br>再稳定暴利，所以我的盈利理念是稳健地步步蚕食，多数新手都是想一下子暴利，急功近利只会让自己<br>倒退。今天就讲到这里，希望大家都有收获。<br>——————————————————————————<br>前段时间跟朋友聊天，讨论什么样的交易系统才是最有效的。我来说说我的看法。<br>其实不管你是用道氏理论，均线系统，macd，还是波浪理论。有一个前提是必须认清的，那就是每<br>天赚钱的人和亏钱的人，所面对的是同样的行情。我喜欢用钓鱼来比喻做交易，池塘里的鱼那么多，每<br>人用的钓竿和鱼饵可能不一样，但只要你用正确的方法，总会钓到属于你的那条鱼，钓鱼，难免会出现<br>鱼漂动了但没钓上来，鱼饵却被吃掉的情况，和止损何其相似，这时作为一个捕鱼人，只有镇定下来，<br>重新上好鱼饵，等待机会继续下钩，如果气急败坏的把自己当作鱼饵跳下池塘想捞一条大鱼，能不能捞<br>到大鱼我不知道，但是被淹死的风险是非常大的……<br>作为一个钓鱼人，池塘的鱼不可能全都能上你的钩，也就是说，不是所有的行情都会符合你的交易<br>系统，这就谈到一个心态问题，当一波大行情启动，但是不符合你的交易系统时，你能淡定的看着么？<br>曾经有过一次操盘的比赛，参赛者都是各大交易团队的高手，一个星期之后，所有的参赛者都出现了亏<br>损，最后拿到冠军的人是账面平保，而他获胜的原因是他一个星期都没有参与交易，发表获奖感言时，<br>他说他不交易的原因是这一个星期都没有出现他做单的信号，于是他选择观望……我第一听到这个事的<br>时候觉得挺搞笑，但是里面包含的做单思想又有几个人能够理解，“只做自己看得懂的行情”这意味这你把<br>眼光放在了交易这件事本身上，而不是赚钱上，我前面也提到过，只有当你把这件事做好，财富才会自<br>然而然来到你的身边。<br>虽然我当年研究交易技巧时，是以解决100％的行情为目标的，但是到了今天，依然有我看不懂的行<br>情，市场复杂变化多端，没有人能做到100％准确，但是当你有了稳定盈利的交易系统，再加上“只做自<br>己看得懂的行情”的良好心态，我相信稳定盈利会自然而然的来到你身边。<br>享受交易，享受交易的过程，希望大家能从交易中收获快乐。<br>——————————————————————————<br>今天来讲讲行情的级别递进问题，先上图一张<br>这是上周的黄金60分图，这波下跌 是前面一大波上涨之后没有经历过等长的横盘开始下跌的，也就<br>是所谓的急变，发现了这波下跌的特点没？下跌的横盘时间越来越长，横盘时间越长，启动的单边行情<br>也就相应的增长。结合我之前讲的下跌级别来判断。一波大涨之后，在下面存在N个支撑位，如果要下<br>跌，也是一个一个破。先从小周期的破起，而突破支撑阻力，有两种方式，一种是慢慢横盘，一种是回<br>调之后，蓄力冲刺。这两种，显然前一种更好把握，也就是横盘之后的爆发点。蓄力冲刺，存在两个方<br>向，相当于要撞破一堵墙，需要先往后退几步。这对于操盘的要求就比较高了，进场没选好，可能就被<br>蓄力的那一波套了进去。突破支撑位，从小周期开始，5分的支撑不需要太多的时间，然后随着周期的增<br>大，横盘时间也开始增长。<br>但是，周期不可能无限增大，那么到哪个周期为止呢。结合具体的例子来回答，上面的黄金横盘<br>图，有4个框框，分别是5分 15分 30分 60分级别的横盘。但是，日图级别依然是看多的，所以，黄金应<br>该在日图，或者比日图小一点的级别止跌，然后重新开启上涨行情。这就是所谓的，小周期的反转不会<br>扭转大势。<br>这个理论，放到周图也可以。第一个框框，是蓄力，其他几个都是横盘。如果在最高的转折点开<br>空。必然要经历来回震荡横盘的心理压力。而如果在横盘区域内部做单，拿个十几点就要跑，风险太<br>大，属于快枪手的做法。我属于慢热持久型。<br>我们讲道法术，我的爆发点进场也只是术的一种，很多人推崇缠论，睡论，道氏理论，其实都是术<br>不同而已，本人对缠对睡研究得不深，爆发点进场也只是属于我自己研究的野路子，如果要取个名字，<br>叫什么好呢，P论还是爆论，呵呵。还是前面说的，不管用什么方法，每天的行情就在那里，只是你如何<br>去解读的问题，有人只看到涨跌，我眼里最多的是横盘，很多人无视横盘的存在，殊不知大行情都是在<br>横盘中酝酿爆发的。<br>今天就先讲到这，如果你对老杨上面的言论表示赞同，希望能有更多的交流，可以来找我。（不知<br>道怎么找？你连我都找不到，还想找到市场的运行规律？）下次再聊。<br>————————————————————————<br>关于固定盈亏比的反驳与见解<br>在我交易的学习过程中，时常会看到或听到这样的论述，我们的交易盈亏比需要达到1：2或者1：3<br>甚至以上才可以赚钱，就是说，当我的止损预设为50点时，我的预期盈利应该是100甚至150点。也就是<br>说，我盈利的一笔单子可以扛住2到3单的止损单。很多交易书籍上都把这个作为重点内容讲述，其中不<br>乏交易大师们的著作。<br>能做到这样的盈亏比固然很好。<br>但是事实果真是如此么？<br>是不是我一个单子做进去，没有达到我的盈亏比我就不出单，一定要到盈利点数才出？是不是到了<br>我的盈利点数我就一定要出，剩下的行情与我无关？答案当然是否定的，任何一个真正做过交易的人都<br>知道，行情瞬息万变，不可能每一次都按照我们的主观意愿来波动。所以给自己定下一个固定的盈亏比<br>无异于削足适履。我喜欢用很简单的举例来说明问题，如果说把我们的交易学习之路比作在驾校学开<br>车，而真正的做交易是上路行驶。驾校的练习路线都是固定的，他们教导学员在什么位置转弯，什么位<br>置停车，什么位置启动……一切都规规矩矩，学员只要遵照执行就可以通过考试。但真正上路行驶又是<br>什么样子？没有一个固定的车况提前让你知道，如果碰上了塞车（盘整行情）那就只能一步一刹，缓慢<br>前行。而如果上了高速（单边趋势）则必须一路加油到底。这才是我们的交易市场！如果在盘整的时候<br>依然坚持固定的盈亏比，不到自己的目标点位绝不出单，就好比在塞车的时候依然坚持以常速行驶，结<br>果一定是出车祸。而在单边行情上坚持固定盈亏比，到了自己的目标点位就出单，就好比在高速路上跑<br>了一小段就停车了，结果也一定是没有把握机会赚取大额的利润。<br>行情瞬息万变，路况也瞬息万变。一个优秀的操盘手好比一个有经验的老司机，会根据实时的盘面<br>来调整自己的策略，如果发现是塞车行情，那么就缩小目标点位，看到前方有阻碍就踩下刹车（平<br>仓），上了一马平川的高速，那就大胆的加上油门往前开（顺势加仓）。，<br>大家可以来讨论讨论<br>所以我的看法是，抛弃固定盈亏比的概念，而把关注的重点放在实时的盘面上来，通过图表来辨明<br>当前的形势，让K线图来告诉你什么时候该进，什么时候该出。</p>
]]></content>
      <categories>
        <category>quant</category>
      </categories>
      <tags>
        <tag>quant</tag>
        <tag>ML</tag>
      </tags>
  </entry>
</search>
